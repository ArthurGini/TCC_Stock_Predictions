{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usei como base esse tutorial:\n",
    "# https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/pt-br/tutorials/keras/regression.ipynb#scrollTo=f-OHX4DiXd8x\n",
    "\n",
    "\n",
    "# Ja li tudo\n",
    "# https://boostedml.com/2020/04/1-d-convolutional-neural-networks-for-time-series-basic-intuition.html\n",
    "\n",
    "# How do I use make a convolutional layer for tabular (1-D) features?\n",
    "# https://stackoverflow.com/questions/59756806/tensorflow-how-do-i-use-make-a-convolutional-layer-for-tabular-1-d-features\n",
    "\n",
    "# TODO: Fiquei de verificar:\n",
    "# https://machinelearningmastery.com/cnn-models-for-human-activity-recognition-time-series-classification/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 2;\n                var nbb_unformatted_code = \"%load_ext nb_black\\n%load_ext lab_black\";\n                var nbb_formatted_code = \"%load_ext nb_black\\n%load_ext lab_black\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black\n",
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lendo Dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 3;\n                var nbb_unformatted_code = \"import pathlib\\nimport datetime\\n\\nimport matplotlib.pyplot as plt\\nimport pandas as pd\\nimport seaborn as sns\\n\\nimport tensorflow as tf\\nimport datetime\\n\\nfrom tensorflow import keras\\nfrom tensorflow.keras import layers\\n\\nfrom keras.callbacks import ModelCheckpoint\\nimport keras_tuner as kt\\n\\n# 80%\\nPATH_TREINO = \\\"../Data/3_Gold/Treino_all_stocks.csv\\\"\\nDF_TREINO = pd.read_csv(PATH_TREINO, sep=\\\",\\\")\\ntrain_dataset = DF_TREINO\\ntrain_dataset = train_dataset.drop(\\n    [\\n        \\\"oil_5\\\",\\n        \\\"usd_5\\\",\\n        \\\"abev_5\\\",\\n        \\\"jbs_5\\\",\\n        \\\"petr_5\\\",\\n        \\\"vale_5\\\",\\n    ],\\n    axis=1,\\n)\\ntrain_labels = train_dataset.pop(\\\"ibova_5\\\")\\n\\n# 20%\\nPATH_TESTE = \\\"../Data/3_Gold/Teste_all_stocks.csv\\\"\\nDF_TESTE = pd.read_csv(PATH_TESTE, sep=\\\",\\\")\\ntest_dataset = DF_TESTE\\ntest_dataset = test_dataset.drop(\\n    [\\n        \\\"oil_5\\\",\\n        \\\"usd_5\\\",\\n        \\\"abev_5\\\",\\n        \\\"jbs_5\\\",\\n        \\\"petr_5\\\",\\n        \\\"vale_5\\\",\\n    ],\\n    axis=1,\\n)\\ntest_labels = test_dataset.pop(\\\"ibova_5\\\")\\n\\n\\\"\\\"\\\"\\n\\tResultado\\n\\\"\\\"\\\"\\n\\nlist_activation = []\\nlist_best_epoch = []\\nlist_best_model_path = []\\nlist_hp_unit_1 = []\\nlist_hp_unit_2 = []\\nlist_hp_unit_3 = []\\nlist_hp_unit_4 = []\\nlist_kernel_size_1 = []\\nlist_kernel_size_2 = []\\nlist_learning_rate = []\\nlist_n_filter_1 = []\\nlist_n_filter_2 = []\\nlist_val_mae = []\\nlist_val_mse = []\\n\\n\\ndf_results = pd.DataFrame(\\n    columns=[\\n        \\\"best_epoch\\\",\\n        \\\"val_mae\\\",\\n        \\\"val_mse\\\",\\n        \\\"n_filter_1\\\",\\n        \\\"n_filter_2\\\",\\n        \\\"kernel_size_1\\\",\\n        \\\"kernel_size_2\\\",\\n        \\\"learning_rate\\\",\\n        \\\"activation\\\",\\n    ]\\n)\";\n                var nbb_formatted_code = \"import pathlib\\nimport datetime\\n\\nimport matplotlib.pyplot as plt\\nimport pandas as pd\\nimport seaborn as sns\\n\\nimport tensorflow as tf\\nimport datetime\\n\\nfrom tensorflow import keras\\nfrom tensorflow.keras import layers\\n\\nfrom keras.callbacks import ModelCheckpoint\\nimport keras_tuner as kt\\n\\n# 80%\\nPATH_TREINO = \\\"../Data/3_Gold/Treino_all_stocks.csv\\\"\\nDF_TREINO = pd.read_csv(PATH_TREINO, sep=\\\",\\\")\\ntrain_dataset = DF_TREINO\\ntrain_dataset = train_dataset.drop(\\n    [\\n        \\\"oil_5\\\",\\n        \\\"usd_5\\\",\\n        \\\"abev_5\\\",\\n        \\\"jbs_5\\\",\\n        \\\"petr_5\\\",\\n        \\\"vale_5\\\",\\n    ],\\n    axis=1,\\n)\\ntrain_labels = train_dataset.pop(\\\"ibova_5\\\")\\n\\n# 20%\\nPATH_TESTE = \\\"../Data/3_Gold/Teste_all_stocks.csv\\\"\\nDF_TESTE = pd.read_csv(PATH_TESTE, sep=\\\",\\\")\\ntest_dataset = DF_TESTE\\ntest_dataset = test_dataset.drop(\\n    [\\n        \\\"oil_5\\\",\\n        \\\"usd_5\\\",\\n        \\\"abev_5\\\",\\n        \\\"jbs_5\\\",\\n        \\\"petr_5\\\",\\n        \\\"vale_5\\\",\\n    ],\\n    axis=1,\\n)\\ntest_labels = test_dataset.pop(\\\"ibova_5\\\")\\n\\n\\\"\\\"\\\"\\n\\tResultado\\n\\\"\\\"\\\"\\n\\nlist_activation = []\\nlist_best_epoch = []\\nlist_best_model_path = []\\nlist_hp_unit_1 = []\\nlist_hp_unit_2 = []\\nlist_hp_unit_3 = []\\nlist_hp_unit_4 = []\\nlist_kernel_size_1 = []\\nlist_kernel_size_2 = []\\nlist_learning_rate = []\\nlist_n_filter_1 = []\\nlist_n_filter_2 = []\\nlist_val_mae = []\\nlist_val_mse = []\\n\\n\\ndf_results = pd.DataFrame(\\n    columns=[\\n        \\\"best_epoch\\\",\\n        \\\"val_mae\\\",\\n        \\\"val_mse\\\",\\n        \\\"n_filter_1\\\",\\n        \\\"n_filter_2\\\",\\n        \\\"kernel_size_1\\\",\\n        \\\"kernel_size_2\\\",\\n        \\\"learning_rate\\\",\\n        \\\"activation\\\",\\n    ]\\n)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pathlib\n",
    "import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import keras_tuner as kt\n",
    "\n",
    "# 80%\n",
    "PATH_TREINO = \"../Data/3_Gold/Treino_all_stocks.csv\"\n",
    "DF_TREINO = pd.read_csv(PATH_TREINO, sep=\",\")\n",
    "train_dataset = DF_TREINO\n",
    "train_dataset = train_dataset.drop(\n",
    "    [\n",
    "        \"oil_5\",\n",
    "        \"usd_5\",\n",
    "        \"abev_5\",\n",
    "        \"jbs_5\",\n",
    "        \"petr_5\",\n",
    "        \"vale_5\",\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "train_labels = train_dataset.pop(\"ibova_5\")\n",
    "\n",
    "# 20%\n",
    "PATH_TESTE = \"../Data/3_Gold/Teste_all_stocks.csv\"\n",
    "DF_TESTE = pd.read_csv(PATH_TESTE, sep=\",\")\n",
    "test_dataset = DF_TESTE\n",
    "test_dataset = test_dataset.drop(\n",
    "    [\n",
    "        \"oil_5\",\n",
    "        \"usd_5\",\n",
    "        \"abev_5\",\n",
    "        \"jbs_5\",\n",
    "        \"petr_5\",\n",
    "        \"vale_5\",\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "test_labels = test_dataset.pop(\"ibova_5\")\n",
    "\n",
    "\"\"\"\n",
    "\tResultado\n",
    "\"\"\"\n",
    "\n",
    "list_activation = []\n",
    "list_best_epoch = []\n",
    "list_best_model_path = []\n",
    "list_hp_unit_1 = []\n",
    "list_hp_unit_2 = []\n",
    "list_hp_unit_3 = []\n",
    "list_hp_unit_4 = []\n",
    "list_kernel_size_1 = []\n",
    "list_kernel_size_2 = []\n",
    "list_learning_rate = []\n",
    "list_n_filter_1 = []\n",
    "list_n_filter_2 = []\n",
    "list_val_mae = []\n",
    "list_val_mse = []\n",
    "\n",
    "\n",
    "df_results = pd.DataFrame(\n",
    "    columns=[\n",
    "        \"best_epoch\",\n",
    "        \"val_mae\",\n",
    "        \"val_mse\",\n",
    "        \"n_filter_1\",\n",
    "        \"n_filter_2\",\n",
    "        \"kernel_size_1\",\n",
    "        \"kernel_size_2\",\n",
    "        \"learning_rate\",\n",
    "        \"activation\",\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 4;\n                var nbb_unformatted_code = \"def get_results(history, best_hps, bst_model_path):\\n    # Select the best epoch,\\n    val_mse_per_epoch = history.history[\\\"val_mse\\\"]\\n    best_epoch = val_mse_per_epoch.index(min(val_mse_per_epoch)) + 1\\n\\n    try:\\n        value_activation = best_hps.get(\\\"activation\\\")\\n    except:\\n        value_activation = None\\n    try:\\n        value_learning_rate = best_hps.get(\\\"learning_rate\\\")\\n    except:\\n        value_learning_rate = None\\n    try:\\n        value_unit_1 = best_hps.get(\\\"unit_1\\\")\\n    except:\\n        value_unit_1 = None\\n    try:\\n        value_unit_2 = best_hps.get(\\\"unit_2\\\")\\n    except:\\n        value_unit_2 = None\\n    try:\\n        value_unit_3 = best_hps.get(\\\"unit_3\\\")\\n    except:\\n        value_unit_3 = None\\n    try:\\n        value_unit_4 = best_hps.get(\\\"unit_4\\\")\\n    except:\\n        value_unit_4 = None\\n    try:\\n        value_kernel_size_1 = best_hps.get(\\\"kernel_size_1\\\")\\n    except:\\n        value_kernel_size_1 = None\\n    try:\\n        value_kernel_size_2 = best_hps.get(\\\"kernel_size_2\\\")\\n    except:\\n        value_kernel_size_2 = None\\n    try:\\n        value_n_filter_1 = best_hps.get(\\\"n_filter_1\\\")\\n    except:\\n        value_n_filter_1 = None\\n    try:\\n        value_n_filter_2 = best_hps.get(\\\"n_filter_2\\\")\\n    except:\\n        value_n_filter_2 = None\\n\\n    \\\"\\\"\\\"\\\"Repeticao MODEL.ipynb\\\"\\\"\\\"\\n\\n    def save_in_list(one_list, value=None):\\n        try:\\n            one_list.append(value)\\n            return one_list\\n        except:\\n            one_list.append(None)\\n            return one_list\\n\\n    save_in_list(list_activation, value_activation)\\n    save_in_list(list_best_epoch, best_epoch)\\n    save_in_list(list_best_model_path, bst_model_path)\\n    save_in_list(list_hp_unit_1, value_unit_1)\\n    save_in_list(list_hp_unit_2, value_unit_2)\\n    save_in_list(list_hp_unit_3, value_unit_3)\\n    save_in_list(list_hp_unit_4, value_unit_4)\\n    save_in_list(list_kernel_size_1, value_kernel_size_1)\\n    save_in_list(list_kernel_size_2, value_kernel_size_2)\\n    save_in_list(list_learning_rate, value_learning_rate)\\n    save_in_list(list_n_filter_1, value_n_filter_1)\\n    save_in_list(list_n_filter_2, value_n_filter_2)\\n    save_in_list(list_val_mae, min(history.history[\\\"val_mae\\\"]))\\n    save_in_list(list_val_mse, min(history.history[\\\"val_mse\\\"]))\\n\\n    # print(f\\\"list_activation: {list_activation}\\\")\\n    # print(f\\\"list_best_epoch: {list_best_epoch}\\\")\\n    # print(f\\\"list_best_model_path: {list_best_model_path}\\\")\\n    # print(f\\\"list_hp_unit_1: {list_hp_unit_1}\\\")\\n    # print(f\\\"list_hp_unit_2: {list_hp_unit_2}\\\")\\n    # print(f\\\"list_hp_unit_3: {list_hp_unit_3}\\\")\\n    # print(f\\\"list_hp_unit_4: {list_hp_unit_4}\\\")\\n    # print(f\\\"list_kernel_size_1: {list_kernel_size_1}\\\")\\n    # print(f\\\"list_kernel_size_2: {list_kernel_size_2}\\\")\\n    # print(f\\\"list_learning_rate: {list_learning_rate}\\\")\\n    # print(f\\\"list_n_filter_1: {list_n_filter_1}\\\")\\n    # print(f\\\"list_n_filter_2: {list_n_filter_2}\\\")\\n    # print(f\\\"list_val_mae: {list_val_mae}\\\")\\n    # print(f\\\"list_val_mse: {list_val_mse}\\\")\";\n                var nbb_formatted_code = \"def get_results(history, best_hps, bst_model_path):\\n    # Select the best epoch,\\n    val_mse_per_epoch = history.history[\\\"val_mse\\\"]\\n    best_epoch = val_mse_per_epoch.index(min(val_mse_per_epoch)) + 1\\n\\n    try:\\n        value_activation = best_hps.get(\\\"activation\\\")\\n    except:\\n        value_activation = None\\n    try:\\n        value_learning_rate = best_hps.get(\\\"learning_rate\\\")\\n    except:\\n        value_learning_rate = None\\n    try:\\n        value_unit_1 = best_hps.get(\\\"unit_1\\\")\\n    except:\\n        value_unit_1 = None\\n    try:\\n        value_unit_2 = best_hps.get(\\\"unit_2\\\")\\n    except:\\n        value_unit_2 = None\\n    try:\\n        value_unit_3 = best_hps.get(\\\"unit_3\\\")\\n    except:\\n        value_unit_3 = None\\n    try:\\n        value_unit_4 = best_hps.get(\\\"unit_4\\\")\\n    except:\\n        value_unit_4 = None\\n    try:\\n        value_kernel_size_1 = best_hps.get(\\\"kernel_size_1\\\")\\n    except:\\n        value_kernel_size_1 = None\\n    try:\\n        value_kernel_size_2 = best_hps.get(\\\"kernel_size_2\\\")\\n    except:\\n        value_kernel_size_2 = None\\n    try:\\n        value_n_filter_1 = best_hps.get(\\\"n_filter_1\\\")\\n    except:\\n        value_n_filter_1 = None\\n    try:\\n        value_n_filter_2 = best_hps.get(\\\"n_filter_2\\\")\\n    except:\\n        value_n_filter_2 = None\\n\\n    \\\"\\\"\\\"\\\"Repeticao MODEL.ipynb\\\"\\\"\\\"\\n\\n    def save_in_list(one_list, value=None):\\n        try:\\n            one_list.append(value)\\n            return one_list\\n        except:\\n            one_list.append(None)\\n            return one_list\\n\\n    save_in_list(list_activation, value_activation)\\n    save_in_list(list_best_epoch, best_epoch)\\n    save_in_list(list_best_model_path, bst_model_path)\\n    save_in_list(list_hp_unit_1, value_unit_1)\\n    save_in_list(list_hp_unit_2, value_unit_2)\\n    save_in_list(list_hp_unit_3, value_unit_3)\\n    save_in_list(list_hp_unit_4, value_unit_4)\\n    save_in_list(list_kernel_size_1, value_kernel_size_1)\\n    save_in_list(list_kernel_size_2, value_kernel_size_2)\\n    save_in_list(list_learning_rate, value_learning_rate)\\n    save_in_list(list_n_filter_1, value_n_filter_1)\\n    save_in_list(list_n_filter_2, value_n_filter_2)\\n    save_in_list(list_val_mae, min(history.history[\\\"val_mae\\\"]))\\n    save_in_list(list_val_mse, min(history.history[\\\"val_mse\\\"]))\\n\\n    # print(f\\\"list_activation: {list_activation}\\\")\\n    # print(f\\\"list_best_epoch: {list_best_epoch}\\\")\\n    # print(f\\\"list_best_model_path: {list_best_model_path}\\\")\\n    # print(f\\\"list_hp_unit_1: {list_hp_unit_1}\\\")\\n    # print(f\\\"list_hp_unit_2: {list_hp_unit_2}\\\")\\n    # print(f\\\"list_hp_unit_3: {list_hp_unit_3}\\\")\\n    # print(f\\\"list_hp_unit_4: {list_hp_unit_4}\\\")\\n    # print(f\\\"list_kernel_size_1: {list_kernel_size_1}\\\")\\n    # print(f\\\"list_kernel_size_2: {list_kernel_size_2}\\\")\\n    # print(f\\\"list_learning_rate: {list_learning_rate}\\\")\\n    # print(f\\\"list_n_filter_1: {list_n_filter_1}\\\")\\n    # print(f\\\"list_n_filter_2: {list_n_filter_2}\\\")\\n    # print(f\\\"list_val_mae: {list_val_mae}\\\")\\n    # print(f\\\"list_val_mse: {list_val_mse}\\\")\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_results(history, best_hps, bst_model_path):\n",
    "    # Select the best epoch,\n",
    "    val_mse_per_epoch = history.history[\"val_mse\"]\n",
    "    best_epoch = val_mse_per_epoch.index(min(val_mse_per_epoch)) + 1\n",
    "\n",
    "    try:\n",
    "        value_activation = best_hps.get(\"activation\")\n",
    "    except:\n",
    "        value_activation = None\n",
    "    try:\n",
    "        value_learning_rate = best_hps.get(\"learning_rate\")\n",
    "    except:\n",
    "        value_learning_rate = None\n",
    "    try:\n",
    "        value_unit_1 = best_hps.get(\"unit_1\")\n",
    "    except:\n",
    "        value_unit_1 = None\n",
    "    try:\n",
    "        value_unit_2 = best_hps.get(\"unit_2\")\n",
    "    except:\n",
    "        value_unit_2 = None\n",
    "    try:\n",
    "        value_unit_3 = best_hps.get(\"unit_3\")\n",
    "    except:\n",
    "        value_unit_3 = None\n",
    "    try:\n",
    "        value_unit_4 = best_hps.get(\"unit_4\")\n",
    "    except:\n",
    "        value_unit_4 = None\n",
    "    try:\n",
    "        value_kernel_size_1 = best_hps.get(\"kernel_size_1\")\n",
    "    except:\n",
    "        value_kernel_size_1 = None\n",
    "    try:\n",
    "        value_kernel_size_2 = best_hps.get(\"kernel_size_2\")\n",
    "    except:\n",
    "        value_kernel_size_2 = None\n",
    "    try:\n",
    "        value_n_filter_1 = best_hps.get(\"n_filter_1\")\n",
    "    except:\n",
    "        value_n_filter_1 = None\n",
    "    try:\n",
    "        value_n_filter_2 = best_hps.get(\"n_filter_2\")\n",
    "    except:\n",
    "        value_n_filter_2 = None\n",
    "\n",
    "    \"\"\"\"Repeticao MODEL.ipynb\"\"\"\n",
    "\n",
    "    def save_in_list(one_list, value=None):\n",
    "        try:\n",
    "            one_list.append(value)\n",
    "            return one_list\n",
    "        except:\n",
    "            one_list.append(None)\n",
    "            return one_list\n",
    "\n",
    "    save_in_list(list_activation, value_activation)\n",
    "    save_in_list(list_best_epoch, best_epoch)\n",
    "    save_in_list(list_best_model_path, bst_model_path)\n",
    "    save_in_list(list_hp_unit_1, value_unit_1)\n",
    "    save_in_list(list_hp_unit_2, value_unit_2)\n",
    "    save_in_list(list_hp_unit_3, value_unit_3)\n",
    "    save_in_list(list_hp_unit_4, value_unit_4)\n",
    "    save_in_list(list_kernel_size_1, value_kernel_size_1)\n",
    "    save_in_list(list_kernel_size_2, value_kernel_size_2)\n",
    "    save_in_list(list_learning_rate, value_learning_rate)\n",
    "    save_in_list(list_n_filter_1, value_n_filter_1)\n",
    "    save_in_list(list_n_filter_2, value_n_filter_2)\n",
    "    save_in_list(list_val_mae, min(history.history[\"val_mae\"]))\n",
    "    save_in_list(list_val_mse, min(history.history[\"val_mse\"]))\n",
    "\n",
    "    # print(f\"list_activation: {list_activation}\")\n",
    "    # print(f\"list_best_epoch: {list_best_epoch}\")\n",
    "    # print(f\"list_best_model_path: {list_best_model_path}\")\n",
    "    # print(f\"list_hp_unit_1: {list_hp_unit_1}\")\n",
    "    # print(f\"list_hp_unit_2: {list_hp_unit_2}\")\n",
    "    # print(f\"list_hp_unit_3: {list_hp_unit_3}\")\n",
    "    # print(f\"list_hp_unit_4: {list_hp_unit_4}\")\n",
    "    # print(f\"list_kernel_size_1: {list_kernel_size_1}\")\n",
    "    # print(f\"list_kernel_size_2: {list_kernel_size_2}\")\n",
    "    # print(f\"list_learning_rate: {list_learning_rate}\")\n",
    "    # print(f\"list_n_filter_1: {list_n_filter_1}\")\n",
    "    # print(f\"list_n_filter_2: {list_n_filter_2}\")\n",
    "    # print(f\"list_val_mae: {list_val_mae}\")\n",
    "    # print(f\"list_val_mse: {list_val_mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 5;\n                var nbb_unformatted_code = \"def save_df_results(save_time):\\n\\n    result_columns = [\\n        \\\"activation\\\",\\n        \\\"best_epoch\\\",\\n        \\\"best_model_path\\\",\\n        \\\"hp_unit_1\\\",\\n        \\\"hp_unit_2\\\",\\n        \\\"hp_unit_3\\\",\\n        \\\"hp_unit_4\\\",\\n        \\\"kernel_size_1\\\",\\n        \\\"kernel_size_2\\\",\\n        \\\"learning_rate\\\",\\n        \\\"n_filter_1\\\",\\n        \\\"n_filter_2\\\",\\n        \\\"val_mae\\\",\\n        \\\"val_mse\\\",\\n    ]\\n\\n    data = list(\\n        zip(\\n            list_activation,\\n            list_best_epoch,\\n            list_best_model_path,\\n            list_hp_unit_1,\\n            list_hp_unit_2,\\n            list_hp_unit_3,\\n            list_hp_unit_4,\\n            list_kernel_size_1,\\n            list_kernel_size_2,\\n            list_learning_rate,\\n            list_n_filter_1,\\n            list_n_filter_2,\\n            list_val_mae,\\n            list_val_mse,\\n        )\\n    )\\n\\n    df_resultados = pd.DataFrame(\\n        data,\\n        columns=result_columns,\\n    )\\n\\n    df_resultados.to_csv(f\\\"Resultados_{TYPE_MODEL}_{save_time}.csv\\\")\\n    return df_resultados\";\n                var nbb_formatted_code = \"def save_df_results(save_time):\\n\\n    result_columns = [\\n        \\\"activation\\\",\\n        \\\"best_epoch\\\",\\n        \\\"best_model_path\\\",\\n        \\\"hp_unit_1\\\",\\n        \\\"hp_unit_2\\\",\\n        \\\"hp_unit_3\\\",\\n        \\\"hp_unit_4\\\",\\n        \\\"kernel_size_1\\\",\\n        \\\"kernel_size_2\\\",\\n        \\\"learning_rate\\\",\\n        \\\"n_filter_1\\\",\\n        \\\"n_filter_2\\\",\\n        \\\"val_mae\\\",\\n        \\\"val_mse\\\",\\n    ]\\n\\n    data = list(\\n        zip(\\n            list_activation,\\n            list_best_epoch,\\n            list_best_model_path,\\n            list_hp_unit_1,\\n            list_hp_unit_2,\\n            list_hp_unit_3,\\n            list_hp_unit_4,\\n            list_kernel_size_1,\\n            list_kernel_size_2,\\n            list_learning_rate,\\n            list_n_filter_1,\\n            list_n_filter_2,\\n            list_val_mae,\\n            list_val_mse,\\n        )\\n    )\\n\\n    df_resultados = pd.DataFrame(\\n        data,\\n        columns=result_columns,\\n    )\\n\\n    df_resultados.to_csv(f\\\"Resultados_{TYPE_MODEL}_{save_time}.csv\\\")\\n    return df_resultados\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def save_df_results(save_time):\n",
    "\n",
    "    result_columns = [\n",
    "        \"activation\",\n",
    "        \"best_epoch\",\n",
    "        \"best_model_path\",\n",
    "        \"hp_unit_1\",\n",
    "        \"hp_unit_2\",\n",
    "        \"hp_unit_3\",\n",
    "        \"hp_unit_4\",\n",
    "        \"kernel_size_1\",\n",
    "        \"kernel_size_2\",\n",
    "        \"learning_rate\",\n",
    "        \"n_filter_1\",\n",
    "        \"n_filter_2\",\n",
    "        \"val_mae\",\n",
    "        \"val_mse\",\n",
    "    ]\n",
    "\n",
    "    data = list(\n",
    "        zip(\n",
    "            list_activation,\n",
    "            list_best_epoch,\n",
    "            list_best_model_path,\n",
    "            list_hp_unit_1,\n",
    "            list_hp_unit_2,\n",
    "            list_hp_unit_3,\n",
    "            list_hp_unit_4,\n",
    "            list_kernel_size_1,\n",
    "            list_kernel_size_2,\n",
    "            list_learning_rate,\n",
    "            list_n_filter_1,\n",
    "            list_n_filter_2,\n",
    "            list_val_mae,\n",
    "            list_val_mse,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    df_resultados = pd.DataFrame(\n",
    "        data,\n",
    "        columns=result_columns,\n",
    "    )\n",
    "\n",
    "    df_resultados.to_csv(f\"Resultados_{TYPE_MODEL}_{save_time}.csv\")\n",
    "    return df_resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definindo o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 6;\n                var nbb_unformatted_code = \"def model_builder(hp):\\n    hp_unit_1 = hp.Int(\\\"unit_1\\\", min_value=16, max_value=64, step=1)\\n    activationL = [\\n        \\\"relu\\\",\\n        \\\"sigmoid\\\",\\n        \\\"softplus\\\",\\n        \\\"softsign\\\",\\n        \\\"tanh\\\",\\n        \\\"selu\\\",\\n        \\\"elu\\\",\\n        \\\"relu\\\",\\n    ]\\n    activation_choice = hp.Choice(\\\"activation\\\", values=activationL)\\n    hp_learning_rate = hp.Choice(\\\"learning_rate\\\", values=[1e-2, 1e-3, 1e-4])\\n\\n    model = keras.models.Sequential(\\n        [\\n            layers.LSTM(\\n                units=hp_unit_1,\\n                return_sequences=True,\\n                input_shape=(36, 1),\\n                activation=activation_choice,\\n            ),\\n            # tf.keras.layers.Flatten(),\\n            layers.Dense(units=1, activation=\\\"linear\\\"),\\n        ]\\n    )\\n\\n    model.compile(\\n        optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\\n        loss=\\\"mse\\\",\\n        metrics=[\\\"mae\\\", \\\"mse\\\"],\\n    )\\n\\n    return model\\n\\n\\n# rmse pra avalia\\u00e7\\u00e3o, nao para loss\";\n                var nbb_formatted_code = \"def model_builder(hp):\\n    hp_unit_1 = hp.Int(\\\"unit_1\\\", min_value=16, max_value=64, step=1)\\n    activationL = [\\n        \\\"relu\\\",\\n        \\\"sigmoid\\\",\\n        \\\"softplus\\\",\\n        \\\"softsign\\\",\\n        \\\"tanh\\\",\\n        \\\"selu\\\",\\n        \\\"elu\\\",\\n        \\\"relu\\\",\\n    ]\\n    activation_choice = hp.Choice(\\\"activation\\\", values=activationL)\\n    hp_learning_rate = hp.Choice(\\\"learning_rate\\\", values=[1e-2, 1e-3, 1e-4])\\n\\n    model = keras.models.Sequential(\\n        [\\n            layers.LSTM(\\n                units=hp_unit_1,\\n                return_sequences=True,\\n                input_shape=(36, 1),\\n                activation=activation_choice,\\n            ),\\n            # tf.keras.layers.Flatten(),\\n            layers.Dense(units=1, activation=\\\"linear\\\"),\\n        ]\\n    )\\n\\n    model.compile(\\n        optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\\n        loss=\\\"mse\\\",\\n        metrics=[\\\"mae\\\", \\\"mse\\\"],\\n    )\\n\\n    return model\\n\\n\\n# rmse pra avalia\\u00e7\\u00e3o, nao para loss\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def model_builder(hp):\n",
    "    hp_unit_1 = hp.Int(\"unit_1\", min_value=16, max_value=64, step=1)\n",
    "    activationL = [\n",
    "        \"relu\",\n",
    "        \"sigmoid\",\n",
    "        \"softplus\",\n",
    "        \"softsign\",\n",
    "        \"tanh\",\n",
    "        \"selu\",\n",
    "        \"elu\",\n",
    "        \"relu\",\n",
    "    ]\n",
    "    activation_choice = hp.Choice(\"activation\", values=activationL)\n",
    "    hp_learning_rate = hp.Choice(\"learning_rate\", values=[1e-2, 1e-3, 1e-4])\n",
    "\n",
    "    model = keras.models.Sequential(\n",
    "        [\n",
    "            layers.LSTM(\n",
    "                units=hp_unit_1,\n",
    "                return_sequences=True,\n",
    "                input_shape=(36, 1),\n",
    "                activation=activation_choice,\n",
    "            ),\n",
    "            # tf.keras.layers.Flatten(),\n",
    "            layers.Dense(units=1, activation=\"linear\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "        loss=\"mse\",\n",
    "        metrics=[\"mae\", \"mse\"],\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# rmse pra avaliação, nao para loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecionando a melhor epoca do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 7;\n                var nbb_unformatted_code = \"def repetir(SAVE_TIME, EPOCHS, epochs_to_search, TYPE_MODEL):\\n    best_hps = None\\n    history = None\\n    bst_model_path = None\\n    tuner = None\\n\\n    tuner = kt.Hyperband(\\n        model_builder,\\n        objective=\\\"val_mse\\\",\\n        max_epochs=10,\\n        factor=3,\\n        directory=\\\"logs\\\",\\n        project_name=f\\\"{TYPE_MODEL}_{SAVE_TIME}_hyper_parameters\\\",\\n    )\\n\\n    # Buscando hyper parametros\\n    tuner.search(\\n        train_dataset,\\n        train_labels,\\n        epochs=epochs_to_search,\\n        validation_split=0.2,\\n        verbose=0,\\n    )\\n\\n    best_hps = tuner.get_best_hyperparameters(num_trials=100)[0]\\n\\n    # Build the model with the optimal hyperparameters and train it on the data for 50 epochs\\n    bst_model_path = f\\\"Models/{TYPE_MODEL}/model_{TYPE_MODEL}_{SAVE_TIME}.h5\\\"\\n    model_checkpoint = ModelCheckpoint(\\n        bst_model_path, save_best_only=True, monitor=\\\"val_mse\\\", mode=\\\"min\\\"\\n    )\\n\\n    model = tuner.hypermodel.build(best_hps)\\n    history = model.fit(\\n        train_dataset,\\n        train_labels,\\n        epochs=EPOCHS,\\n        validation_split=0.2,\\n        verbose=0,\\n        callbacks=([model_checkpoint]),\\n    )\\n\\n    # Select the best epoch,\\n    val_mse_per_epoch = history.history[\\\"val_mse\\\"]\\n    best_epoch = val_mse_per_epoch.index(min(val_mse_per_epoch)) + 1\\n\\n    # Saving results in lists\\n    get_results(history, best_hps, bst_model_path)\";\n                var nbb_formatted_code = \"def repetir(SAVE_TIME, EPOCHS, epochs_to_search, TYPE_MODEL):\\n    best_hps = None\\n    history = None\\n    bst_model_path = None\\n    tuner = None\\n\\n    tuner = kt.Hyperband(\\n        model_builder,\\n        objective=\\\"val_mse\\\",\\n        max_epochs=10,\\n        factor=3,\\n        directory=\\\"logs\\\",\\n        project_name=f\\\"{TYPE_MODEL}_{SAVE_TIME}_hyper_parameters\\\",\\n    )\\n\\n    # Buscando hyper parametros\\n    tuner.search(\\n        train_dataset,\\n        train_labels,\\n        epochs=epochs_to_search,\\n        validation_split=0.2,\\n        verbose=0,\\n    )\\n\\n    best_hps = tuner.get_best_hyperparameters(num_trials=100)[0]\\n\\n    # Build the model with the optimal hyperparameters and train it on the data for 50 epochs\\n    bst_model_path = f\\\"Models/{TYPE_MODEL}/model_{TYPE_MODEL}_{SAVE_TIME}.h5\\\"\\n    model_checkpoint = ModelCheckpoint(\\n        bst_model_path, save_best_only=True, monitor=\\\"val_mse\\\", mode=\\\"min\\\"\\n    )\\n\\n    model = tuner.hypermodel.build(best_hps)\\n    history = model.fit(\\n        train_dataset,\\n        train_labels,\\n        epochs=EPOCHS,\\n        validation_split=0.2,\\n        verbose=0,\\n        callbacks=([model_checkpoint]),\\n    )\\n\\n    # Select the best epoch,\\n    val_mse_per_epoch = history.history[\\\"val_mse\\\"]\\n    best_epoch = val_mse_per_epoch.index(min(val_mse_per_epoch)) + 1\\n\\n    # Saving results in lists\\n    get_results(history, best_hps, bst_model_path)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def repetir(SAVE_TIME, EPOCHS, epochs_to_search, TYPE_MODEL):\n",
    "    best_hps = None\n",
    "    history = None\n",
    "    bst_model_path = None\n",
    "    tuner = None\n",
    "\n",
    "    tuner = kt.Hyperband(\n",
    "        model_builder,\n",
    "        objective=\"val_mse\",\n",
    "        max_epochs=10,\n",
    "        factor=3,\n",
    "        directory=\"logs\",\n",
    "        project_name=f\"{TYPE_MODEL}_{SAVE_TIME}_hyper_parameters\",\n",
    "    )\n",
    "\n",
    "    # Buscando hyper parametros\n",
    "    tuner.search(\n",
    "        train_dataset,\n",
    "        train_labels,\n",
    "        epochs=epochs_to_search,\n",
    "        validation_split=0.2,\n",
    "        verbose=0,\n",
    "    )\n",
    "\n",
    "    best_hps = tuner.get_best_hyperparameters(num_trials=100)[0]\n",
    "\n",
    "    # Build the model with the optimal hyperparameters and train it on the data for 50 epochs\n",
    "    bst_model_path = f\"Models/{TYPE_MODEL}/model_{TYPE_MODEL}_{SAVE_TIME}.h5\"\n",
    "    model_checkpoint = ModelCheckpoint(\n",
    "        bst_model_path, save_best_only=True, monitor=\"val_mse\", mode=\"min\"\n",
    "    )\n",
    "\n",
    "    model = tuner.hypermodel.build(best_hps)\n",
    "    history = model.fit(\n",
    "        train_dataset,\n",
    "        train_labels,\n",
    "        epochs=EPOCHS,\n",
    "        validation_split=0.2,\n",
    "        verbose=0,\n",
    "        callbacks=([model_checkpoint]),\n",
    "    )\n",
    "\n",
    "    # Select the best epoch,\n",
    "    val_mse_per_epoch = history.history[\"val_mse\"]\n",
    "    best_epoch = val_mse_per_epoch.index(min(val_mse_per_epoch)) + 1\n",
    "\n",
    "    # Saving results in lists\n",
    "    get_results(history, best_hps, bst_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\arthu\\Documents\\GitHub\\TCC_Stock_Predictions\\Experiments\\Experimentos_LSTM.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/arthu/Documents/GitHub/TCC_Stock_Predictions/Experiments/Experimentos_LSTM.ipynb#X13sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(REPETICAO):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/arthu/Documents/GitHub/TCC_Stock_Predictions/Experiments/Experimentos_LSTM.ipynb#X13sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     SAVE_TIME \u001b[39m=\u001b[39m datetime\u001b[39m.\u001b[39mdatetime\u001b[39m.\u001b[39mstrftime(datetime\u001b[39m.\u001b[39mdatetime\u001b[39m.\u001b[39mnow(), \u001b[39m\"\u001b[39m\u001b[39m%\u001b[39m\u001b[39my_\u001b[39m\u001b[39m%\u001b[39m\u001b[39mm_\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m%\u001b[39m\u001b[39mHh\u001b[39m\u001b[39m%\u001b[39m\u001b[39mMm\u001b[39m\u001b[39m%\u001b[39m\u001b[39mS\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/arthu/Documents/GitHub/TCC_Stock_Predictions/Experiments/Experimentos_LSTM.ipynb#X13sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     repetir(SAVE_TIME, EPOCHS, epochs_to_search, TYPE_MODEL)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/arthu/Documents/GitHub/TCC_Stock_Predictions/Experiments/Experimentos_LSTM.ipynb#X13sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m df_resultados \u001b[39m=\u001b[39m save_df_results(SAVE_TIME)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/arthu/Documents/GitHub/TCC_Stock_Predictions/Experiments/Experimentos_LSTM.ipynb#X13sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m df_resultados\n",
      "\u001b[1;32mc:\\Users\\arthu\\Documents\\GitHub\\TCC_Stock_Predictions\\Experiments\\Experimentos_LSTM.ipynb Cell 11\u001b[0m in \u001b[0;36mrepetir\u001b[1;34m(SAVE_TIME, EPOCHS, epochs_to_search, TYPE_MODEL)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/arthu/Documents/GitHub/TCC_Stock_Predictions/Experiments/Experimentos_LSTM.ipynb#X13sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m model_checkpoint \u001b[39m=\u001b[39m ModelCheckpoint(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/arthu/Documents/GitHub/TCC_Stock_Predictions/Experiments/Experimentos_LSTM.ipynb#X13sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     bst_model_path, save_best_only\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, monitor\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mval_mse\u001b[39m\u001b[39m\"\u001b[39m, mode\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmin\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/arthu/Documents/GitHub/TCC_Stock_Predictions/Experiments/Experimentos_LSTM.ipynb#X13sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/arthu/Documents/GitHub/TCC_Stock_Predictions/Experiments/Experimentos_LSTM.ipynb#X13sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m model \u001b[39m=\u001b[39m tuner\u001b[39m.\u001b[39mhypermodel\u001b[39m.\u001b[39mbuild(best_hps)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/arthu/Documents/GitHub/TCC_Stock_Predictions/Experiments/Experimentos_LSTM.ipynb#X13sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/arthu/Documents/GitHub/TCC_Stock_Predictions/Experiments/Experimentos_LSTM.ipynb#X13sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m     train_dataset,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/arthu/Documents/GitHub/TCC_Stock_Predictions/Experiments/Experimentos_LSTM.ipynb#X13sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m     train_labels,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/arthu/Documents/GitHub/TCC_Stock_Predictions/Experiments/Experimentos_LSTM.ipynb#X13sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m     epochs\u001b[39m=\u001b[39;49mEPOCHS,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/arthu/Documents/GitHub/TCC_Stock_Predictions/Experiments/Experimentos_LSTM.ipynb#X13sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m     validation_split\u001b[39m=\u001b[39;49m\u001b[39m0.2\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/arthu/Documents/GitHub/TCC_Stock_Predictions/Experiments/Experimentos_LSTM.ipynb#X13sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/arthu/Documents/GitHub/TCC_Stock_Predictions/Experiments/Experimentos_LSTM.ipynb#X13sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m     callbacks\u001b[39m=\u001b[39;49m([model_checkpoint]),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/arthu/Documents/GitHub/TCC_Stock_Predictions/Experiments/Experimentos_LSTM.ipynb#X13sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/arthu/Documents/GitHub/TCC_Stock_Predictions/Experiments/Experimentos_LSTM.ipynb#X13sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m \u001b[39m# Select the best epoch,\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/arthu/Documents/GitHub/TCC_Stock_Predictions/Experiments/Experimentos_LSTM.ipynb#X13sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m val_mse_per_epoch \u001b[39m=\u001b[39m history\u001b[39m.\u001b[39mhistory[\u001b[39m\"\u001b[39m\u001b[39mval_mse\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\arthu\\.conda\\envs\\pystock\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\arthu\\.conda\\envs\\pystock\\lib\\site-packages\\keras\\engine\\training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1402\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1403\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   1404\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   1405\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[0;32m   1406\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m   1407\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m   1408\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1409\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1410\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1411\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\arthu\\.conda\\envs\\pystock\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\arthu\\.conda\\envs\\pystock\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\arthu\\.conda\\envs\\pystock\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\arthu\\.conda\\envs\\pystock\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2450\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2451\u001b[0m   (graph_function,\n\u001b[0;32m   2452\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2453\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2454\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\arthu\\.conda\\envs\\pystock\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1856\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1857\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1858\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1859\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1860\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1861\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1862\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1863\u001b[0m     args,\n\u001b[0;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1865\u001b[0m     executing_eagerly)\n\u001b[0;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\arthu\\.conda\\envs\\pystock\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    496\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 497\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    498\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    499\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    500\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    501\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    502\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    503\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    504\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    505\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    506\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    509\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    510\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\arthu\\.conda\\envs\\pystock\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 8;\n                var nbb_unformatted_code = \"TYPE_MODEL = \\\"LSTM\\\"\\nREPETICAO = 2\\nEPOCHS = 500\\nepochs_to_search = 3\\n\\nfor i in range(REPETICAO):\\n    SAVE_TIME = datetime.datetime.strftime(datetime.datetime.now(), \\\"%y_%m_%d_%Hh%Mm%S\\\")\\n    repetir(SAVE_TIME, EPOCHS, epochs_to_search, TYPE_MODEL)\\n\\ndf_resultados = save_df_results(SAVE_TIME)\\ndf_resultados\";\n                var nbb_formatted_code = \"TYPE_MODEL = \\\"LSTM\\\"\\nREPETICAO = 2\\nEPOCHS = 500\\nepochs_to_search = 3\\n\\nfor i in range(REPETICAO):\\n    SAVE_TIME = datetime.datetime.strftime(datetime.datetime.now(), \\\"%y_%m_%d_%Hh%Mm%S\\\")\\n    repetir(SAVE_TIME, EPOCHS, epochs_to_search, TYPE_MODEL)\\n\\ndf_resultados = save_df_results(SAVE_TIME)\\ndf_resultados\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TYPE_MODEL = \"LSTM\"\n",
    "REPETICAO = 10\n",
    "EPOCHS = 500\n",
    "epochs_to_search = 3\n",
    "\n",
    "for i in range(REPETICAO):\n",
    "    SAVE_TIME = datetime.datetime.strftime(datetime.datetime.now(), \"%y_%m_%d_%Hh%Mm%S\")\n",
    "    repetir(SAVE_TIME, EPOCHS, epochs_to_search, TYPE_MODEL)\n",
    "\n",
    "df_resultados = save_df_results(SAVE_TIME)\n",
    "df_resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'keras_tuner' has no attribute 'results_summary'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\arthu\\Documents\\GitHub\\TCC_Stock_Predictions\\Experiments\\Experimentos_LSTM.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/arthu/Documents/GitHub/TCC_Stock_Predictions/Experiments/Experimentos_LSTM.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m kt\u001b[39m.\u001b[39;49mresults_summary(num_trials\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'keras_tuner' has no attribute 'results_summary'"
     ]
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 9;\n                var nbb_unformatted_code = \"kt.results_summary(num_trials=10)\";\n                var nbb_formatted_code = \"kt.results_summary(num_trials=10)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "kt.results_summary(num_trials=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best epoch: %d\" % (best_epoch,))\n",
    "print(f'val_mae: {min(history.history[\"val_mae\"])}')\n",
    "print(f'val_mse: {min(history.history[\"val_mse\"])}')\n",
    "\n",
    "print(f'n_filter_1: {best_hps.get(\"n_filter_1\")}')\n",
    "# print(f'n_filter_2: {best_hps.get(\"n_filter_2\")}')\n",
    "print(f'kernel_size_1: {best_hps.get(\"kernel_size_1\")}')\n",
    "# print(f'kernel_size_2: {best_hps.get(\"kernel_size_2\")}')\n",
    "\n",
    "# print(f'unit_3: {best_hps.get(\"unit_3\")}')\n",
    "# print(f'unit_4: {best_hps.get(\"unit_4\")}')\n",
    "print(f'learning_rate: {best_hps.get(\"learning_rate\")}')\n",
    "print(f'activation: {best_hps.get(\"activation\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for REPETICAO, value in enumerate((df_results)):\n",
    "df_results.loc[REPETICAO, \"best_model_path\"] = bst_model_path\n",
    "df_results.loc[REPETICAO, \"best_epoch\"] = best_epoch\n",
    "df_results.loc[REPETICAO, \"val_mae\"] = min(history.history[\"val_mae\"])\n",
    "df_results.loc[REPETICAO, \"val_mse\"] = min(history.history[\"val_mse\"])\n",
    "df_results.loc[REPETICAO, \"n_filter_1\"] = best_hps.get(\"n_filter_1\")\n",
    "df_results.loc[REPETICAO, \"n_filter_2\"] = None\n",
    "df_results.loc[REPETICAO, \"kernel_size_1\"] = best_hps.get(\"kernel_size_1\")\n",
    "df_results.loc[REPETICAO, \"kernel_size_2\"] = None\n",
    "df_results.loc[REPETICAO, \"learning_rate\"] = best_hps.get(\"learning_rate\")\n",
    "df_results.loc[REPETICAO, \"activation\"] = best_hps.get(\"activation\")\n",
    "\n",
    "df_results\n",
    "# bst_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.teste()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.to_csv(\n",
    "    f\"Parameter_{TYPE_MODEL}\",\n",
    "    header=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinando modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hypermodel = tuner.hypermodel.build(best_hps)\n",
    "# history = hypermodel.fit(train_dataset, train_labels, epochs=best_epoch, validation_split=0.2, verbose=1)\n",
    "\n",
    "# # ja pega o modelo na melhor epoca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_result = model.evaluate(test_dataset, test_labels)\n",
    "print(\"[test loss, test accuracy]:\", eval_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avaliando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f'train_dataset: {train_dataset.columns()} \\n')\n",
    "# print(f'valid_dataset: {valid_dataset.columns()} \\n')\n",
    "# print(f'test_dataset: {test_dataset.columns()} \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = pd.DataFrame(history.history)\n",
    "hist[\"epoch\"] = history.epoch\n",
    "hist.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Min MSE: {hist.mse.min()}\")\n",
    "print(f\"Min Val_MSE: {hist.val_mse.min()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    hist = pd.DataFrame(history.history)\n",
    "    hist[\"epoch\"] = history.epoch\n",
    "\n",
    "    plt.figure()\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Mean Abs Error [ibova_0]\")\n",
    "    plt.plot(hist[\"epoch\"], hist[\"mae\"], label=\"Train Error\")\n",
    "    plt.plot(hist[\"epoch\"], hist[\"val_mae\"], label=\"Val Error\")\n",
    "    plt.ylim([0, 1])\n",
    "    plt.legend()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Mean Square Error [$ibova_0^2$]\")\n",
    "    plt.plot(hist[\"epoch\"], hist[\"mse\"], label=\"Train Error\")\n",
    "    plt.plot(hist[\"epoch\"], hist[\"val_mse\"], label=\"Val Error\")\n",
    "    plt.ylim([0, 1])\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Realizando as previsões"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = model.predict(test_dataset).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avaliando as previsões:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_test_labels():\n",
    "    # Imprimindo valores reais\n",
    "    plt.plot(test_labels, color=\"r\", label=\"ibova_REAL\")\n",
    "    plt.xlabel(\"Dates\")\n",
    "    plt.ylabel(\"Variation ROC\")\n",
    "    plt.title(\"ibova_REAL\")\n",
    "    plt.legend()\n",
    "\n",
    "\n",
    "def show_model_predictions():\n",
    "    # Imprimindo previsoes\n",
    "    plt.plot(test_predictions, color=\"g\", label=\"predictions_MODEL\")\n",
    "    plt.xlabel(\"Dates\")\n",
    "    plt.ylabel(\"Variation ROC\")\n",
    "    plt.title(\"predictions_MODEL\")\n",
    "    plt.legend()\n",
    "\n",
    "\n",
    "def show_compare_graph():\n",
    "    # Predictt X Real values\n",
    "    plt.plot(test_labels, color=\"r\", label=\"ibova_REAL\")\n",
    "    plt.plot(test_predictions, color=\"g\", label=\"predictions_MODEL\")\n",
    "    plt.xlabel(\"Dates\")\n",
    "    plt.ylabel(\"Variation ROC\")\n",
    "    plt.title(\"Predict X Real values\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def show_true_predict_values():\n",
    "    plt.figure(figsize=(24, 4))\n",
    "    plt.scatter(test_labels, test_predictions)\n",
    "    plt.xlabel(\"True Values [ibova_0]\")\n",
    "    plt.ylabel(\"Predictions [ibova_0]\")\n",
    "    plt.axis(\"equal\")\n",
    "    plt.axis(\"square\")\n",
    "    plt.xlim([0, plt.xlim()[1]])\n",
    "    plt.ylim([0, plt.ylim()[1]])\n",
    "    _ = plt.plot([-100, 100], [-100, 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_compare_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_model_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = f'mlp_unit_1({best_hps.get(\"unit_1\")})unit_2({best_hps.get(\"unit_2\")})unit_3({best_hps.get(\"unit_3\")})unit_4({best_hps.get(\"unit_4\")})_learning({best_hps.get(\"learning_rate\")})_activation({best_hps.get(\"activation\")})'\n",
    "model_name\n",
    "model.save(f\"models/mlp/{model_name}date_{save_time}.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analisando Medias:\n",
    "\n",
    "print(f\"Massa de predição: {test_predictions.mean()}\")\n",
    "print(f\"Massa inicial: {ibova_test.mean()}\")\n",
    "print(f\"Diferenças das médias: {ibova_test.mean() - test_predictions.mean()}\")\n",
    "\n",
    "# Add o RM_MSE medio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_time"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('pystock')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bc0c8eb905859abd75b389576d87e2ac71c748b72952270660ecc130aeb3e651"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
