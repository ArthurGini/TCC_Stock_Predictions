{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 1;\n                var nbb_unformatted_code = \"%load_ext nb_black\\n%load_ext lab_black\";\n                var nbb_formatted_code = \"%load_ext nb_black\\n%load_ext lab_black\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black\n",
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 2;\n                var nbb_unformatted_code = \"import pathlib\\nimport datetime\\n\\nimport matplotlib.pyplot as plt\\nimport pandas as pd\\nimport seaborn as sns\\n\\nimport tensorflow as tf\\nimport datetime\\n\\nfrom tensorflow import keras\\nfrom tensorflow.keras import layers\\n\\nfrom keras.callbacks import ModelCheckpoint\\nimport keras_tuner as kt\\n\\n# 60%\\nPATH_TREINO = \\\"../Data/3_Gold/Treino_all_stocks.csv\\\"\\nDF_TREINO = pd.read_csv(PATH_TREINO, sep=\\\",\\\")\\ntrain_dataset = DF_TREINO\\ntrain_dataset = train_dataset.drop(\\n    [\\n        \\\"oil_5\\\",\\n        \\\"usd_5\\\",\\n        \\\"abev_5\\\",\\n        \\\"jbs_5\\\",\\n        \\\"petr_5\\\",\\n        \\\"vale_5\\\",\\n    ],\\n    axis=1,\\n)\\ntrain_labels = train_dataset.pop(\\\"ibova_5\\\")\\n\\n# 20%\\nPATH_VALIDACAO = \\\"../Data/3_Gold/Validacao_all_stocks.csv\\\"\\nDF_VALIDACAO = pd.read_csv(PATH_VALIDACAO, sep=\\\",\\\")\\nvalid_dataset = DF_VALIDACAO\\nvalid_dataset = valid_dataset.drop(\\n    [\\n        \\\"ibova_5\\\",\\n        \\\"oil_5\\\",\\n        \\\"usd_5\\\",\\n        \\\"abev_5\\\",\\n        \\\"jbs_5\\\",\\n        \\\"petr_5\\\",\\n        \\\"vale_5\\\",\\n    ],\\n    axis=1,\\n)\\n# valid_labels = valid_dataset.pop('ibova_5')\\n\\n# 20%\\nPATH_TESTE = \\\"../Data/3_Gold/Teste_all_stocks.csv\\\"\\nDF_TESTE = pd.read_csv(PATH_TESTE, sep=\\\",\\\")\\ntest_dataset = DF_TESTE\\ntest_dataset = test_dataset.drop(\\n    [\\n        \\\"oil_5\\\",\\n        \\\"usd_5\\\",\\n        \\\"abev_5\\\",\\n        \\\"jbs_5\\\",\\n        \\\"petr_5\\\",\\n        \\\"vale_5\\\",\\n    ],\\n    axis=1,\\n)\\ntest_labels = test_dataset.pop(\\\"ibova_5\\\")\\n\\n\\\"\\\"\\\"\\n\\tResultado\\n\\\"\\\"\\\"\\nlist_activation = []\\nlist_best_epoch = []\\nlist_best_model_path = []\\nlist_hp_unit_1 = []\\nlist_hp_unit_2 = []\\nlist_hp_unit_3 = []\\nlist_hp_unit_4 = []\\nlist_kernel_size_1 = []\\nlist_kernel_size_2 = []\\nlist_learning_rate = []\\nlist_n_filter_1 = []\\nlist_n_filter_2 = []\\nlist_val_mae = []\\nlist_val_mse = []\";\n                var nbb_formatted_code = \"import pathlib\\nimport datetime\\n\\nimport matplotlib.pyplot as plt\\nimport pandas as pd\\nimport seaborn as sns\\n\\nimport tensorflow as tf\\nimport datetime\\n\\nfrom tensorflow import keras\\nfrom tensorflow.keras import layers\\n\\nfrom keras.callbacks import ModelCheckpoint\\nimport keras_tuner as kt\\n\\n# 60%\\nPATH_TREINO = \\\"../Data/3_Gold/Treino_all_stocks.csv\\\"\\nDF_TREINO = pd.read_csv(PATH_TREINO, sep=\\\",\\\")\\ntrain_dataset = DF_TREINO\\ntrain_dataset = train_dataset.drop(\\n    [\\n        \\\"oil_5\\\",\\n        \\\"usd_5\\\",\\n        \\\"abev_5\\\",\\n        \\\"jbs_5\\\",\\n        \\\"petr_5\\\",\\n        \\\"vale_5\\\",\\n    ],\\n    axis=1,\\n)\\ntrain_labels = train_dataset.pop(\\\"ibova_5\\\")\\n\\n# 20%\\nPATH_VALIDACAO = \\\"../Data/3_Gold/Validacao_all_stocks.csv\\\"\\nDF_VALIDACAO = pd.read_csv(PATH_VALIDACAO, sep=\\\",\\\")\\nvalid_dataset = DF_VALIDACAO\\nvalid_dataset = valid_dataset.drop(\\n    [\\n        \\\"ibova_5\\\",\\n        \\\"oil_5\\\",\\n        \\\"usd_5\\\",\\n        \\\"abev_5\\\",\\n        \\\"jbs_5\\\",\\n        \\\"petr_5\\\",\\n        \\\"vale_5\\\",\\n    ],\\n    axis=1,\\n)\\n# valid_labels = valid_dataset.pop('ibova_5')\\n\\n# 20%\\nPATH_TESTE = \\\"../Data/3_Gold/Teste_all_stocks.csv\\\"\\nDF_TESTE = pd.read_csv(PATH_TESTE, sep=\\\",\\\")\\ntest_dataset = DF_TESTE\\ntest_dataset = test_dataset.drop(\\n    [\\n        \\\"oil_5\\\",\\n        \\\"usd_5\\\",\\n        \\\"abev_5\\\",\\n        \\\"jbs_5\\\",\\n        \\\"petr_5\\\",\\n        \\\"vale_5\\\",\\n    ],\\n    axis=1,\\n)\\ntest_labels = test_dataset.pop(\\\"ibova_5\\\")\\n\\n\\\"\\\"\\\"\\n\\tResultado\\n\\\"\\\"\\\"\\nlist_activation = []\\nlist_best_epoch = []\\nlist_best_model_path = []\\nlist_hp_unit_1 = []\\nlist_hp_unit_2 = []\\nlist_hp_unit_3 = []\\nlist_hp_unit_4 = []\\nlist_kernel_size_1 = []\\nlist_kernel_size_2 = []\\nlist_learning_rate = []\\nlist_n_filter_1 = []\\nlist_n_filter_2 = []\\nlist_val_mae = []\\nlist_val_mse = []\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pathlib\n",
    "import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import keras_tuner as kt\n",
    "\n",
    "# 60%\n",
    "PATH_TREINO = \"../Data/3_Gold/Treino_all_stocks.csv\"\n",
    "DF_TREINO = pd.read_csv(PATH_TREINO, sep=\",\")\n",
    "train_dataset = DF_TREINO\n",
    "train_dataset = train_dataset.drop(\n",
    "    [\n",
    "        \"oil_5\",\n",
    "        \"usd_5\",\n",
    "        \"abev_5\",\n",
    "        \"jbs_5\",\n",
    "        \"petr_5\",\n",
    "        \"vale_5\",\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "train_labels = train_dataset.pop(\"ibova_5\")\n",
    "\n",
    "# 20%\n",
    "PATH_VALIDACAO = \"../Data/3_Gold/Validacao_all_stocks.csv\"\n",
    "DF_VALIDACAO = pd.read_csv(PATH_VALIDACAO, sep=\",\")\n",
    "valid_dataset = DF_VALIDACAO\n",
    "valid_dataset = valid_dataset.drop(\n",
    "    [\n",
    "        \"ibova_5\",\n",
    "        \"oil_5\",\n",
    "        \"usd_5\",\n",
    "        \"abev_5\",\n",
    "        \"jbs_5\",\n",
    "        \"petr_5\",\n",
    "        \"vale_5\",\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "# valid_labels = valid_dataset.pop('ibova_5')\n",
    "\n",
    "# 20%\n",
    "PATH_TESTE = \"../Data/3_Gold/Teste_all_stocks.csv\"\n",
    "DF_TESTE = pd.read_csv(PATH_TESTE, sep=\",\")\n",
    "test_dataset = DF_TESTE\n",
    "test_dataset = test_dataset.drop(\n",
    "    [\n",
    "        \"oil_5\",\n",
    "        \"usd_5\",\n",
    "        \"abev_5\",\n",
    "        \"jbs_5\",\n",
    "        \"petr_5\",\n",
    "        \"vale_5\",\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "test_labels = test_dataset.pop(\"ibova_5\")\n",
    "\n",
    "\"\"\"\n",
    "\tResultado\n",
    "\"\"\"\n",
    "list_activation = []\n",
    "list_best_epoch = []\n",
    "list_best_model_path = []\n",
    "list_hp_unit_1 = []\n",
    "list_hp_unit_2 = []\n",
    "list_hp_unit_3 = []\n",
    "list_hp_unit_4 = []\n",
    "list_kernel_size_1 = []\n",
    "list_kernel_size_2 = []\n",
    "list_learning_rate = []\n",
    "list_n_filter_1 = []\n",
    "list_n_filter_2 = []\n",
    "list_val_mae = []\n",
    "list_val_mse = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 3;\n                var nbb_unformatted_code = \"\\ndef repetir():\\n    EPOCHS = 500\\n    TYPE_MODEL = 'LSTM'\\n\\n    def model_builder(hp):\\n        hp_unit_1 = hp.Int(\\\"unit_1\\\", min_value=16, max_value=64, step=1)\\n        activationL = [\\n            \\\"relu\\\",\\n            \\\"sigmoid\\\",\\n            \\\"softplus\\\",\\n            \\\"softsign\\\",\\n            \\\"tanh\\\",\\n            \\\"selu\\\",\\n            \\\"elu\\\",\\n            \\\"exponential\\\",\\n            \\\"relu\\\",\\n        ]\\n        activation_choice = hp.Choice(\\\"activation\\\", values=activationL)\\n        hp_learning_rate = hp.Choice(\\\"learning_rate\\\", values=[1e-2, 1e-3, 1e-4])\\n\\n        model = keras.models.Sequential(\\n            [\\n                layers.LSTM(units=hp_unit_1, return_sequences=True, input_shape=(36, 1), activation = activationL),\\n                tf.keras.layers.Flatten(),\\n                layers.Dense(units=1, activation=\\\"linear\\\"),\\n            ]\\n        )\\n\\n        model.compile(\\n            optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\\n            loss=\\\"mse\\\",\\n            metrics=[\\\"mae\\\", \\\"mse\\\"],\\n        )\\n\\n        return model\\n\\n\\n    tuner = kt.Hyperband(\\n        model_builder,\\n        objective=\\\"val_mse\\\",\\n        max_epochs=50,\\n        factor=3,\\n        directory=\\\"logs\\\",\\n        project_name=\\\"hyper_parameters\\\",\\n    )\\n    # Build the model with the optimal hyperparameters and train it on the data for 50 epochs\\n    save_time = datetime.datetime.strftime(datetime.datetime.now(), \\\"%y_%m_%d_%Hh%Mm%S\\\")\\n\\n    bst_model_path = f\\\"Models/{TYPE_MODEL}/model_{save_time}.h5\\\"\\n    model_checkpoint = ModelCheckpoint(\\n        bst_model_path, save_best_only=True, monitor=\\\"val_mse\\\", mode=\\\"min\\\"\\n    )\\n\\n    best_hps = tuner.get_best_hyperparameters(num_trials=100)[0]\\n\\n    model = tuner.hypermodel.build(best_hps)\\n    history = model.fit(\\n        train_dataset,\\n        train_labels,\\n        epochs=EPOCHS,\\n        validation_split=0.2,\\n        verbose=0,\\n        callbacks=([model_checkpoint]),\\n    )\\n\\n    # Select the best epoch,\\n    val_mse_per_epoch = history.history[\\\"val_mse\\\"]\\n    best_epoch = val_mse_per_epoch.index(min(val_mse_per_epoch)) + 1\\n\\n    try:\\n        value_activation = best_hps.get(\\\"activation\\\")\\n    except:\\n        value_activation = None\\n    try:\\n        value_learning_rate = best_hps.get(\\\"learning_rate\\\")\\n    except:\\n        value_learning_rate = None\\n    try:\\n        value_unit_1 = best_hps.get(\\\"unit_1\\\")\\n    except:\\n        value_unit_1 = None\\n    try:\\n        value_unit_2 = best_hps.get(\\\"unit_2\\\")\\n    except:\\n        value_unit_2 = None\\n    try:\\n        value_unit_3 = best_hps.get(\\\"unit_3\\\")\\n    except:\\n        value_unit_3 = None\\n    try:\\n        value_unit_4 = best_hps.get(\\\"unit_4\\\")\\n    except:\\n        value_unit_4 = None\\n    try:\\n        value_kernel_size_1 = best_hps.get(\\\"kernel_size_1\\\")\\n    except:\\n        value_kernel_size_1 = None\\n    try:\\n        value_kernel_size_2 = best_hps.get(\\\"kernel_size_2\\\")\\n    except:\\n        value_kernel_size_2 = None\\n    try:\\n        value_n_filter_1 = best_hps.get(\\\"n_filter_1\\\")\\n    except:\\n        value_n_filter_1 = None\\n    try:\\n        value_n_filter_2 = best_hps.get(\\\"n_filter_2\\\")\\n    except:\\n        value_n_filter_2 = None\\n\\n    \\\"\\\"\\\"\\\"Repeticao MODEL.ipynb\\\"\\\"\\\"\\n\\n    def save_in_list(one_list, value=None):\\n        try:\\n            one_list.append(value)\\n            return one_list\\n        except:\\n            one_list.append(None)\\n            return one_list\\n\\n    save_in_list(list_activation, value_activation)\\n    save_in_list(list_best_epoch, best_epoch)\\n    save_in_list(list_best_model_path, bst_model_path)\\n    save_in_list(list_hp_unit_1, value_unit_1)\\n    save_in_list(list_hp_unit_2, value_unit_2)\\n    save_in_list(list_hp_unit_3, value_unit_3)\\n    save_in_list(list_hp_unit_4, value_unit_4)\\n    save_in_list(list_kernel_size_1, value_kernel_size_1)\\n    save_in_list(list_kernel_size_2, value_kernel_size_2)\\n    save_in_list(list_learning_rate, value_learning_rate)\\n    save_in_list(list_n_filter_1, value_n_filter_1)\\n    save_in_list(list_n_filter_2, value_n_filter_2)\\n    save_in_list(list_val_mae, min(history.history[\\\"val_mae\\\"]))\\n    save_in_list(list_val_mse, min(history.history[\\\"val_mse\\\"]))\";\n                var nbb_formatted_code = \"def repetir():\\n    EPOCHS = 500\\n    TYPE_MODEL = \\\"LSTM\\\"\\n\\n    def model_builder(hp):\\n        hp_unit_1 = hp.Int(\\\"unit_1\\\", min_value=16, max_value=64, step=1)\\n        activationL = [\\n            \\\"relu\\\",\\n            \\\"sigmoid\\\",\\n            \\\"softplus\\\",\\n            \\\"softsign\\\",\\n            \\\"tanh\\\",\\n            \\\"selu\\\",\\n            \\\"elu\\\",\\n            \\\"exponential\\\",\\n            \\\"relu\\\",\\n        ]\\n        activation_choice = hp.Choice(\\\"activation\\\", values=activationL)\\n        hp_learning_rate = hp.Choice(\\\"learning_rate\\\", values=[1e-2, 1e-3, 1e-4])\\n\\n        model = keras.models.Sequential(\\n            [\\n                layers.LSTM(\\n                    units=hp_unit_1,\\n                    return_sequences=True,\\n                    input_shape=(36, 1),\\n                    activation=activationL,\\n                ),\\n                tf.keras.layers.Flatten(),\\n                layers.Dense(units=1, activation=\\\"linear\\\"),\\n            ]\\n        )\\n\\n        model.compile(\\n            optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\\n            loss=\\\"mse\\\",\\n            metrics=[\\\"mae\\\", \\\"mse\\\"],\\n        )\\n\\n        return model\\n\\n    tuner = kt.Hyperband(\\n        model_builder,\\n        objective=\\\"val_mse\\\",\\n        max_epochs=50,\\n        factor=3,\\n        directory=\\\"logs\\\",\\n        project_name=\\\"hyper_parameters\\\",\\n    )\\n    # Build the model with the optimal hyperparameters and train it on the data for 50 epochs\\n    save_time = datetime.datetime.strftime(datetime.datetime.now(), \\\"%y_%m_%d_%Hh%Mm%S\\\")\\n\\n    bst_model_path = f\\\"Models/{TYPE_MODEL}/model_{save_time}.h5\\\"\\n    model_checkpoint = ModelCheckpoint(\\n        bst_model_path, save_best_only=True, monitor=\\\"val_mse\\\", mode=\\\"min\\\"\\n    )\\n\\n    best_hps = tuner.get_best_hyperparameters(num_trials=100)[0]\\n\\n    model = tuner.hypermodel.build(best_hps)\\n    history = model.fit(\\n        train_dataset,\\n        train_labels,\\n        epochs=EPOCHS,\\n        validation_split=0.2,\\n        verbose=0,\\n        callbacks=([model_checkpoint]),\\n    )\\n\\n    # Select the best epoch,\\n    val_mse_per_epoch = history.history[\\\"val_mse\\\"]\\n    best_epoch = val_mse_per_epoch.index(min(val_mse_per_epoch)) + 1\\n\\n    try:\\n        value_activation = best_hps.get(\\\"activation\\\")\\n    except:\\n        value_activation = None\\n    try:\\n        value_learning_rate = best_hps.get(\\\"learning_rate\\\")\\n    except:\\n        value_learning_rate = None\\n    try:\\n        value_unit_1 = best_hps.get(\\\"unit_1\\\")\\n    except:\\n        value_unit_1 = None\\n    try:\\n        value_unit_2 = best_hps.get(\\\"unit_2\\\")\\n    except:\\n        value_unit_2 = None\\n    try:\\n        value_unit_3 = best_hps.get(\\\"unit_3\\\")\\n    except:\\n        value_unit_3 = None\\n    try:\\n        value_unit_4 = best_hps.get(\\\"unit_4\\\")\\n    except:\\n        value_unit_4 = None\\n    try:\\n        value_kernel_size_1 = best_hps.get(\\\"kernel_size_1\\\")\\n    except:\\n        value_kernel_size_1 = None\\n    try:\\n        value_kernel_size_2 = best_hps.get(\\\"kernel_size_2\\\")\\n    except:\\n        value_kernel_size_2 = None\\n    try:\\n        value_n_filter_1 = best_hps.get(\\\"n_filter_1\\\")\\n    except:\\n        value_n_filter_1 = None\\n    try:\\n        value_n_filter_2 = best_hps.get(\\\"n_filter_2\\\")\\n    except:\\n        value_n_filter_2 = None\\n\\n    \\\"\\\"\\\"\\\"Repeticao MODEL.ipynb\\\"\\\"\\\"\\n\\n    def save_in_list(one_list, value=None):\\n        try:\\n            one_list.append(value)\\n            return one_list\\n        except:\\n            one_list.append(None)\\n            return one_list\\n\\n    save_in_list(list_activation, value_activation)\\n    save_in_list(list_best_epoch, best_epoch)\\n    save_in_list(list_best_model_path, bst_model_path)\\n    save_in_list(list_hp_unit_1, value_unit_1)\\n    save_in_list(list_hp_unit_2, value_unit_2)\\n    save_in_list(list_hp_unit_3, value_unit_3)\\n    save_in_list(list_hp_unit_4, value_unit_4)\\n    save_in_list(list_kernel_size_1, value_kernel_size_1)\\n    save_in_list(list_kernel_size_2, value_kernel_size_2)\\n    save_in_list(list_learning_rate, value_learning_rate)\\n    save_in_list(list_n_filter_1, value_n_filter_1)\\n    save_in_list(list_n_filter_2, value_n_filter_2)\\n    save_in_list(list_val_mae, min(history.history[\\\"val_mae\\\"]))\\n    save_in_list(list_val_mse, min(history.history[\\\"val_mse\\\"]))\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def repetir():\n",
    "    EPOCHS = 500\n",
    "    TYPE_MODEL = \"LSTM\"\n",
    "\n",
    "    def model_builder(hp):\n",
    "        hp_unit_1 = hp.Int(\"unit_1\", min_value=16, max_value=64, step=1)\n",
    "        activationL = [\n",
    "            \"relu\",\n",
    "            \"sigmoid\",\n",
    "            \"softplus\",\n",
    "            \"softsign\",\n",
    "            \"tanh\",\n",
    "            \"selu\",\n",
    "            \"elu\",\n",
    "            \"exponential\",\n",
    "            \"relu\"\n",
    "        ]\n",
    "        activation_choice = hp.Choice(\"activation\", values=activationL)\n",
    "        hp_learning_rate = hp.Choice(\"learning_rate\", values=[1e-2, 1e-3, 1e-4])\n",
    "\n",
    "        model = keras.models.Sequential(\n",
    "            [\n",
    "                layers.LSTM(\n",
    "                    units=hp_unit_1,\n",
    "                    return_sequences=True,\n",
    "                    input_shape=(36, 1),\n",
    "                    activation=activationL,\n",
    "                ),\n",
    "                tf.keras.layers.Flatten(),\n",
    "                layers.Dense(units=1, activation=\"linear\"),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "            loss=\"mse\",\n",
    "            metrics=[\"mae\", \"mse\"],\n",
    "        )\n",
    "\n",
    "        return model\n",
    "\n",
    "    tuner = kt.Hyperband(\n",
    "        model_builder,\n",
    "        objective=\"val_mse\",\n",
    "        max_epochs=50,\n",
    "        factor=3,\n",
    "        directory=\"logs\",\n",
    "        project_name=\"hyper_parameters\",\n",
    "    )\n",
    "    # Build the model with the optimal hyperparameters and train it on the data for 50 epochs\n",
    "    save_time = datetime.datetime.strftime(datetime.datetime.now(), \"%y_%m_%d_%Hh%Mm%S\")\n",
    "\n",
    "    bst_model_path = f\"Models/{TYPE_MODEL}/model_{save_time}.h5\"\n",
    "    model_checkpoint = ModelCheckpoint(\n",
    "        bst_model_path, save_best_only=True, monitor=\"val_mse\", mode=\"min\"\n",
    "    )\n",
    "\n",
    "    best_hps = tuner.get_best_hyperparameters(num_trials=100)[0]\n",
    "\n",
    "    model = tuner.hypermodel.build(best_hps)\n",
    "    history = model.fit(\n",
    "        train_dataset,\n",
    "        train_labels,\n",
    "        epochs=EPOCHS,\n",
    "        validation_split=0.2,\n",
    "        verbose=0,\n",
    "        callbacks=([model_checkpoint]),\n",
    "    )\n",
    "\n",
    "    # Select the best epoch,\n",
    "    val_mse_per_epoch = history.history[\"val_mse\"]\n",
    "    best_epoch = val_mse_per_epoch.index(min(val_mse_per_epoch)) + 1\n",
    "\n",
    "    try:\n",
    "        value_activation = best_hps.get(\"activation\")\n",
    "    except:\n",
    "        value_activation = None\n",
    "    try:\n",
    "        value_learning_rate = best_hps.get(\"learning_rate\")\n",
    "    except:\n",
    "        value_learning_rate = None\n",
    "    try:\n",
    "        value_unit_1 = best_hps.get(\"unit_1\")\n",
    "    except:\n",
    "        value_unit_1 = None\n",
    "    try:\n",
    "        value_unit_2 = best_hps.get(\"unit_2\")\n",
    "    except:\n",
    "        value_unit_2 = None\n",
    "    try:\n",
    "        value_unit_3 = best_hps.get(\"unit_3\")\n",
    "    except:\n",
    "        value_unit_3 = None\n",
    "    try:\n",
    "        value_unit_4 = best_hps.get(\"unit_4\")\n",
    "    except:\n",
    "        value_unit_4 = None\n",
    "    try:\n",
    "        value_kernel_size_1 = best_hps.get(\"kernel_size_1\")\n",
    "    except:\n",
    "        value_kernel_size_1 = None\n",
    "    try:\n",
    "        value_kernel_size_2 = best_hps.get(\"kernel_size_2\")\n",
    "    except:\n",
    "        value_kernel_size_2 = None\n",
    "    try:\n",
    "        value_n_filter_1 = best_hps.get(\"n_filter_1\")\n",
    "    except:\n",
    "        value_n_filter_1 = None\n",
    "    try:\n",
    "        value_n_filter_2 = best_hps.get(\"n_filter_2\")\n",
    "    except:\n",
    "        value_n_filter_2 = None\n",
    "\n",
    "    \"\"\"\"Repeticao MODEL.ipynb\"\"\"\n",
    "\n",
    "    def save_in_list(one_list, value=None):\n",
    "        try:\n",
    "            one_list.append(value)\n",
    "            return one_list\n",
    "        except:\n",
    "            one_list.append(None)\n",
    "            return one_list\n",
    "\n",
    "    save_in_list(list_activation, value_activation)\n",
    "    save_in_list(list_best_epoch, best_epoch)\n",
    "    save_in_list(list_best_model_path, bst_model_path)\n",
    "    save_in_list(list_hp_unit_1, value_unit_1)\n",
    "    save_in_list(list_hp_unit_2, value_unit_2)\n",
    "    save_in_list(list_hp_unit_3, value_unit_3)\n",
    "    save_in_list(list_hp_unit_4, value_unit_4)\n",
    "    save_in_list(list_kernel_size_1, value_kernel_size_1)\n",
    "    save_in_list(list_kernel_size_2, value_kernel_size_2)\n",
    "    save_in_list(list_learning_rate, value_learning_rate)\n",
    "    save_in_list(list_n_filter_1, value_n_filter_1)\n",
    "    save_in_list(list_n_filter_2, value_n_filter_2)\n",
    "    save_in_list(list_val_mae, min(history.history[\"val_mae\"]))\n",
    "    save_in_list(list_val_mse, min(history.history[\"val_mse\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Could not interpret activation function identifier: ['relu', 'sigmoid', 'softplus', 'softsign', 'tanh', 'selu', 'elu', 'exponential', 'relu']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\arthu\\Documents\\GitHub\\TCC_Stock_Predictions\\Experiments\\Experimentos_LSTM.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/arthu/Documents/GitHub/TCC_Stock_Predictions/Experiments/Experimentos_LSTM.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m10\u001b[39m):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/arthu/Documents/GitHub/TCC_Stock_Predictions/Experiments/Experimentos_LSTM.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     repetir()\n",
      "\u001b[1;32mc:\\Users\\arthu\\Documents\\GitHub\\TCC_Stock_Predictions\\Experiments\\Experimentos_LSTM.ipynb Cell 4\u001b[0m in \u001b[0;36mrepetir\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/arthu/Documents/GitHub/TCC_Stock_Predictions/Experiments/Experimentos_LSTM.ipynb#W3sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     model\u001b[39m.\u001b[39mcompile(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/arthu/Documents/GitHub/TCC_Stock_Predictions/Experiments/Experimentos_LSTM.ipynb#W3sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m         optimizer\u001b[39m=\u001b[39mkeras\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mAdam(learning_rate\u001b[39m=\u001b[39mhp_learning_rate),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/arthu/Documents/GitHub/TCC_Stock_Predictions/Experiments/Experimentos_LSTM.ipynb#W3sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m         loss\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmse\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/arthu/Documents/GitHub/TCC_Stock_Predictions/Experiments/Experimentos_LSTM.ipynb#W3sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m         metrics\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mmae\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmse\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/arthu/Documents/GitHub/TCC_Stock_Predictions/Experiments/Experimentos_LSTM.ipynb#W3sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m     )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/arthu/Documents/GitHub/TCC_Stock_Predictions/Experiments/Experimentos_LSTM.ipynb#W3sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m model\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/arthu/Documents/GitHub/TCC_Stock_Predictions/Experiments/Experimentos_LSTM.ipynb#W3sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m tuner \u001b[39m=\u001b[39m kt\u001b[39m.\u001b[39;49mHyperband(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/arthu/Documents/GitHub/TCC_Stock_Predictions/Experiments/Experimentos_LSTM.ipynb#W3sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m     model_builder,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/arthu/Documents/GitHub/TCC_Stock_Predictions/Experiments/Experimentos_LSTM.ipynb#W3sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m     objective\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mval_mse\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/arthu/Documents/GitHub/TCC_Stock_Predictions/Experiments/Experimentos_LSTM.ipynb#W3sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m     max_epochs\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/arthu/Documents/GitHub/TCC_Stock_Predictions/Experiments/Experimentos_LSTM.ipynb#W3sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m     factor\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/arthu/Documents/GitHub/TCC_Stock_Predictions/Experiments/Experimentos_LSTM.ipynb#W3sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m     directory\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mlogs\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/arthu/Documents/GitHub/TCC_Stock_Predictions/Experiments/Experimentos_LSTM.ipynb#W3sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m     project_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mhyper_parameters\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/arthu/Documents/GitHub/TCC_Stock_Predictions/Experiments/Experimentos_LSTM.ipynb#W3sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/arthu/Documents/GitHub/TCC_Stock_Predictions/Experiments/Experimentos_LSTM.ipynb#W3sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m \u001b[39m# Build the model with the optimal hyperparameters and train it on the data for 50 epochs\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/arthu/Documents/GitHub/TCC_Stock_Predictions/Experiments/Experimentos_LSTM.ipynb#W3sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m save_time \u001b[39m=\u001b[39m datetime\u001b[39m.\u001b[39mdatetime\u001b[39m.\u001b[39mstrftime(datetime\u001b[39m.\u001b[39mdatetime\u001b[39m.\u001b[39mnow(), \u001b[39m\"\u001b[39m\u001b[39m%\u001b[39m\u001b[39my_\u001b[39m\u001b[39m%\u001b[39m\u001b[39mm_\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m%\u001b[39m\u001b[39mHh\u001b[39m\u001b[39m%\u001b[39m\u001b[39mMm\u001b[39m\u001b[39m%\u001b[39m\u001b[39mS\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\arthu\\.conda\\envs\\pystock\\lib\\site-packages\\keras_tuner\\tuners\\hyperband.py:375\u001b[0m, in \u001b[0;36mHyperband.__init__\u001b[1;34m(self, hypermodel, objective, max_epochs, factor, hyperband_iterations, seed, hyperparameters, tune_new_entries, allow_new_entries, **kwargs)\u001b[0m\n\u001b[0;32m    352\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[0;32m    353\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    354\u001b[0m     hypermodel\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    363\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[0;32m    364\u001b[0m ):\n\u001b[0;32m    365\u001b[0m     oracle \u001b[39m=\u001b[39m HyperbandOracle(\n\u001b[0;32m    366\u001b[0m         objective,\n\u001b[0;32m    367\u001b[0m         max_epochs\u001b[39m=\u001b[39mmax_epochs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    373\u001b[0m         allow_new_entries\u001b[39m=\u001b[39mallow_new_entries,\n\u001b[0;32m    374\u001b[0m     )\n\u001b[1;32m--> 375\u001b[0m     \u001b[39msuper\u001b[39;49m(Hyperband, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\n\u001b[0;32m    376\u001b[0m         oracle\u001b[39m=\u001b[39;49moracle, hypermodel\u001b[39m=\u001b[39;49mhypermodel, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[0;32m    377\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\arthu\\.conda\\envs\\pystock\\lib\\site-packages\\keras_tuner\\engine\\tuner.py:110\u001b[0m, in \u001b[0;36mTuner.__init__\u001b[1;34m(self, oracle, hypermodel, max_model_size, optimizer, loss, metrics, distribution_strategy, directory, project_name, logger, tuner_id, overwrite, executions_per_trial)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[39mif\u001b[39;00m hypermodel \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39mrun_trial \u001b[39mis\u001b[39;00m Tuner\u001b[39m.\u001b[39mrun_trial:\n\u001b[0;32m    103\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    104\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mReceived `hypermodel=None`. We only allow not specifying \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    105\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`hypermodel` if the user defines the search space in \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    106\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`Tuner.run_trial()` by subclassing a `Tuner` class without \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    107\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39musing a `HyperModel` instance.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    108\u001b[0m     )\n\u001b[1;32m--> 110\u001b[0m \u001b[39msuper\u001b[39;49m(Tuner, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\n\u001b[0;32m    111\u001b[0m     oracle\u001b[39m=\u001b[39;49moracle,\n\u001b[0;32m    112\u001b[0m     hypermodel\u001b[39m=\u001b[39;49mhypermodel,\n\u001b[0;32m    113\u001b[0m     directory\u001b[39m=\u001b[39;49mdirectory,\n\u001b[0;32m    114\u001b[0m     project_name\u001b[39m=\u001b[39;49mproject_name,\n\u001b[0;32m    115\u001b[0m     logger\u001b[39m=\u001b[39;49mlogger,\n\u001b[0;32m    116\u001b[0m     overwrite\u001b[39m=\u001b[39;49moverwrite,\n\u001b[0;32m    117\u001b[0m )\n\u001b[0;32m    119\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_model_size \u001b[39m=\u001b[39m max_model_size\n\u001b[0;32m    120\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer \u001b[39m=\u001b[39m optimizer\n",
      "File \u001b[1;32mc:\\Users\\arthu\\.conda\\envs\\pystock\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py:103\u001b[0m, in \u001b[0;36mBaseTuner.__init__\u001b[1;34m(self, oracle, hypermodel, directory, project_name, logger, overwrite)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlogger \u001b[39m=\u001b[39m logger\n\u001b[0;32m    101\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_display \u001b[39m=\u001b[39m tuner_utils\u001b[39m.\u001b[39mDisplay(oracle\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moracle)\n\u001b[1;32m--> 103\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_populate_initial_space()\n\u001b[0;32m    105\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m overwrite \u001b[39mand\u001b[39;00m tf\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mgfile\u001b[39m.\u001b[39mexists(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_tuner_fname()):\n\u001b[0;32m    106\u001b[0m     tf\u001b[39m.\u001b[39mget_logger()\u001b[39m.\u001b[39minfo(\n\u001b[0;32m    107\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mReloading Tuner from \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_tuner_fname())\n\u001b[0;32m    108\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\arthu\\.conda\\envs\\pystock\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py:135\u001b[0m, in \u001b[0;36mBaseTuner._populate_initial_space\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    132\u001b[0m scopes_once_active \u001b[39m=\u001b[39m []\n\u001b[0;32m    134\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m--> 135\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhypermodel\u001b[39m.\u001b[39;49mbuild(hp)\n\u001b[0;32m    137\u001b[0m     \u001b[39m# Update the recored scopes.\u001b[39;00m\n\u001b[0;32m    138\u001b[0m     \u001b[39mfor\u001b[39;00m conditions \u001b[39min\u001b[39;00m hp\u001b[39m.\u001b[39mactive_scopes:\n",
      "\u001b[1;32mc:\\Users\\arthu\\Documents\\GitHub\\TCC_Stock_Predictions\\Experiments\\Experimentos_LSTM.ipynb Cell 4\u001b[0m in \u001b[0;36mrepetir.<locals>.model_builder\u001b[1;34m(hp)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/arthu/Documents/GitHub/TCC_Stock_Predictions/Experiments/Experimentos_LSTM.ipynb#W3sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m activation_choice \u001b[39m=\u001b[39m hp\u001b[39m.\u001b[39mChoice(\u001b[39m\"\u001b[39m\u001b[39mactivation\u001b[39m\u001b[39m\"\u001b[39m, values\u001b[39m=\u001b[39mactivationL)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/arthu/Documents/GitHub/TCC_Stock_Predictions/Experiments/Experimentos_LSTM.ipynb#W3sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m hp_learning_rate \u001b[39m=\u001b[39m hp\u001b[39m.\u001b[39mChoice(\u001b[39m\"\u001b[39m\u001b[39mlearning_rate\u001b[39m\u001b[39m\"\u001b[39m, values\u001b[39m=\u001b[39m[\u001b[39m1e-2\u001b[39m, \u001b[39m1e-3\u001b[39m, \u001b[39m1e-4\u001b[39m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/arthu/Documents/GitHub/TCC_Stock_Predictions/Experiments/Experimentos_LSTM.ipynb#W3sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m model \u001b[39m=\u001b[39m keras\u001b[39m.\u001b[39mmodels\u001b[39m.\u001b[39mSequential(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/arthu/Documents/GitHub/TCC_Stock_Predictions/Experiments/Experimentos_LSTM.ipynb#W3sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     [\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/arthu/Documents/GitHub/TCC_Stock_Predictions/Experiments/Experimentos_LSTM.ipynb#W3sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m         layers\u001b[39m.\u001b[39;49mLSTM(units\u001b[39m=\u001b[39;49mhp_unit_1, return_sequences\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, input_shape\u001b[39m=\u001b[39;49m(\u001b[39m36\u001b[39;49m, \u001b[39m1\u001b[39;49m), activation \u001b[39m=\u001b[39;49m activationL),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/arthu/Documents/GitHub/TCC_Stock_Predictions/Experiments/Experimentos_LSTM.ipynb#W3sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m         tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mFlatten(),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/arthu/Documents/GitHub/TCC_Stock_Predictions/Experiments/Experimentos_LSTM.ipynb#W3sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m         layers\u001b[39m.\u001b[39mDense(units\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, activation\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mlinear\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/arthu/Documents/GitHub/TCC_Stock_Predictions/Experiments/Experimentos_LSTM.ipynb#W3sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     ]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/arthu/Documents/GitHub/TCC_Stock_Predictions/Experiments/Experimentos_LSTM.ipynb#W3sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/arthu/Documents/GitHub/TCC_Stock_Predictions/Experiments/Experimentos_LSTM.ipynb#W3sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/arthu/Documents/GitHub/TCC_Stock_Predictions/Experiments/Experimentos_LSTM.ipynb#W3sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     optimizer\u001b[39m=\u001b[39mkeras\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mAdam(learning_rate\u001b[39m=\u001b[39mhp_learning_rate),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/arthu/Documents/GitHub/TCC_Stock_Predictions/Experiments/Experimentos_LSTM.ipynb#W3sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     loss\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmse\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/arthu/Documents/GitHub/TCC_Stock_Predictions/Experiments/Experimentos_LSTM.ipynb#W3sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     metrics\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mmae\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmse\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/arthu/Documents/GitHub/TCC_Stock_Predictions/Experiments/Experimentos_LSTM.ipynb#W3sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/arthu/Documents/GitHub/TCC_Stock_Predictions/Experiments/Experimentos_LSTM.ipynb#W3sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m \u001b[39mreturn\u001b[39;00m model\n",
      "File \u001b[1;32mc:\\Users\\arthu\\.conda\\envs\\pystock\\lib\\site-packages\\keras\\layers\\rnn\\lstm.py:498\u001b[0m, in \u001b[0;36mLSTM.__init__\u001b[1;34m(self, units, activation, recurrent_activation, use_bias, kernel_initializer, recurrent_initializer, bias_initializer, unit_forget_bias, kernel_regularizer, recurrent_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, recurrent_constraint, bias_constraint, dropout, recurrent_dropout, return_sequences, return_state, go_backwards, stateful, time_major, unroll, **kwargs)\u001b[0m\n\u001b[0;32m    496\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    497\u001b[0m   cell_kwargs \u001b[39m=\u001b[39m {}\n\u001b[1;32m--> 498\u001b[0m cell \u001b[39m=\u001b[39m LSTMCell(\n\u001b[0;32m    499\u001b[0m     units,\n\u001b[0;32m    500\u001b[0m     activation\u001b[39m=\u001b[39;49mactivation,\n\u001b[0;32m    501\u001b[0m     recurrent_activation\u001b[39m=\u001b[39;49mrecurrent_activation,\n\u001b[0;32m    502\u001b[0m     use_bias\u001b[39m=\u001b[39;49muse_bias,\n\u001b[0;32m    503\u001b[0m     kernel_initializer\u001b[39m=\u001b[39;49mkernel_initializer,\n\u001b[0;32m    504\u001b[0m     recurrent_initializer\u001b[39m=\u001b[39;49mrecurrent_initializer,\n\u001b[0;32m    505\u001b[0m     unit_forget_bias\u001b[39m=\u001b[39;49munit_forget_bias,\n\u001b[0;32m    506\u001b[0m     bias_initializer\u001b[39m=\u001b[39;49mbias_initializer,\n\u001b[0;32m    507\u001b[0m     kernel_regularizer\u001b[39m=\u001b[39;49mkernel_regularizer,\n\u001b[0;32m    508\u001b[0m     recurrent_regularizer\u001b[39m=\u001b[39;49mrecurrent_regularizer,\n\u001b[0;32m    509\u001b[0m     bias_regularizer\u001b[39m=\u001b[39;49mbias_regularizer,\n\u001b[0;32m    510\u001b[0m     kernel_constraint\u001b[39m=\u001b[39;49mkernel_constraint,\n\u001b[0;32m    511\u001b[0m     recurrent_constraint\u001b[39m=\u001b[39;49mrecurrent_constraint,\n\u001b[0;32m    512\u001b[0m     bias_constraint\u001b[39m=\u001b[39;49mbias_constraint,\n\u001b[0;32m    513\u001b[0m     dropout\u001b[39m=\u001b[39;49mdropout,\n\u001b[0;32m    514\u001b[0m     recurrent_dropout\u001b[39m=\u001b[39;49mrecurrent_dropout,\n\u001b[0;32m    515\u001b[0m     implementation\u001b[39m=\u001b[39;49mimplementation,\n\u001b[0;32m    516\u001b[0m     dtype\u001b[39m=\u001b[39;49mkwargs\u001b[39m.\u001b[39;49mget(\u001b[39m'\u001b[39;49m\u001b[39mdtype\u001b[39;49m\u001b[39m'\u001b[39;49m),\n\u001b[0;32m    517\u001b[0m     trainable\u001b[39m=\u001b[39;49mkwargs\u001b[39m.\u001b[39;49mget(\u001b[39m'\u001b[39;49m\u001b[39mtrainable\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39mTrue\u001b[39;49;00m),\n\u001b[0;32m    518\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcell_kwargs)\n\u001b[0;32m    519\u001b[0m \u001b[39msuper\u001b[39m(LSTM, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\n\u001b[0;32m    520\u001b[0m     cell,\n\u001b[0;32m    521\u001b[0m     return_sequences\u001b[39m=\u001b[39mreturn_sequences,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    526\u001b[0m     unroll\u001b[39m=\u001b[39munroll,\n\u001b[0;32m    527\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    528\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactivity_regularizer \u001b[39m=\u001b[39m regularizers\u001b[39m.\u001b[39mget(activity_regularizer)\n",
      "File \u001b[1;32mc:\\Users\\arthu\\.conda\\envs\\pystock\\lib\\site-packages\\keras\\layers\\rnn\\lstm.py:148\u001b[0m, in \u001b[0;36mLSTMCell.__init__\u001b[1;34m(self, units, activation, recurrent_activation, use_bias, kernel_initializer, recurrent_initializer, bias_initializer, unit_forget_bias, kernel_regularizer, recurrent_regularizer, bias_regularizer, kernel_constraint, recurrent_constraint, bias_constraint, dropout, recurrent_dropout, **kwargs)\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[39msuper\u001b[39m(LSTMCell, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    147\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39munits \u001b[39m=\u001b[39m units\n\u001b[1;32m--> 148\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactivation \u001b[39m=\u001b[39m activations\u001b[39m.\u001b[39;49mget(activation)\n\u001b[0;32m    149\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrecurrent_activation \u001b[39m=\u001b[39m activations\u001b[39m.\u001b[39mget(recurrent_activation)\n\u001b[0;32m    150\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_bias \u001b[39m=\u001b[39m use_bias\n",
      "File \u001b[1;32mc:\\Users\\arthu\\.conda\\envs\\pystock\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\arthu\\.conda\\envs\\pystock\\lib\\site-packages\\keras\\activations.py:599\u001b[0m, in \u001b[0;36mget\u001b[1;34m(identifier)\u001b[0m\n\u001b[0;32m    597\u001b[0m   \u001b[39mreturn\u001b[39;00m identifier\n\u001b[0;32m    598\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 599\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m    600\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mCould not interpret activation function identifier: \u001b[39m\u001b[39m{\u001b[39;00midentifier\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: Could not interpret activation function identifier: ['relu', 'sigmoid', 'softplus', 'softsign', 'tanh', 'selu', 'elu', 'exponential', 'relu']"
     ]
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 4;\n                var nbb_unformatted_code = \"for i in range(10):\\n    repetir()\";\n                var nbb_formatted_code = \"for i in range(10):\\n    repetir()\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    repetir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 19;\n                var nbb_unformatted_code = \"result_columns = [\\n    \\\"activation\\\",\\n    \\\"best_epoch\\\",\\n    \\\"best_model_path\\\",\\n    \\\"hp_unit_1\\\",\\n    \\\"hp_unit_2\\\",\\n    \\\"hp_unit_3\\\",\\n    \\\"hp_unit_4\\\",\\n    \\\"kernel_size_1\\\",\\n    \\\"kernel_size_2\\\",\\n    \\\"learning_rate\\\",\\n    \\\"n_filter_1\\\",\\n    \\\"n_filter_2\\\",\\n    \\\"val_mae\\\",\\n    \\\"val_mse\\\",\\n]\\n\\ndata = list(\\n    zip(\\n        list_activation,\\n        list_best_epoch,\\n        list_best_model_path,\\n        list_hp_unit_1,\\n        list_hp_unit_2,\\n        list_hp_unit_3,\\n        list_hp_unit_4,\\n        list_kernel_size_1,\\n        list_kernel_size_2,\\n        list_learning_rate,\\n        list_n_filter_1,\\n        list_n_filter_2,\\n        list_val_mae,\\n        list_val_mse,\\n    )\\n)\\n\\ndf_resultados = pd.DataFrame(\\n    data,\\n    columns=result_columns,\\n)\\nTYPE_MODEL = \\\"MLP\\\"\\ndf_resultados.to_csv(f\\\"Resultados_{TYPE_MODEL}.csv\\\")\";\n                var nbb_formatted_code = \"result_columns = [\\n    \\\"activation\\\",\\n    \\\"best_epoch\\\",\\n    \\\"best_model_path\\\",\\n    \\\"hp_unit_1\\\",\\n    \\\"hp_unit_2\\\",\\n    \\\"hp_unit_3\\\",\\n    \\\"hp_unit_4\\\",\\n    \\\"kernel_size_1\\\",\\n    \\\"kernel_size_2\\\",\\n    \\\"learning_rate\\\",\\n    \\\"n_filter_1\\\",\\n    \\\"n_filter_2\\\",\\n    \\\"val_mae\\\",\\n    \\\"val_mse\\\",\\n]\\n\\ndata = list(\\n    zip(\\n        list_activation,\\n        list_best_epoch,\\n        list_best_model_path,\\n        list_hp_unit_1,\\n        list_hp_unit_2,\\n        list_hp_unit_3,\\n        list_hp_unit_4,\\n        list_kernel_size_1,\\n        list_kernel_size_2,\\n        list_learning_rate,\\n        list_n_filter_1,\\n        list_n_filter_2,\\n        list_val_mae,\\n        list_val_mse,\\n    )\\n)\\n\\ndf_resultados = pd.DataFrame(\\n    data,\\n    columns=result_columns,\\n)\\nTYPE_MODEL = \\\"MLP\\\"\\ndf_resultados.to_csv(f\\\"Resultados_{TYPE_MODEL}.csv\\\")\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result_columns = [\n",
    "    \"activation\",\n",
    "    \"best_epoch\",\n",
    "    \"best_model_path\",\n",
    "    \"hp_unit_1\",\n",
    "    \"hp_unit_2\",\n",
    "    \"hp_unit_3\",\n",
    "    \"hp_unit_4\",\n",
    "    \"kernel_size_1\",\n",
    "    \"kernel_size_2\",\n",
    "    \"learning_rate\",\n",
    "    \"n_filter_1\",\n",
    "    \"n_filter_2\",\n",
    "    \"val_mae\",\n",
    "    \"val_mse\",\n",
    "]\n",
    "\n",
    "data = list(\n",
    "    zip(\n",
    "        list_activation,\n",
    "        list_best_epoch,\n",
    "        list_best_model_path,\n",
    "        list_hp_unit_1,\n",
    "        list_hp_unit_2,\n",
    "        list_hp_unit_3,\n",
    "        list_hp_unit_4,\n",
    "        list_kernel_size_1,\n",
    "        list_kernel_size_2,\n",
    "        list_learning_rate,\n",
    "        list_n_filter_1,\n",
    "        list_n_filter_2,\n",
    "        list_val_mae,\n",
    "        list_val_mse,\n",
    "    )\n",
    ")\n",
    "\n",
    "df_resultados = pd.DataFrame(\n",
    "    data,\n",
    "    columns=result_columns,\n",
    ")\n",
    "\n",
    "df_resultados.to_csv(f\"Resultados_{TYPE_MODEL}.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('pystock')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bc0c8eb905859abd75b389576d87e2ac71c748b72952270660ecc130aeb3e651"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
