{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usei como base esse tutorial:\n",
    "# https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/pt-br/tutorials/keras/regression.ipynb#scrollTo=f-OHX4DiXd8x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "# # # Clear logs\n",
    "# # %rm -rf ./logs/\n",
    "\n",
    "# # Ativação do Tensorboard\n",
    "%conda activate pystock\n",
    "%load_ext tensorboard\n",
    "\n",
    "# # Reload Tensorboar\n",
    "%reload_ext tensorboard\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential model\n",
    "\n",
    "*Dense model 16*\n",
    "*Dense model 16*\n",
    "*Dense model 8*\n",
    "*Dense model 4*\n",
    "*Epoch 350*\n",
    "\n",
    "_MSE: 1.31_\n",
    "epoch: 350\n",
    "\n",
    "Activation: softplus\n",
    "Optimizer: Adam\n",
    "\n",
    "15/15 - 0s - loss: 0.6325 - mae: 0.5830 - mse: 0.6325\n",
    "Testing set Mean Abs Error:  0.58 ibova_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lendo Dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TREINO = '../Data/3_Gold/Treino_all_stocks.csv'\n",
    "DF_TREINO = pd.read_csv(PATH_TREINO, sep=\",\")\n",
    "\n",
    "PATH_VALIDACAO = '../Data/3_Gold/Validacao_all_stocks.csv'\n",
    "DF_VALIDACAO = pd.read_csv(PATH_VALIDACAO, sep=\",\")\n",
    "\n",
    "PATH_TESTE = '../Data/3_Gold/Teste_all_stocks.csv'\n",
    "DF_TESTE = pd.read_csv(PATH_TESTE, sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index,\n",
    "# ibova_0,ibova_1,ibova_2,ibova_3,ibova_4,ibova_5,\n",
    "# oil_0,oil_1,oil_2,oil_3,oil_4,oil_5,usd_0,\n",
    "# usd_1,usd_2,usd_3,usd_4,usd_5,\n",
    "# abev_0,abev_1,abev_2,abev_3,abev_4,abev_5,\n",
    "# jbs_0,jbs_1,jbs_2,jbs_3,jbs_4,jbs_5,\n",
    "# petr_0,petr_1,petr_2,petr_3,petr_4,petr_5,\n",
    "# vale_0,vale_1,vale_2,vale_3,vale_4,vale_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = DF_TREINO\n",
    "train_dataset = train_dataset.drop(['oil_0','usd_0','abev_0','jbs_0','petr_0','vale_0',], axis=1)\n",
    "train_labels = train_dataset.pop('ibova_0')\n",
    "\n",
    "test_dataset = DF_TESTE\n",
    "test_dataset = test_dataset.drop(['oil_0','usd_0','abev_0','jbs_0','petr_0','vale_0',],axis=1)\n",
    "test_labels = test_dataset.pop('ibova_0')\n",
    "\n",
    "valid_dataset = DF_VALIDACAO\n",
    "valid_dataset = valid_dataset.drop(['ibova_0','oil_0','usd_0','abev_0','jbs_0','petr_0','vale_0',],axis=1)\n",
    "# valid_labels = valid_dataset.pop('ibova_0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspecionando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.pairplot(train_dataset[['index','ibova_0','ibova_1','ibova_2','ibova_3','ibova_4','oil_0','oil_1','oil_2','oil_3','oil_4','usd_0','usd_1','usd_2','usd_3','usd_4']], diag_kind=\"kde\")\n",
    "# sns.pairplot(train_dataset[['index','ibova_0','oil_0','usd_0']], diag_kind=\"kde\")\n",
    "# sns.pairplot(train_dataset[['ibova_1','oil_1','usd_1']], diag_kind=\"kde\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stats = train_dataset.describe()\n",
    "# train_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definindo o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_45 (Dense)             (None, 16)                592       \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 841\n",
      "Trainable params: 841\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Diminuir quantidade de nós \n",
    "# Funcao logistica pra optimization\n",
    "# Ver se relu funciona com RMSprop\n",
    "\n",
    "# softplus melhor até agora\n",
    "def build_model():\n",
    "  model = keras.Sequential([\n",
    "    layers.Dense(16, activation='relu', input_shape=[len(train_dataset.keys())]),\n",
    "    layers.Dense(8, activation='relu'),\n",
    "    layers.Dense(8, activation='relu'),\n",
    "    layers.Dense(4, activation='relu'),\n",
    "    layers.Dense(1, activation='linear')\n",
    "  ])\n",
    "\n",
    "  # optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
    "  optimizer = tf.keras.optimizers.Adam(learning_rate=0.00009,\n",
    "                                       beta_1=0.9,\n",
    "                                       beta_2=0.999,\n",
    "                                       amsgrad=True)\n",
    "  \n",
    "  model.compile(loss='mse',\n",
    "                optimizer=optimizer,\n",
    "                metrics=['mae', 'mse'])\n",
    "  return model\n",
    "\n",
    "model = build_model()\n",
    "model.summary()\n",
    "\n",
    "# rmse pra avaliação, nao para loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definindo Métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seguindo esse tutorial para extrair metricas para o tensorboard\n",
    "# https://www.tensorflow.org/tensorboard/get_started?hl=pt\n",
    "\n",
    "\n",
    "# Define metrics\n",
    "train_loss = tf.keras.metrics.Mean('train_loss', dtype=tf.float32)\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy('train_accuracy')\n",
    "test_loss = tf.keras.metrics.Mean('test_loss', dtype=tf.float32)\n",
    "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy('test_accuracy')\n",
    "\n",
    "\n",
    "# Para salvar os arquivos de log\n",
    "current_time = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "train_log_dir = 'logs/gradient_tape/' + current_time + '/train'\n",
    "test_log_dir = 'logs/gradient_tape/' + current_time + '/test'\n",
    "train_summary_writer = tf.summary.create_file_writer(train_log_dir)\n",
    "test_summary_writer = tf.summary.create_file_writer(test_log_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_batch = train_dataset[:10]\n",
    "example_result = model.predict(example_batch)\n",
    "# example_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinado o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5812/1883174720.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'train_dataset: {train_dataset.columns()} \\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'valid_dataset: {valid_dataset.columns()} \\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'test_dataset: {test_dataset.columns()} \\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "print(f'train_dataset: {train_dataset.columns()} \\n')\n",
    "print(f'valid_dataset: {valid_dataset.columns()} \\n')\n",
    "print(f'test_dataset: {test_dataset.columns()} \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      " 2/36 [>.............................] - ETA: 16s - loss: 5754.8931 - mae: 66.9591 - mse: 5754.8931WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0030s vs `on_train_batch_end` time: 0.9670s). Check your callbacks.\n",
      "36/36 [==============================] - 1s 36ms/step - loss: 4742.9609 - mae: 59.5938 - mse: 4742.9609 - val_loss: 15997.5820 - val_mae: 126.2164 - val_mse: 15997.5820\n",
      "Epoch 2/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 3655.0383 - mae: 52.2453 - mse: 3655.0383 - val_loss: 12246.6299 - val_mae: 110.4307 - val_mse: 12246.6299\n",
      "Epoch 3/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 2785.2380 - mae: 45.6147 - mse: 2785.2380 - val_loss: 9333.3574 - val_mae: 96.4031 - val_mse: 9333.3574\n",
      "Epoch 4/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 2094.4639 - mae: 39.5575 - mse: 2094.4639 - val_loss: 7002.6577 - val_mae: 83.5005 - val_mse: 7002.6577\n",
      "Epoch 5/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 1548.5331 - mae: 33.9984 - mse: 1548.5331 - val_loss: 5136.3027 - val_mae: 71.5112 - val_mse: 5136.3027\n",
      "Epoch 6/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 1149.6985 - mae: 29.2844 - mse: 1149.6985 - val_loss: 3881.3901 - val_mae: 62.1610 - val_mse: 3881.3901\n",
      "Epoch 7/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 857.3628 - mae: 25.2854 - mse: 857.3628 - val_loss: 2878.7554 - val_mae: 53.5295 - val_mse: 2878.7554\n",
      "Epoch 8/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 625.1139 - mae: 21.6029 - mse: 625.1139 - val_loss: 2092.8662 - val_mae: 45.6413 - val_mse: 2092.8662\n",
      "Epoch 9/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 482.6411 - mae: 19.0158 - mse: 482.6411 - val_loss: 1730.6984 - val_mae: 41.5086 - val_mse: 1730.6984\n",
      "Epoch 10/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 417.7178 - mae: 17.7167 - mse: 417.7178 - val_loss: 1525.2123 - val_mae: 38.9705 - val_mse: 1525.2123\n",
      "Epoch 11/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 372.4443 - mae: 16.7292 - mse: 372.4443 - val_loss: 1367.8655 - val_mae: 36.9036 - val_mse: 1367.8655\n",
      "Epoch 12/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 333.6233 - mae: 15.8314 - mse: 333.6233 - val_loss: 1228.4541 - val_mae: 34.9720 - val_mse: 1228.4541\n",
      "Epoch 13/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 299.8614 - mae: 15.0104 - mse: 299.8614 - val_loss: 1107.2180 - val_mae: 33.2009 - val_mse: 1107.2180\n",
      "Epoch 14/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 270.2958 - mae: 14.2490 - mse: 270.2958 - val_loss: 1001.4771 - val_mae: 31.5747 - val_mse: 1001.4771\n",
      "Epoch 15/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 244.2932 - mae: 13.5467 - mse: 244.2932 - val_loss: 907.5290 - val_mae: 30.0565 - val_mse: 907.5290\n",
      "Epoch 16/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 221.3534 - mae: 12.8946 - mse: 221.3534 - val_loss: 825.2203 - val_mae: 28.6598 - val_mse: 825.2203\n",
      "Epoch 17/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 201.0650 - mae: 12.2855 - mse: 201.0650 - val_loss: 750.4352 - val_mae: 27.3296 - val_mse: 750.4352\n",
      "Epoch 18/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 182.9044 - mae: 11.7169 - mse: 182.9044 - val_loss: 685.2656 - val_mae: 26.1149 - val_mse: 685.2656\n",
      "Epoch 19/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 166.8101 - mae: 11.1886 - mse: 166.8101 - val_loss: 626.0880 - val_mae: 24.9611 - val_mse: 626.0880\n",
      "Epoch 20/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 152.4341 - mae: 10.6920 - mse: 152.4341 - val_loss: 572.7009 - val_mae: 23.8722 - val_mse: 572.7009\n",
      "Epoch 21/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 139.5020 - mae: 10.2229 - mse: 139.5020 - val_loss: 525.0156 - val_mae: 22.8556 - val_mse: 525.0156\n",
      "Epoch 22/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 127.8491 - mae: 9.7880 - mse: 127.8491 - val_loss: 482.3681 - val_mae: 21.9068 - val_mse: 482.3681\n",
      "Epoch 23/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 117.4156 - mae: 9.3789 - mse: 117.4156 - val_loss: 443.7613 - val_mae: 21.0110 - val_mse: 443.7613\n",
      "Epoch 24/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 107.9814 - mae: 8.9922 - mse: 107.9814 - val_loss: 409.0924 - val_mae: 20.1726 - val_mse: 409.0924\n",
      "Epoch 25/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 99.4623 - mae: 8.6270 - mse: 99.4623 - val_loss: 377.8915 - val_mae: 19.3865 - val_mse: 377.8915\n",
      "Epoch 26/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 91.7106 - mae: 8.2834 - mse: 91.7106 - val_loss: 349.4875 - val_mae: 18.6424 - val_mse: 349.4875\n",
      "Epoch 27/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 84.6798 - mae: 7.9570 - mse: 84.6798 - val_loss: 322.7678 - val_mae: 17.9153 - val_mse: 322.7678\n",
      "Epoch 28/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 78.3000 - mae: 7.6472 - mse: 78.3000 - val_loss: 299.0075 - val_mae: 17.2419 - val_mse: 299.0075\n",
      "Epoch 29/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 72.4366 - mae: 7.3547 - mse: 72.4366 - val_loss: 277.5824 - val_mae: 16.6112 - val_mse: 277.5824\n",
      "Epoch 30/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 67.1029 - mae: 7.0780 - mse: 67.1029 - val_loss: 257.6946 - val_mae: 16.0044 - val_mse: 257.6946\n",
      "Epoch 31/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 62.2534 - mae: 6.8144 - mse: 62.2534 - val_loss: 239.3837 - val_mae: 15.4242 - val_mse: 239.3837\n",
      "Epoch 32/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 57.7868 - mae: 6.5655 - mse: 57.7868 - val_loss: 222.6718 - val_mae: 14.8750 - val_mse: 222.6718\n",
      "Epoch 33/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 53.7420 - mae: 6.3285 - mse: 53.7420 - val_loss: 207.4099 - val_mae: 14.3547 - val_mse: 207.4099\n",
      "Epoch 34/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 50.0287 - mae: 6.1038 - mse: 50.0287 - val_loss: 193.6566 - val_mae: 13.8694 - val_mse: 193.6566\n",
      "Epoch 35/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 46.6775 - mae: 5.8944 - mse: 46.6775 - val_loss: 181.2523 - val_mae: 13.4168 - val_mse: 181.2523\n",
      "Epoch 36/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 43.6399 - mae: 5.6978 - mse: 43.6399 - val_loss: 169.9294 - val_mae: 12.9898 - val_mse: 169.9294\n",
      "Epoch 37/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 40.8682 - mae: 5.5111 - mse: 40.8682 - val_loss: 159.2528 - val_mae: 12.5742 - val_mse: 159.2528\n",
      "Epoch 38/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 38.2894 - mae: 5.3318 - mse: 38.2894 - val_loss: 149.4733 - val_mae: 12.1812 - val_mse: 149.4733\n",
      "Epoch 39/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 35.9076 - mae: 5.1626 - mse: 35.9076 - val_loss: 140.4572 - val_mae: 11.8072 - val_mse: 140.4572\n",
      "Epoch 40/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 33.7115 - mae: 4.9990 - mse: 33.7115 - val_loss: 132.0457 - val_mae: 11.4469 - val_mse: 132.0457\n",
      "Epoch 41/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 31.6343 - mae: 4.8420 - mse: 31.6343 - val_loss: 124.2958 - val_mae: 11.1049 - val_mse: 124.2958\n",
      "Epoch 42/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 29.7360 - mae: 4.6917 - mse: 29.7360 - val_loss: 116.8922 - val_mae: 10.7679 - val_mse: 116.8922\n",
      "Epoch 43/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 27.9321 - mae: 4.5465 - mse: 27.9321 - val_loss: 110.0946 - val_mae: 10.4492 - val_mse: 110.0946\n",
      "Epoch 44/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 26.2708 - mae: 4.4071 - mse: 26.2708 - val_loss: 103.7402 - val_mae: 10.1419 - val_mse: 103.7402\n",
      "Epoch 45/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 24.7088 - mae: 4.2723 - mse: 24.7088 - val_loss: 97.8076 - val_mae: 9.8463 - val_mse: 97.8076\n",
      "Epoch 46/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 23.2505 - mae: 4.1425 - mse: 23.2505 - val_loss: 92.1223 - val_mae: 9.5549 - val_mse: 92.1223\n",
      "Epoch 47/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 21.8843 - mae: 4.0171 - mse: 21.8843 - val_loss: 86.9806 - val_mae: 9.2829 - val_mse: 86.9806\n",
      "Epoch 48/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 20.6076 - mae: 3.8964 - mse: 20.6076 - val_loss: 81.9359 - val_mae: 9.0088 - val_mse: 81.9359\n",
      "Epoch 49/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 19.4084 - mae: 3.7798 - mse: 19.4084 - val_loss: 77.4011 - val_mae: 8.7544 - val_mse: 77.4011\n",
      "Epoch 50/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 18.2800 - mae: 3.6667 - mse: 18.2800 - val_loss: 73.0697 - val_mae: 8.5048 - val_mse: 73.0697\n",
      "Epoch 51/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 17.2331 - mae: 3.5582 - mse: 17.2331 - val_loss: 68.9470 - val_mae: 8.2602 - val_mse: 68.9470\n",
      "Epoch 52/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 15.9253 - mae: 3.4173 - mse: 15.9253 - val_loss: 57.6867 - val_mae: 7.5515 - val_mse: 57.6867\n",
      "Epoch 53/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 12.3147 - mae: 2.9867 - mse: 12.3147 - val_loss: 47.1749 - val_mae: 6.8179 - val_mse: 47.1749\n",
      "Epoch 54/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 9.9755 - mae: 2.6805 - mse: 9.9755 - val_loss: 38.7380 - val_mae: 6.1716 - val_mse: 38.7380\n",
      "Epoch 55/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 8.0761 - mae: 2.4070 - mse: 8.0761 - val_loss: 31.5782 - val_mae: 5.5650 - val_mse: 31.5782\n",
      "Epoch 56/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 6.4870 - mae: 2.1481 - mse: 6.4870 - val_loss: 25.3856 - val_mae: 4.9809 - val_mse: 25.3856\n",
      "Epoch 57/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 5.1517 - mae: 1.9079 - mse: 5.1517 - val_loss: 20.3683 - val_mae: 4.4520 - val_mse: 20.3683\n",
      "Epoch 58/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 4.0734 - mae: 1.6902 - mse: 4.0734 - val_loss: 16.1759 - val_mae: 3.9564 - val_mse: 16.1759\n",
      "Epoch 59/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 3.1960 - mae: 1.4914 - mse: 3.1960 - val_loss: 12.7792 - val_mae: 3.5042 - val_mse: 12.7792\n",
      "Epoch 60/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 2.4951 - mae: 1.3135 - mse: 2.4951 - val_loss: 10.0476 - val_mae: 3.0930 - val_mse: 10.0476\n",
      "Epoch 61/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 1.9398 - mae: 1.1519 - mse: 1.9398 - val_loss: 7.8713 - val_mae: 2.7213 - val_mse: 7.8713\n",
      "Epoch 62/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 1.5069 - mae: 1.0106 - mse: 1.5069 - val_loss: 6.1231 - val_mae: 2.3811 - val_mse: 6.1231\n",
      "Epoch 63/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 1.1700 - mae: 0.8848 - mse: 1.1700 - val_loss: 4.7873 - val_mae: 2.0842 - val_mse: 4.7873\n",
      "Epoch 64/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.9177 - mae: 0.7779 - mse: 0.9177 - val_loss: 3.7380 - val_mae: 1.8175 - val_mse: 3.7380\n",
      "Epoch 65/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.7267 - mae: 0.6864 - mse: 0.7267 - val_loss: 2.9504 - val_mae: 1.5917 - val_mse: 2.9504\n",
      "Epoch 66/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5869 - mae: 0.6120 - mse: 0.5869 - val_loss: 2.3378 - val_mae: 1.3931 - val_mse: 2.3378\n",
      "Epoch 67/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4835 - mae: 0.5520 - mse: 0.4835 - val_loss: 1.8863 - val_mae: 1.2273 - val_mse: 1.8863\n",
      "Epoch 68/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4113 - mae: 0.5055 - mse: 0.4113 - val_loss: 1.5409 - val_mae: 1.0873 - val_mse: 1.5409\n",
      "Epoch 69/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.3626 - mae: 0.4730 - mse: 0.3626 - val_loss: 1.3043 - val_mae: 0.9841 - val_mse: 1.3043\n",
      "Epoch 70/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.3319 - mae: 0.4526 - mse: 0.3319 - val_loss: 1.1545 - val_mae: 0.9149 - val_mse: 1.1545\n",
      "Epoch 71/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.3140 - mae: 0.4399 - mse: 0.3140 - val_loss: 1.0560 - val_mae: 0.8680 - val_mse: 1.0560\n",
      "Epoch 72/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.3022 - mae: 0.4312 - mse: 0.3022 - val_loss: 0.9878 - val_mae: 0.8347 - val_mse: 0.9878\n",
      "Epoch 73/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2932 - mae: 0.4249 - mse: 0.2932 - val_loss: 0.9305 - val_mae: 0.8057 - val_mse: 0.9305\n",
      "Epoch 74/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2856 - mae: 0.4197 - mse: 0.2856 - val_loss: 0.8823 - val_mae: 0.7811 - val_mse: 0.8823\n",
      "Epoch 75/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2792 - mae: 0.4149 - mse: 0.2792 - val_loss: 0.8393 - val_mae: 0.7583 - val_mse: 0.8393\n",
      "Epoch 76/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2735 - mae: 0.4108 - mse: 0.2735 - val_loss: 0.8021 - val_mae: 0.7384 - val_mse: 0.8021\n",
      "Epoch 77/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2686 - mae: 0.4070 - mse: 0.2686 - val_loss: 0.7694 - val_mae: 0.7205 - val_mse: 0.7694\n",
      "Epoch 78/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2642 - mae: 0.4039 - mse: 0.2642 - val_loss: 0.7407 - val_mae: 0.7042 - val_mse: 0.7407\n",
      "Epoch 79/500\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.2398 - mae: 0.4006 - mse: 0.239 - 0s 2ms/step - loss: 0.2603 - mae: 0.4011 - mse: 0.2603 - val_loss: 0.7131 - val_mae: 0.6881 - val_mse: 0.7131\n",
      "Epoch 80/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2569 - mae: 0.3987 - mse: 0.2569 - val_loss: 0.6895 - val_mae: 0.6745 - val_mse: 0.6895\n",
      "Epoch 81/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2537 - mae: 0.3960 - mse: 0.2537 - val_loss: 0.6656 - val_mae: 0.6605 - val_mse: 0.6656\n",
      "Epoch 82/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2510 - mae: 0.3939 - mse: 0.2510 - val_loss: 0.6462 - val_mae: 0.6491 - val_mse: 0.6462\n",
      "Epoch 83/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2485 - mae: 0.3921 - mse: 0.2485 - val_loss: 0.6278 - val_mae: 0.6380 - val_mse: 0.6278\n",
      "Epoch 84/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2465 - mae: 0.3911 - mse: 0.2465 - val_loss: 0.6108 - val_mae: 0.6279 - val_mse: 0.6108\n",
      "Epoch 85/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2446 - mae: 0.3897 - mse: 0.2446 - val_loss: 0.5948 - val_mae: 0.6181 - val_mse: 0.5948\n",
      "Epoch 86/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2429 - mae: 0.3885 - mse: 0.2429 - val_loss: 0.5812 - val_mae: 0.6096 - val_mse: 0.5812\n",
      "Epoch 87/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2412 - mae: 0.3872 - mse: 0.2412 - val_loss: 0.5674 - val_mae: 0.6008 - val_mse: 0.5674\n",
      "Epoch 88/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2399 - mae: 0.3863 - mse: 0.2399 - val_loss: 0.5554 - val_mae: 0.5927 - val_mse: 0.5554\n",
      "Epoch 89/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2388 - mae: 0.3855 - mse: 0.2388 - val_loss: 0.5466 - val_mae: 0.5874 - val_mse: 0.5466\n",
      "Epoch 90/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2379 - mae: 0.3846 - mse: 0.2379 - val_loss: 0.5328 - val_mae: 0.5782 - val_mse: 0.5328\n",
      "Epoch 91/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2371 - mae: 0.3844 - mse: 0.2371 - val_loss: 0.5265 - val_mae: 0.5748 - val_mse: 0.5265\n",
      "Epoch 92/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2358 - mae: 0.3837 - mse: 0.2358 - val_loss: 0.5181 - val_mae: 0.5698 - val_mse: 0.5181\n",
      "Epoch 93/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2350 - mae: 0.3831 - mse: 0.2350 - val_loss: 0.5101 - val_mae: 0.5649 - val_mse: 0.5101\n",
      "Epoch 94/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2343 - mae: 0.3827 - mse: 0.2343 - val_loss: 0.5027 - val_mae: 0.5604 - val_mse: 0.5027\n",
      "Epoch 95/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2338 - mae: 0.3824 - mse: 0.2338 - val_loss: 0.4976 - val_mae: 0.5573 - val_mse: 0.4976\n",
      "Epoch 96/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2333 - mae: 0.3821 - mse: 0.2333 - val_loss: 0.4900 - val_mae: 0.5525 - val_mse: 0.4900\n",
      "Epoch 97/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2327 - mae: 0.3818 - mse: 0.2327 - val_loss: 0.4855 - val_mae: 0.5501 - val_mse: 0.4855\n",
      "Epoch 98/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2323 - mae: 0.3815 - mse: 0.2323 - val_loss: 0.4792 - val_mae: 0.5462 - val_mse: 0.4792\n",
      "Epoch 99/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2319 - mae: 0.3813 - mse: 0.2319 - val_loss: 0.4755 - val_mae: 0.5441 - val_mse: 0.4755\n",
      "Epoch 100/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2314 - mae: 0.3810 - mse: 0.2314 - val_loss: 0.4708 - val_mae: 0.5414 - val_mse: 0.4708\n",
      "Epoch 101/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2312 - mae: 0.3809 - mse: 0.2312 - val_loss: 0.4664 - val_mae: 0.5389 - val_mse: 0.4664\n",
      "Epoch 102/500\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.2306 - mae: 0.3806 - mse: 0.2306 - val_loss: 0.4637 - val_mae: 0.5375 - val_mse: 0.4637\n",
      "Epoch 103/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2305 - mae: 0.3808 - mse: 0.2305 - val_loss: 0.4596 - val_mae: 0.5351 - val_mse: 0.4596\n",
      "Epoch 104/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.2301 - mae: 0.3805 - mse: 0.2301 - val_loss: 0.4532 - val_mae: 0.5309 - val_mse: 0.4532\n",
      "Epoch 105/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2296 - mae: 0.3798 - mse: 0.2296 - val_loss: 0.4456 - val_mae: 0.5251 - val_mse: 0.4456\n",
      "Epoch 106/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.2289 - mae: 0.3804 - mse: 0.2289 - val_loss: 0.4379 - val_mae: 0.5205 - val_mse: 0.4379\n",
      "Epoch 107/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2279 - mae: 0.3798 - mse: 0.2279 - val_loss: 0.4341 - val_mae: 0.5176 - val_mse: 0.4341\n",
      "Epoch 108/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2277 - mae: 0.3791 - mse: 0.2277 - val_loss: 0.4307 - val_mae: 0.5154 - val_mse: 0.4307\n",
      "Epoch 109/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2267 - mae: 0.3795 - mse: 0.2267 - val_loss: 0.4236 - val_mae: 0.5113 - val_mse: 0.4236\n",
      "Epoch 110/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2280 - mae: 0.3794 - mse: 0.2280 - val_loss: 0.4264 - val_mae: 0.5141 - val_mse: 0.4264\n",
      "Epoch 111/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2269 - mae: 0.3792 - mse: 0.2269 - val_loss: 0.4171 - val_mae: 0.5071 - val_mse: 0.4171\n",
      "Epoch 112/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2257 - mae: 0.3789 - mse: 0.2257 - val_loss: 0.4131 - val_mae: 0.5046 - val_mse: 0.4131\n",
      "Epoch 113/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2251 - mae: 0.3786 - mse: 0.2251 - val_loss: 0.4085 - val_mae: 0.5019 - val_mse: 0.4085\n",
      "Epoch 114/500\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.2247 - mae: 0.3783 - mse: 0.2247 - val_loss: 0.4030 - val_mae: 0.4987 - val_mse: 0.4030\n",
      "Epoch 115/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2248 - mae: 0.3780 - mse: 0.2248 - val_loss: 0.3990 - val_mae: 0.4967 - val_mse: 0.3990\n",
      "Epoch 116/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2241 - mae: 0.3786 - mse: 0.2241 - val_loss: 0.3954 - val_mae: 0.4941 - val_mse: 0.3954\n",
      "Epoch 117/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2240 - mae: 0.3780 - mse: 0.2240 - val_loss: 0.3918 - val_mae: 0.4917 - val_mse: 0.3918\n",
      "Epoch 118/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2226 - mae: 0.3773 - mse: 0.2226 - val_loss: 0.3895 - val_mae: 0.4902 - val_mse: 0.3895\n",
      "Epoch 119/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2225 - mae: 0.3772 - mse: 0.2225 - val_loss: 0.3856 - val_mae: 0.4877 - val_mse: 0.3856\n",
      "Epoch 120/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.2223 - mae: 0.3771 - mse: 0.2223 - val_loss: 0.3809 - val_mae: 0.4856 - val_mse: 0.3809\n",
      "Epoch 121/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.2230 - mae: 0.3781 - mse: 0.2230 - val_loss: 0.3807 - val_mae: 0.4848 - val_mse: 0.3807\n",
      "Epoch 122/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.2221 - mae: 0.3768 - mse: 0.2221 - val_loss: 0.3768 - val_mae: 0.4824 - val_mse: 0.3768\n",
      "Epoch 123/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2212 - mae: 0.3766 - mse: 0.2212 - val_loss: 0.3713 - val_mae: 0.4790 - val_mse: 0.3713\n",
      "Epoch 124/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2212 - mae: 0.3765 - mse: 0.2212 - val_loss: 0.3689 - val_mae: 0.4771 - val_mse: 0.3689\n",
      "Epoch 125/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2207 - mae: 0.3765 - mse: 0.2207 - val_loss: 0.3658 - val_mae: 0.4752 - val_mse: 0.3658\n",
      "Epoch 126/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2213 - mae: 0.3767 - mse: 0.2213 - val_loss: 0.3650 - val_mae: 0.4746 - val_mse: 0.3650\n",
      "Epoch 127/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2206 - mae: 0.3765 - mse: 0.2206 - val_loss: 0.3607 - val_mae: 0.4720 - val_mse: 0.3607\n",
      "Epoch 128/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2205 - mae: 0.3762 - mse: 0.2205 - val_loss: 0.3584 - val_mae: 0.4709 - val_mse: 0.3584\n",
      "Epoch 129/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2203 - mae: 0.3767 - mse: 0.2203 - val_loss: 0.3555 - val_mae: 0.4682 - val_mse: 0.3555\n",
      "Epoch 130/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2193 - mae: 0.3755 - mse: 0.2193 - val_loss: 0.3547 - val_mae: 0.4677 - val_mse: 0.3547\n",
      "Epoch 131/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2195 - mae: 0.3757 - mse: 0.2195 - val_loss: 0.3518 - val_mae: 0.4655 - val_mse: 0.3518\n",
      "Epoch 132/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2188 - mae: 0.3752 - mse: 0.2188 - val_loss: 0.3478 - val_mae: 0.4635 - val_mse: 0.3478\n",
      "Epoch 133/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2193 - mae: 0.3761 - mse: 0.2193 - val_loss: 0.3457 - val_mae: 0.4614 - val_mse: 0.3457\n",
      "Epoch 134/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2184 - mae: 0.3748 - mse: 0.2184 - val_loss: 0.3432 - val_mae: 0.4598 - val_mse: 0.3432\n",
      "Epoch 135/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2180 - mae: 0.3746 - mse: 0.2180 - val_loss: 0.3410 - val_mae: 0.4584 - val_mse: 0.3410\n",
      "Epoch 136/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2178 - mae: 0.3744 - mse: 0.2178 - val_loss: 0.3396 - val_mae: 0.4573 - val_mse: 0.3396\n",
      "Epoch 137/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2178 - mae: 0.3746 - mse: 0.2178 - val_loss: 0.3357 - val_mae: 0.4552 - val_mse: 0.3357\n",
      "Epoch 138/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2173 - mae: 0.3740 - mse: 0.2173 - val_loss: 0.3334 - val_mae: 0.4542 - val_mse: 0.3334\n",
      "Epoch 139/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2169 - mae: 0.3738 - mse: 0.2169 - val_loss: 0.3312 - val_mae: 0.4528 - val_mse: 0.3312\n",
      "Epoch 140/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2166 - mae: 0.3735 - mse: 0.2166 - val_loss: 0.3292 - val_mae: 0.4509 - val_mse: 0.3292\n",
      "Epoch 141/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2162 - mae: 0.3734 - mse: 0.2162 - val_loss: 0.3272 - val_mae: 0.4496 - val_mse: 0.3272\n",
      "Epoch 142/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2160 - mae: 0.3730 - mse: 0.2160 - val_loss: 0.3253 - val_mae: 0.4482 - val_mse: 0.3253\n",
      "Epoch 143/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2163 - mae: 0.3730 - mse: 0.2163 - val_loss: 0.3240 - val_mae: 0.4494 - val_mse: 0.3240\n",
      "Epoch 144/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2155 - mae: 0.3721 - mse: 0.2155 - val_loss: 0.3216 - val_mae: 0.4458 - val_mse: 0.3216\n",
      "Epoch 145/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2153 - mae: 0.3725 - mse: 0.2153 - val_loss: 0.3211 - val_mae: 0.4482 - val_mse: 0.3211\n",
      "Epoch 146/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2145 - mae: 0.3719 - mse: 0.2145 - val_loss: 0.3168 - val_mae: 0.4437 - val_mse: 0.3168\n",
      "Epoch 147/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2147 - mae: 0.3716 - mse: 0.2147 - val_loss: 0.3161 - val_mae: 0.4443 - val_mse: 0.3161\n",
      "Epoch 148/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2144 - mae: 0.3711 - mse: 0.2144 - val_loss: 0.3135 - val_mae: 0.4411 - val_mse: 0.3135\n",
      "Epoch 149/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2143 - mae: 0.3713 - mse: 0.2143 - val_loss: 0.3120 - val_mae: 0.4409 - val_mse: 0.3120\n",
      "Epoch 150/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2138 - mae: 0.3709 - mse: 0.2138 - val_loss: 0.3103 - val_mae: 0.4393 - val_mse: 0.3103\n",
      "Epoch 151/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2138 - mae: 0.3711 - mse: 0.2138 - val_loss: 0.3088 - val_mae: 0.4385 - val_mse: 0.3088\n",
      "Epoch 152/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2136 - mae: 0.3701 - mse: 0.2136 - val_loss: 0.3073 - val_mae: 0.4374 - val_mse: 0.3073\n",
      "Epoch 153/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2133 - mae: 0.3707 - mse: 0.2133 - val_loss: 0.3067 - val_mae: 0.4380 - val_mse: 0.3067\n",
      "Epoch 154/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2129 - mae: 0.3701 - mse: 0.2129 - val_loss: 0.3056 - val_mae: 0.4374 - val_mse: 0.3056\n",
      "Epoch 155/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2126 - mae: 0.3697 - mse: 0.2126 - val_loss: 0.3046 - val_mae: 0.4368 - val_mse: 0.3046\n",
      "Epoch 156/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2123 - mae: 0.3698 - mse: 0.2123 - val_loss: 0.3031 - val_mae: 0.4356 - val_mse: 0.3031\n",
      "Epoch 157/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2122 - mae: 0.3699 - mse: 0.2122 - val_loss: 0.3026 - val_mae: 0.4355 - val_mse: 0.3026\n",
      "Epoch 158/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2126 - mae: 0.3697 - mse: 0.2126 - val_loss: 0.3002 - val_mae: 0.4331 - val_mse: 0.3002\n",
      "Epoch 159/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2116 - mae: 0.3689 - mse: 0.2116 - val_loss: 0.3019 - val_mae: 0.4360 - val_mse: 0.3019\n",
      "Epoch 160/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2118 - mae: 0.3694 - mse: 0.2118 - val_loss: 0.3009 - val_mae: 0.4354 - val_mse: 0.3009\n",
      "Epoch 161/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2116 - mae: 0.3688 - mse: 0.2116 - val_loss: 0.2974 - val_mae: 0.4313 - val_mse: 0.2974\n",
      "Epoch 162/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2116 - mae: 0.3689 - mse: 0.2116 - val_loss: 0.2972 - val_mae: 0.4317 - val_mse: 0.2972\n",
      "Epoch 163/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.2113 - mae: 0.3688 - mse: 0.2113 - val_loss: 0.2977 - val_mae: 0.4329 - val_mse: 0.2977\n",
      "Epoch 164/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2113 - mae: 0.3685 - mse: 0.2113 - val_loss: 0.2949 - val_mae: 0.4297 - val_mse: 0.2949\n",
      "Epoch 165/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2108 - mae: 0.3681 - mse: 0.2108 - val_loss: 0.2943 - val_mae: 0.4293 - val_mse: 0.2943\n",
      "Epoch 166/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2106 - mae: 0.3681 - mse: 0.2106 - val_loss: 0.2948 - val_mae: 0.4307 - val_mse: 0.2948\n",
      "Epoch 167/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2114 - mae: 0.3685 - mse: 0.2114 - val_loss: 0.2920 - val_mae: 0.4266 - val_mse: 0.2920\n",
      "Epoch 168/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.2104 - mae: 0.3677 - mse: 0.2104 - val_loss: 0.2929 - val_mae: 0.4290 - val_mse: 0.2929\n",
      "Epoch 169/500\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.2101 - mae: 0.3675 - mse: 0.2101 - val_loss: 0.2911 - val_mae: 0.4269 - val_mse: 0.2911\n",
      "Epoch 170/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.2100 - mae: 0.3672 - mse: 0.2100 - val_loss: 0.2938 - val_mae: 0.4308 - val_mse: 0.2938\n",
      "Epoch 171/500\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.2100 - mae: 0.3675 - mse: 0.2100 - val_loss: 0.2907 - val_mae: 0.4272 - val_mse: 0.2907\n",
      "Epoch 172/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2101 - mae: 0.3675 - mse: 0.2101 - val_loss: 0.2897 - val_mae: 0.4262 - val_mse: 0.2897\n",
      "Epoch 173/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2096 - mae: 0.3669 - mse: 0.2096 - val_loss: 0.2900 - val_mae: 0.4270 - val_mse: 0.2900\n",
      "Epoch 174/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2097 - mae: 0.3668 - mse: 0.2097 - val_loss: 0.2898 - val_mae: 0.4272 - val_mse: 0.2898\n",
      "Epoch 175/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2092 - mae: 0.3666 - mse: 0.2092 - val_loss: 0.2882 - val_mae: 0.4252 - val_mse: 0.2882\n",
      "Epoch 176/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2095 - mae: 0.3665 - mse: 0.2095 - val_loss: 0.2890 - val_mae: 0.4268 - val_mse: 0.2890\n",
      "Epoch 177/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2092 - mae: 0.3666 - mse: 0.2092 - val_loss: 0.2869 - val_mae: 0.4240 - val_mse: 0.2869\n",
      "Epoch 178/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2090 - mae: 0.3661 - mse: 0.2090 - val_loss: 0.2891 - val_mae: 0.4273 - val_mse: 0.2891\n",
      "Epoch 179/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2090 - mae: 0.3664 - mse: 0.2090 - val_loss: 0.2869 - val_mae: 0.4248 - val_mse: 0.2869\n",
      "Epoch 180/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2090 - mae: 0.3665 - mse: 0.2090 - val_loss: 0.2860 - val_mae: 0.4238 - val_mse: 0.2860\n",
      "Epoch 181/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2088 - mae: 0.3660 - mse: 0.2088 - val_loss: 0.2849 - val_mae: 0.4224 - val_mse: 0.2849\n",
      "Epoch 182/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2086 - mae: 0.3658 - mse: 0.2086 - val_loss: 0.2873 - val_mae: 0.4260 - val_mse: 0.2873\n",
      "Epoch 183/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2081 - mae: 0.3656 - mse: 0.2081 - val_loss: 0.2837 - val_mae: 0.4211 - val_mse: 0.2837\n",
      "Epoch 184/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2082 - mae: 0.3656 - mse: 0.2082 - val_loss: 0.2847 - val_mae: 0.4231 - val_mse: 0.2847\n",
      "Epoch 185/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2081 - mae: 0.3656 - mse: 0.2081 - val_loss: 0.2830 - val_mae: 0.4208 - val_mse: 0.2830\n",
      "Epoch 186/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2082 - mae: 0.3656 - mse: 0.2082 - val_loss: 0.2856 - val_mae: 0.4247 - val_mse: 0.2856\n",
      "Epoch 187/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2078 - mae: 0.3650 - mse: 0.2078 - val_loss: 0.2833 - val_mae: 0.4220 - val_mse: 0.2833\n",
      "Epoch 188/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.2079 - mae: 0.3655 - mse: 0.2079 - val_loss: 0.2837 - val_mae: 0.4227 - val_mse: 0.2837\n",
      "Epoch 189/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2077 - mae: 0.3650 - mse: 0.2077 - val_loss: 0.2845 - val_mae: 0.4240 - val_mse: 0.2845\n",
      "Epoch 190/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2072 - mae: 0.3648 - mse: 0.2072 - val_loss: 0.2819 - val_mae: 0.4208 - val_mse: 0.2819\n",
      "Epoch 191/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2074 - mae: 0.3648 - mse: 0.2074 - val_loss: 0.2828 - val_mae: 0.4221 - val_mse: 0.2828\n",
      "Epoch 192/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2071 - mae: 0.3645 - mse: 0.2071 - val_loss: 0.2814 - val_mae: 0.4206 - val_mse: 0.2814\n",
      "Epoch 193/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.2071 - mae: 0.3645 - mse: 0.2071 - val_loss: 0.2804 - val_mae: 0.4193 - val_mse: 0.2804\n",
      "Epoch 194/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2073 - mae: 0.3644 - mse: 0.2073 - val_loss: 0.2810 - val_mae: 0.4205 - val_mse: 0.2810\n",
      "Epoch 195/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2067 - mae: 0.3641 - mse: 0.2067 - val_loss: 0.2809 - val_mae: 0.4205 - val_mse: 0.2809\n",
      "Epoch 196/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2068 - mae: 0.3644 - mse: 0.2068 - val_loss: 0.2817 - val_mae: 0.4218 - val_mse: 0.2817\n",
      "Epoch 197/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.2066 - mae: 0.3638 - mse: 0.2066 - val_loss: 0.2825 - val_mae: 0.4231 - val_mse: 0.2825\n",
      "Epoch 198/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2066 - mae: 0.3642 - mse: 0.2066 - val_loss: 0.2818 - val_mae: 0.4223 - val_mse: 0.2818\n",
      "Epoch 199/500\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.2061 - mae: 0.3639 - mse: 0.2061 - val_loss: 0.2784 - val_mae: 0.4180 - val_mse: 0.2784\n",
      "Epoch 200/500\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.2065 - mae: 0.3641 - mse: 0.2065 - val_loss: 0.2803 - val_mae: 0.4209 - val_mse: 0.2803\n",
      "Epoch 201/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.2058 - mae: 0.3633 - mse: 0.2058 - val_loss: 0.2775 - val_mae: 0.4171 - val_mse: 0.2775\n",
      "Epoch 202/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.2061 - mae: 0.3635 - mse: 0.2061 - val_loss: 0.2782 - val_mae: 0.4183 - val_mse: 0.2782\n",
      "Epoch 203/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.2060 - mae: 0.3637 - mse: 0.2060 - val_loss: 0.2782 - val_mae: 0.4186 - val_mse: 0.2782\n",
      "Epoch 204/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.2062 - mae: 0.3637 - mse: 0.2062 - val_loss: 0.2777 - val_mae: 0.4180 - val_mse: 0.2777\n",
      "Epoch 205/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.3632 - mse: 0.2059 - val_loss: 0.2784 - val_mae: 0.4191 - val_mse: 0.2784\n",
      "Epoch 206/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2054 - mae: 0.3632 - mse: 0.2054 - val_loss: 0.2777 - val_mae: 0.4184 - val_mse: 0.2777\n",
      "Epoch 207/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2056 - mae: 0.3627 - mse: 0.2056 - val_loss: 0.2756 - val_mae: 0.4154 - val_mse: 0.2756\n",
      "Epoch 208/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2054 - mae: 0.3629 - mse: 0.2054 - val_loss: 0.2776 - val_mae: 0.4187 - val_mse: 0.2776\n",
      "Epoch 209/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2052 - mae: 0.3627 - mse: 0.2052 - val_loss: 0.2768 - val_mae: 0.4177 - val_mse: 0.2768\n",
      "Epoch 210/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2052 - mae: 0.3627 - mse: 0.2052 - val_loss: 0.2751 - val_mae: 0.4152 - val_mse: 0.2751\n",
      "Epoch 211/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2055 - mae: 0.3634 - mse: 0.2055 - val_loss: 0.2745 - val_mae: 0.4144 - val_mse: 0.2745\n",
      "Epoch 212/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2050 - mae: 0.3626 - mse: 0.2050 - val_loss: 0.2753 - val_mae: 0.4161 - val_mse: 0.2753\n",
      "Epoch 213/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2046 - mae: 0.3621 - mse: 0.2046 - val_loss: 0.2748 - val_mae: 0.4155 - val_mse: 0.2748\n",
      "Epoch 214/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2045 - mae: 0.3621 - mse: 0.2045 - val_loss: 0.2768 - val_mae: 0.4185 - val_mse: 0.2768\n",
      "Epoch 215/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2043 - mae: 0.3619 - mse: 0.2043 - val_loss: 0.2776 - val_mae: 0.4196 - val_mse: 0.2776\n",
      "Epoch 216/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2043 - mae: 0.3622 - mse: 0.2043 - val_loss: 0.2731 - val_mae: 0.4131 - val_mse: 0.2731\n",
      "Epoch 217/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2041 - mae: 0.3616 - mse: 0.2041 - val_loss: 0.2756 - val_mae: 0.4173 - val_mse: 0.2756\n",
      "Epoch 218/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2043 - mae: 0.3618 - mse: 0.2043 - val_loss: 0.2732 - val_mae: 0.4137 - val_mse: 0.2732\n",
      "Epoch 219/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.2037 - mae: 0.3613 - mse: 0.2037 - val_loss: 0.2759 - val_mae: 0.4180 - val_mse: 0.2759\n",
      "Epoch 220/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2037 - mae: 0.3615 - mse: 0.2037 - val_loss: 0.2753 - val_mae: 0.4173 - val_mse: 0.2753\n",
      "Epoch 221/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2038 - mae: 0.3616 - mse: 0.2038 - val_loss: 0.2744 - val_mae: 0.4162 - val_mse: 0.2744\n",
      "Epoch 222/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2037 - mae: 0.3614 - mse: 0.2037 - val_loss: 0.2724 - val_mae: 0.4131 - val_mse: 0.2724\n",
      "Epoch 223/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2034 - mae: 0.3610 - mse: 0.2034 - val_loss: 0.2747 - val_mae: 0.4168 - val_mse: 0.2747\n",
      "Epoch 224/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2034 - mae: 0.3610 - mse: 0.2034 - val_loss: 0.2734 - val_mae: 0.4152 - val_mse: 0.2734\n",
      "Epoch 225/500\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.2031 - mae: 0.3608 - mse: 0.2031 - val_loss: 0.2740 - val_mae: 0.4161 - val_mse: 0.2740\n",
      "Epoch 226/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2029 - mae: 0.3606 - mse: 0.2029 - val_loss: 0.2751 - val_mae: 0.4176 - val_mse: 0.2751\n",
      "Epoch 227/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2031 - mae: 0.3609 - mse: 0.2031 - val_loss: 0.2763 - val_mae: 0.4192 - val_mse: 0.2763\n",
      "Epoch 228/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2029 - mae: 0.3605 - mse: 0.2029 - val_loss: 0.2741 - val_mae: 0.4166 - val_mse: 0.2741\n",
      "Epoch 229/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2028 - mae: 0.3606 - mse: 0.2028 - val_loss: 0.2739 - val_mae: 0.4165 - val_mse: 0.2739\n",
      "Epoch 230/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2027 - mae: 0.3604 - mse: 0.2027 - val_loss: 0.2727 - val_mae: 0.4150 - val_mse: 0.2727\n",
      "Epoch 231/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.2025 - mae: 0.3603 - mse: 0.2025 - val_loss: 0.2714 - val_mae: 0.4132 - val_mse: 0.2714\n",
      "Epoch 232/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2025 - mae: 0.3599 - mse: 0.2025 - val_loss: 0.2726 - val_mae: 0.4151 - val_mse: 0.2726\n",
      "Epoch 233/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2026 - mae: 0.3603 - mse: 0.2026 - val_loss: 0.2745 - val_mae: 0.4175 - val_mse: 0.2745\n",
      "Epoch 234/500\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.2022 - mae: 0.3598 - mse: 0.2022 - val_loss: 0.2715 - val_mae: 0.4138 - val_mse: 0.2715\n",
      "Epoch 235/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.2020 - mae: 0.3598 - mse: 0.2020 - val_loss: 0.2716 - val_mae: 0.4140 - val_mse: 0.2716\n",
      "Epoch 236/500\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.2020 - mae: 0.3599 - mse: 0.2020 - val_loss: 0.2704 - val_mae: 0.4124 - val_mse: 0.2704\n",
      "Epoch 237/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2020 - mae: 0.3599 - mse: 0.2020 - val_loss: 0.2716 - val_mae: 0.4143 - val_mse: 0.2716\n",
      "Epoch 238/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2019 - mae: 0.3597 - mse: 0.2019 - val_loss: 0.2724 - val_mae: 0.4155 - val_mse: 0.2724\n",
      "Epoch 239/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2020 - mae: 0.3598 - mse: 0.2020 - val_loss: 0.2696 - val_mae: 0.4116 - val_mse: 0.2696\n",
      "Epoch 240/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.2018 - mae: 0.3596 - mse: 0.2018 - val_loss: 0.2695 - val_mae: 0.4115 - val_mse: 0.2695\n",
      "Epoch 241/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.2014 - mae: 0.3592 - mse: 0.2014 - val_loss: 0.2748 - val_mae: 0.4188 - val_mse: 0.2748\n",
      "Epoch 242/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2014 - mae: 0.3590 - mse: 0.2014 - val_loss: 0.2694 - val_mae: 0.4117 - val_mse: 0.2694\n",
      "Epoch 243/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.2013 - mae: 0.3592 - mse: 0.2013 - val_loss: 0.2715 - val_mae: 0.4147 - val_mse: 0.2715\n",
      "Epoch 244/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2010 - mae: 0.3588 - mse: 0.2010 - val_loss: 0.2687 - val_mae: 0.4108 - val_mse: 0.2687\n",
      "Epoch 245/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2015 - mae: 0.3593 - mse: 0.2015 - val_loss: 0.2710 - val_mae: 0.4143 - val_mse: 0.2710\n",
      "Epoch 246/500\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.2010 - mae: 0.3590 - mse: 0.2010 - val_loss: 0.2679 - val_mae: 0.4096 - val_mse: 0.2679\n",
      "Epoch 247/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2008 - mae: 0.3590 - mse: 0.2008 - val_loss: 0.2690 - val_mae: 0.4117 - val_mse: 0.2690\n",
      "Epoch 248/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2008 - mae: 0.3586 - mse: 0.2008 - val_loss: 0.2698 - val_mae: 0.4131 - val_mse: 0.2698\n",
      "Epoch 249/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.2005 - mae: 0.3585 - mse: 0.2005 - val_loss: 0.2713 - val_mae: 0.4151 - val_mse: 0.2713\n",
      "Epoch 250/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2006 - mae: 0.3587 - mse: 0.2006 - val_loss: 0.2691 - val_mae: 0.4122 - val_mse: 0.2691\n",
      "Epoch 251/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2004 - mae: 0.3585 - mse: 0.2004 - val_loss: 0.2698 - val_mae: 0.4133 - val_mse: 0.2698\n",
      "Epoch 252/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.2002 - mae: 0.3582 - mse: 0.2002 - val_loss: 0.2699 - val_mae: 0.4135 - val_mse: 0.2699\n",
      "Epoch 253/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2000 - mae: 0.3581 - mse: 0.2000 - val_loss: 0.2695 - val_mae: 0.4132 - val_mse: 0.2695\n",
      "Epoch 254/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1999 - mae: 0.3578 - mse: 0.1999 - val_loss: 0.2715 - val_mae: 0.4159 - val_mse: 0.2715\n",
      "Epoch 255/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1997 - mae: 0.3580 - mse: 0.1997 - val_loss: 0.2680 - val_mae: 0.4112 - val_mse: 0.2680\n",
      "Epoch 256/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1998 - mae: 0.3578 - mse: 0.1998 - val_loss: 0.2709 - val_mae: 0.4153 - val_mse: 0.2709\n",
      "Epoch 257/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2000 - mae: 0.3577 - mse: 0.2000 - val_loss: 0.2720 - val_mae: 0.4166 - val_mse: 0.2720\n",
      "Epoch 258/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2002 - mae: 0.3585 - mse: 0.2002 - val_loss: 0.2691 - val_mae: 0.4129 - val_mse: 0.2691\n",
      "Epoch 259/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1995 - mae: 0.3574 - mse: 0.1995 - val_loss: 0.2672 - val_mae: 0.4105 - val_mse: 0.2672\n",
      "Epoch 260/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1993 - mae: 0.3576 - mse: 0.1993 - val_loss: 0.2671 - val_mae: 0.4104 - val_mse: 0.2671\n",
      "Epoch 261/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1994 - mae: 0.3574 - mse: 0.1994 - val_loss: 0.2648 - val_mae: 0.4051 - val_mse: 0.2648\n",
      "Epoch 262/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1995 - mae: 0.3580 - mse: 0.1995 - val_loss: 0.2707 - val_mae: 0.4153 - val_mse: 0.2707\n",
      "Epoch 263/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1994 - mae: 0.3576 - mse: 0.1994 - val_loss: 0.2708 - val_mae: 0.4156 - val_mse: 0.2708\n",
      "Epoch 264/500\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.1989 - mae: 0.3570 - mse: 0.1989 - val_loss: 0.2654 - val_mae: 0.4079 - val_mse: 0.2654\n",
      "Epoch 265/500\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.1988 - mae: 0.3569 - mse: 0.1988 - val_loss: 0.2651 - val_mae: 0.4075 - val_mse: 0.2651\n",
      "Epoch 266/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1989 - mae: 0.3574 - mse: 0.1989 - val_loss: 0.2667 - val_mae: 0.4104 - val_mse: 0.2667\n",
      "Epoch 267/500\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.1985 - mae: 0.3568 - mse: 0.1985 - val_loss: 0.2668 - val_mae: 0.4106 - val_mse: 0.2668\n",
      "Epoch 268/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1989 - mae: 0.3575 - mse: 0.1989 - val_loss: 0.2642 - val_mae: 0.4054 - val_mse: 0.2642\n",
      "Epoch 269/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1984 - mae: 0.3566 - mse: 0.1984 - val_loss: 0.2710 - val_mae: 0.4162 - val_mse: 0.2710\n",
      "Epoch 270/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1985 - mae: 0.3564 - mse: 0.1985 - val_loss: 0.2659 - val_mae: 0.4096 - val_mse: 0.2659\n",
      "Epoch 271/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1992 - mae: 0.3576 - mse: 0.1992 - val_loss: 0.2663 - val_mae: 0.4101 - val_mse: 0.2663\n",
      "Epoch 272/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1985 - mae: 0.3568 - mse: 0.1985 - val_loss: 0.2641 - val_mae: 0.4066 - val_mse: 0.2641\n",
      "Epoch 273/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1982 - mae: 0.3565 - mse: 0.1982 - val_loss: 0.2655 - val_mae: 0.4092 - val_mse: 0.2655\n",
      "Epoch 274/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1980 - mae: 0.3566 - mse: 0.1980 - val_loss: 0.2645 - val_mae: 0.4077 - val_mse: 0.2645\n",
      "Epoch 275/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1976 - mae: 0.3559 - mse: 0.1976 - val_loss: 0.2688 - val_mae: 0.4137 - val_mse: 0.2688\n",
      "Epoch 276/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1975 - mae: 0.3557 - mse: 0.1975 - val_loss: 0.2660 - val_mae: 0.4102 - val_mse: 0.2660\n",
      "Epoch 277/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1977 - mae: 0.3564 - mse: 0.1977 - val_loss: 0.2632 - val_mae: 0.4054 - val_mse: 0.2632\n",
      "Epoch 278/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1981 - mae: 0.3564 - mse: 0.1981 - val_loss: 0.2634 - val_mae: 0.4062 - val_mse: 0.2634\n",
      "Epoch 279/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1984 - mae: 0.3566 - mse: 0.1984 - val_loss: 0.2675 - val_mae: 0.4123 - val_mse: 0.2675\n",
      "Epoch 280/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1971 - mae: 0.3557 - mse: 0.1971 - val_loss: 0.2639 - val_mae: 0.4073 - val_mse: 0.2639\n",
      "Epoch 281/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1968 - mae: 0.3553 - mse: 0.1968 - val_loss: 0.2647 - val_mae: 0.4087 - val_mse: 0.2647\n",
      "Epoch 282/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1972 - mae: 0.3560 - mse: 0.1972 - val_loss: 0.2705 - val_mae: 0.4161 - val_mse: 0.2705\n",
      "Epoch 283/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1969 - mae: 0.3558 - mse: 0.1969 - val_loss: 0.2641 - val_mae: 0.4079 - val_mse: 0.2641\n",
      "Epoch 284/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1968 - mae: 0.3552 - mse: 0.1968 - val_loss: 0.2667 - val_mae: 0.4116 - val_mse: 0.2667\n",
      "Epoch 285/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1966 - mae: 0.3552 - mse: 0.1966 - val_loss: 0.2644 - val_mae: 0.4085 - val_mse: 0.2644\n",
      "Epoch 286/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1964 - mae: 0.3546 - mse: 0.1964 - val_loss: 0.2625 - val_mae: 0.4056 - val_mse: 0.2625\n",
      "Epoch 287/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1963 - mae: 0.3551 - mse: 0.1963 - val_loss: 0.2645 - val_mae: 0.4087 - val_mse: 0.2645\n",
      "Epoch 288/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1963 - mae: 0.3547 - mse: 0.1963 - val_loss: 0.2617 - val_mae: 0.4038 - val_mse: 0.2617\n",
      "Epoch 289/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1961 - mae: 0.3550 - mse: 0.1961 - val_loss: 0.2732 - val_mae: 0.4196 - val_mse: 0.2732\n",
      "Epoch 290/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1961 - mae: 0.3544 - mse: 0.1961 - val_loss: 0.2629 - val_mae: 0.4066 - val_mse: 0.2629\n",
      "Epoch 291/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1960 - mae: 0.3548 - mse: 0.1960 - val_loss: 0.2642 - val_mae: 0.4087 - val_mse: 0.2642\n",
      "Epoch 292/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1963 - mae: 0.3551 - mse: 0.1963 - val_loss: 0.2688 - val_mae: 0.4146 - val_mse: 0.2688\n",
      "Epoch 293/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1959 - mae: 0.3544 - mse: 0.1959 - val_loss: 0.2658 - val_mae: 0.4109 - val_mse: 0.2658\n",
      "Epoch 294/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1956 - mae: 0.3542 - mse: 0.1956 - val_loss: 0.2621 - val_mae: 0.4057 - val_mse: 0.2621\n",
      "Epoch 295/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1958 - mae: 0.3545 - mse: 0.1958 - val_loss: 0.2628 - val_mae: 0.4069 - val_mse: 0.2628\n",
      "Epoch 296/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1954 - mae: 0.3542 - mse: 0.1954 - val_loss: 0.2631 - val_mae: 0.4073 - val_mse: 0.2631\n",
      "Epoch 297/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1950 - mae: 0.3538 - mse: 0.1950 - val_loss: 0.2613 - val_mae: 0.4046 - val_mse: 0.2613\n",
      "Epoch 298/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1952 - mae: 0.3538 - mse: 0.1952 - val_loss: 0.2617 - val_mae: 0.4054 - val_mse: 0.2617\n",
      "Epoch 299/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1951 - mae: 0.3538 - mse: 0.1951 - val_loss: 0.2659 - val_mae: 0.4113 - val_mse: 0.2659\n",
      "Epoch 300/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1946 - mae: 0.3533 - mse: 0.1946 - val_loss: 0.2611 - val_mae: 0.4046 - val_mse: 0.2611\n",
      "Epoch 301/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1946 - mae: 0.3533 - mse: 0.1946 - val_loss: 0.2644 - val_mae: 0.4095 - val_mse: 0.2644\n",
      "Epoch 302/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1942 - mae: 0.3529 - mse: 0.1942 - val_loss: 0.2606 - val_mae: 0.4038 - val_mse: 0.2606\n",
      "Epoch 303/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1943 - mae: 0.3532 - mse: 0.1943 - val_loss: 0.2632 - val_mae: 0.4080 - val_mse: 0.2632\n",
      "Epoch 304/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1945 - mae: 0.3530 - mse: 0.1945 - val_loss: 0.2595 - val_mae: 0.4007 - val_mse: 0.2595\n",
      "Epoch 305/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1945 - mae: 0.3531 - mse: 0.1945 - val_loss: 0.2622 - val_mae: 0.4066 - val_mse: 0.2622\n",
      "Epoch 306/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1943 - mae: 0.3532 - mse: 0.1943 - val_loss: 0.2656 - val_mae: 0.4112 - val_mse: 0.2656\n",
      "Epoch 307/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1936 - mae: 0.3528 - mse: 0.1936 - val_loss: 0.2606 - val_mae: 0.4044 - val_mse: 0.2606\n",
      "Epoch 308/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1937 - mae: 0.3526 - mse: 0.1937 - val_loss: 0.2613 - val_mae: 0.4056 - val_mse: 0.2613\n",
      "Epoch 309/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1941 - mae: 0.3534 - mse: 0.1941 - val_loss: 0.2621 - val_mae: 0.4068 - val_mse: 0.2621\n",
      "Epoch 310/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1934 - mae: 0.3530 - mse: 0.1934 - val_loss: 0.2590 - val_mae: 0.4011 - val_mse: 0.2590\n",
      "Epoch 311/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1940 - mae: 0.3526 - mse: 0.1940 - val_loss: 0.2605 - val_mae: 0.4045 - val_mse: 0.2605\n",
      "Epoch 312/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1932 - mae: 0.3522 - mse: 0.1932 - val_loss: 0.2638 - val_mae: 0.4091 - val_mse: 0.2638\n",
      "Epoch 313/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1934 - mae: 0.3519 - mse: 0.1934 - val_loss: 0.2600 - val_mae: 0.4038 - val_mse: 0.2600\n",
      "Epoch 314/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1930 - mae: 0.3521 - mse: 0.1930 - val_loss: 0.2604 - val_mae: 0.4045 - val_mse: 0.2604\n",
      "Epoch 315/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1929 - mae: 0.3521 - mse: 0.1929 - val_loss: 0.2627 - val_mae: 0.4079 - val_mse: 0.2627\n",
      "Epoch 316/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1931 - mae: 0.3519 - mse: 0.1931 - val_loss: 0.2638 - val_mae: 0.4093 - val_mse: 0.2638\n",
      "Epoch 317/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1929 - mae: 0.3513 - mse: 0.1929 - val_loss: 0.2589 - val_mae: 0.4021 - val_mse: 0.2589\n",
      "Epoch 318/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1925 - mae: 0.3518 - mse: 0.1925 - val_loss: 0.2625 - val_mae: 0.4077 - val_mse: 0.2625\n",
      "Epoch 319/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1925 - mae: 0.3517 - mse: 0.1925 - val_loss: 0.2628 - val_mae: 0.4081 - val_mse: 0.2628\n",
      "Epoch 320/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1935 - mae: 0.3526 - mse: 0.1935 - val_loss: 0.2604 - val_mae: 0.4050 - val_mse: 0.2604\n",
      "Epoch 321/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1919 - mae: 0.3511 - mse: 0.1919 - val_loss: 0.2614 - val_mae: 0.4065 - val_mse: 0.2614\n",
      "Epoch 322/500\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.1926 - mae: 0.3516 - mse: 0.1926 - val_loss: 0.2610 - val_mae: 0.4059 - val_mse: 0.2610\n",
      "Epoch 323/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1917 - mae: 0.3509 - mse: 0.1917 - val_loss: 0.2596 - val_mae: 0.4039 - val_mse: 0.2596\n",
      "Epoch 324/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1918 - mae: 0.3511 - mse: 0.1918 - val_loss: 0.2583 - val_mae: 0.4018 - val_mse: 0.2583\n",
      "Epoch 325/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1917 - mae: 0.3513 - mse: 0.1917 - val_loss: 0.2621 - val_mae: 0.4075 - val_mse: 0.2621\n",
      "Epoch 326/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1914 - mae: 0.3507 - mse: 0.1914 - val_loss: 0.2590 - val_mae: 0.4032 - val_mse: 0.2590\n",
      "Epoch 327/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1913 - mae: 0.3506 - mse: 0.1913 - val_loss: 0.2621 - val_mae: 0.4076 - val_mse: 0.2621\n",
      "Epoch 328/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1913 - mae: 0.3507 - mse: 0.1913 - val_loss: 0.2604 - val_mae: 0.4053 - val_mse: 0.2604\n",
      "Epoch 329/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1910 - mae: 0.3506 - mse: 0.1910 - val_loss: 0.2588 - val_mae: 0.4031 - val_mse: 0.2588\n",
      "Epoch 330/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1923 - mae: 0.3512 - mse: 0.1923 - val_loss: 0.2565 - val_mae: 0.3982 - val_mse: 0.2565\n",
      "Epoch 331/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1910 - mae: 0.3508 - mse: 0.1910 - val_loss: 0.2619 - val_mae: 0.4075 - val_mse: 0.2619\n",
      "Epoch 332/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1905 - mae: 0.3497 - mse: 0.1905 - val_loss: 0.2583 - val_mae: 0.4024 - val_mse: 0.2583\n",
      "Epoch 333/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1907 - mae: 0.3505 - mse: 0.1907 - val_loss: 0.2622 - val_mae: 0.4081 - val_mse: 0.2622\n",
      "Epoch 334/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1905 - mae: 0.3499 - mse: 0.1905 - val_loss: 0.2589 - val_mae: 0.4035 - val_mse: 0.2589\n",
      "Epoch 335/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1906 - mae: 0.3502 - mse: 0.1906 - val_loss: 0.2599 - val_mae: 0.4050 - val_mse: 0.2599\n",
      "Epoch 336/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1899 - mae: 0.3497 - mse: 0.1899 - val_loss: 0.2566 - val_mae: 0.3997 - val_mse: 0.2566\n",
      "Epoch 337/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1903 - mae: 0.3496 - mse: 0.1903 - val_loss: 0.2628 - val_mae: 0.4090 - val_mse: 0.2628\n",
      "Epoch 338/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1900 - mae: 0.3495 - mse: 0.1900 - val_loss: 0.2574 - val_mae: 0.4012 - val_mse: 0.2574\n",
      "Epoch 339/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1899 - mae: 0.3499 - mse: 0.1899 - val_loss: 0.2605 - val_mae: 0.4059 - val_mse: 0.2605\n",
      "Epoch 340/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1898 - mae: 0.3491 - mse: 0.1898 - val_loss: 0.2586 - val_mae: 0.4034 - val_mse: 0.2586\n",
      "Epoch 341/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1895 - mae: 0.3490 - mse: 0.1895 - val_loss: 0.2597 - val_mae: 0.4048 - val_mse: 0.2597\n",
      "Epoch 342/500\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.1895 - mae: 0.3491 - mse: 0.1895 - val_loss: 0.2610 - val_mae: 0.4068 - val_mse: 0.2610\n",
      "Epoch 343/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1897 - mae: 0.3497 - mse: 0.1897 - val_loss: 0.2591 - val_mae: 0.4042 - val_mse: 0.2591\n",
      "Epoch 344/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1894 - mae: 0.3489 - mse: 0.1894 - val_loss: 0.2567 - val_mae: 0.4006 - val_mse: 0.2567\n",
      "Epoch 345/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1892 - mae: 0.3491 - mse: 0.1892 - val_loss: 0.2626 - val_mae: 0.4091 - val_mse: 0.2626\n",
      "Epoch 346/500\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.1888 - mae: 0.3486 - mse: 0.1888 - val_loss: 0.2568 - val_mae: 0.4008 - val_mse: 0.2568\n",
      "Epoch 347/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1889 - mae: 0.3485 - mse: 0.1889 - val_loss: 0.2577 - val_mae: 0.4022 - val_mse: 0.2577\n",
      "Epoch 348/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1888 - mae: 0.3486 - mse: 0.1888 - val_loss: 0.2569 - val_mae: 0.4010 - val_mse: 0.2569\n",
      "Epoch 349/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1887 - mae: 0.3484 - mse: 0.1887 - val_loss: 0.2576 - val_mae: 0.4021 - val_mse: 0.2576\n",
      "Epoch 350/500\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.1884 - mae: 0.3482 - mse: 0.1884 - val_loss: 0.2563 - val_mae: 0.4002 - val_mse: 0.2563\n",
      "Epoch 351/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1882 - mae: 0.3482 - mse: 0.1882 - val_loss: 0.2584 - val_mae: 0.4034 - val_mse: 0.2584\n",
      "Epoch 352/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1882 - mae: 0.3481 - mse: 0.1882 - val_loss: 0.2558 - val_mae: 0.3994 - val_mse: 0.2558\n",
      "Epoch 353/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1880 - mae: 0.3481 - mse: 0.1880 - val_loss: 0.2583 - val_mae: 0.4033 - val_mse: 0.2583\n",
      "Epoch 354/500\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.1883 - mae: 0.3483 - mse: 0.1883 - val_loss: 0.2540 - val_mae: 0.3962 - val_mse: 0.2540\n",
      "Epoch 355/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1882 - mae: 0.3484 - mse: 0.1882 - val_loss: 0.2558 - val_mae: 0.3996 - val_mse: 0.2558\n",
      "Epoch 356/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1876 - mae: 0.3476 - mse: 0.1876 - val_loss: 0.2574 - val_mae: 0.4020 - val_mse: 0.2574\n",
      "Epoch 357/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1881 - mae: 0.3480 - mse: 0.1881 - val_loss: 0.2568 - val_mae: 0.4012 - val_mse: 0.2568\n",
      "Epoch 358/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1881 - mae: 0.3479 - mse: 0.1881 - val_loss: 0.2550 - val_mae: 0.3984 - val_mse: 0.2550\n",
      "Epoch 359/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1875 - mae: 0.3474 - mse: 0.1875 - val_loss: 0.2564 - val_mae: 0.4006 - val_mse: 0.2564\n",
      "Epoch 360/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1870 - mae: 0.3470 - mse: 0.1870 - val_loss: 0.2583 - val_mae: 0.4035 - val_mse: 0.2583\n",
      "Epoch 361/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1872 - mae: 0.3474 - mse: 0.1872 - val_loss: 0.2561 - val_mae: 0.4003 - val_mse: 0.2561\n",
      "Epoch 362/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1868 - mae: 0.3468 - mse: 0.1868 - val_loss: 0.2571 - val_mae: 0.4017 - val_mse: 0.2571\n",
      "Epoch 363/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1865 - mae: 0.3462 - mse: 0.1865 - val_loss: 0.2543 - val_mae: 0.3976 - val_mse: 0.2543\n",
      "Epoch 364/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1870 - mae: 0.3465 - mse: 0.1870 - val_loss: 0.2542 - val_mae: 0.3974 - val_mse: 0.2542\n",
      "Epoch 365/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1867 - mae: 0.3464 - mse: 0.1867 - val_loss: 0.2555 - val_mae: 0.3994 - val_mse: 0.2555\n",
      "Epoch 366/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1863 - mae: 0.3466 - mse: 0.1863 - val_loss: 0.2558 - val_mae: 0.4001 - val_mse: 0.2558\n",
      "Epoch 367/500\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.1860 - mae: 0.3458 - mse: 0.1860 - val_loss: 0.2548 - val_mae: 0.3984 - val_mse: 0.2548\n",
      "Epoch 368/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1861 - mae: 0.3461 - mse: 0.1861 - val_loss: 0.2570 - val_mae: 0.4019 - val_mse: 0.2570\n",
      "Epoch 369/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1861 - mae: 0.3461 - mse: 0.1861 - val_loss: 0.2535 - val_mae: 0.3966 - val_mse: 0.2535\n",
      "Epoch 370/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1856 - mae: 0.3459 - mse: 0.1856 - val_loss: 0.2575 - val_mae: 0.4026 - val_mse: 0.2575\n",
      "Epoch 371/500\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.1837 - mae: 0.3425 - mse: 0.183 - 0s 3ms/step - loss: 0.1859 - mae: 0.3458 - mse: 0.1859 - val_loss: 0.2529 - val_mae: 0.3957 - val_mse: 0.2529\n",
      "Epoch 372/500\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.1856 - mae: 0.3459 - mse: 0.1856 - val_loss: 0.2554 - val_mae: 0.3996 - val_mse: 0.2554\n",
      "Epoch 373/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1853 - mae: 0.3449 - mse: 0.1853 - val_loss: 0.2539 - val_mae: 0.3972 - val_mse: 0.2539\n",
      "Epoch 374/500\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.1852 - mae: 0.3451 - mse: 0.1852 - val_loss: 0.2561 - val_mae: 0.4006 - val_mse: 0.2561\n",
      "Epoch 375/500\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.1851 - mae: 0.3454 - mse: 0.1851 - val_loss: 0.2550 - val_mae: 0.3990 - val_mse: 0.2550\n",
      "Epoch 376/500\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.1849 - mae: 0.3450 - mse: 0.1849 - val_loss: 0.2547 - val_mae: 0.3987 - val_mse: 0.2547\n",
      "Epoch 377/500\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.1870 - mae: 0.3468 - mse: 0.187 - 0s 8ms/step - loss: 0.1850 - mae: 0.3454 - mse: 0.1850 - val_loss: 0.2564 - val_mae: 0.4012 - val_mse: 0.2564\n",
      "Epoch 378/500\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.1846 - mae: 0.3449 - mse: 0.1846 - val_loss: 0.2558 - val_mae: 0.4004 - val_mse: 0.2558\n",
      "Epoch 379/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1847 - mae: 0.3450 - mse: 0.1847 - val_loss: 0.2522 - val_mae: 0.3950 - val_mse: 0.2522\n",
      "Epoch 380/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1843 - mae: 0.3446 - mse: 0.1843 - val_loss: 0.2532 - val_mae: 0.3963 - val_mse: 0.2532\n",
      "Epoch 381/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1842 - mae: 0.3444 - mse: 0.1842 - val_loss: 0.2529 - val_mae: 0.3960 - val_mse: 0.2529\n",
      "Epoch 382/500\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.1842 - mae: 0.3446 - mse: 0.1842 - val_loss: 0.2547 - val_mae: 0.3988 - val_mse: 0.2547\n",
      "Epoch 383/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1839 - mae: 0.3444 - mse: 0.1839 - val_loss: 0.2517 - val_mae: 0.3944 - val_mse: 0.2517\n",
      "Epoch 384/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1843 - mae: 0.3447 - mse: 0.1843 - val_loss: 0.2558 - val_mae: 0.4005 - val_mse: 0.2558\n",
      "Epoch 385/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1839 - mae: 0.3440 - mse: 0.1839 - val_loss: 0.2535 - val_mae: 0.3970 - val_mse: 0.2535\n",
      "Epoch 386/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1836 - mae: 0.3438 - mse: 0.1836 - val_loss: 0.2525 - val_mae: 0.3955 - val_mse: 0.2525\n",
      "Epoch 387/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1836 - mae: 0.3439 - mse: 0.1836 - val_loss: 0.2526 - val_mae: 0.3957 - val_mse: 0.2526\n",
      "Epoch 388/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1838 - mae: 0.3442 - mse: 0.1838 - val_loss: 0.2578 - val_mae: 0.4037 - val_mse: 0.2578\n",
      "Epoch 389/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1835 - mae: 0.3441 - mse: 0.1835 - val_loss: 0.2512 - val_mae: 0.3936 - val_mse: 0.2512\n",
      "Epoch 390/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1833 - mae: 0.3438 - mse: 0.1833 - val_loss: 0.2535 - val_mae: 0.3970 - val_mse: 0.2535\n",
      "Epoch 391/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1829 - mae: 0.3431 - mse: 0.1829 - val_loss: 0.2512 - val_mae: 0.3939 - val_mse: 0.2512\n",
      "Epoch 392/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1834 - mae: 0.3437 - mse: 0.1834 - val_loss: 0.2573 - val_mae: 0.4030 - val_mse: 0.2573\n",
      "Epoch 393/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1830 - mae: 0.3431 - mse: 0.1830 - val_loss: 0.2539 - val_mae: 0.3979 - val_mse: 0.2539\n",
      "Epoch 394/500\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.1826 - mae: 0.3430 - mse: 0.1826 - val_loss: 0.2516 - val_mae: 0.3944 - val_mse: 0.2516\n",
      "Epoch 395/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1825 - mae: 0.3431 - mse: 0.1825 - val_loss: 0.2532 - val_mae: 0.3968 - val_mse: 0.2532\n",
      "Epoch 396/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1827 - mae: 0.3432 - mse: 0.1827 - val_loss: 0.2534 - val_mae: 0.3971 - val_mse: 0.2534\n",
      "Epoch 397/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1829 - mae: 0.3434 - mse: 0.1829 - val_loss: 0.2528 - val_mae: 0.3963 - val_mse: 0.2528\n",
      "Epoch 398/500\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.1824 - mae: 0.3424 - mse: 0.1824 - val_loss: 0.2503 - val_mae: 0.3923 - val_mse: 0.2503\n",
      "Epoch 399/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1823 - mae: 0.3429 - mse: 0.1823 - val_loss: 0.2567 - val_mae: 0.4023 - val_mse: 0.2567\n",
      "Epoch 400/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1828 - mae: 0.3435 - mse: 0.1828 - val_loss: 0.2521 - val_mae: 0.3952 - val_mse: 0.2521\n",
      "Epoch 401/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1832 - mae: 0.3432 - mse: 0.1832 - val_loss: 0.2512 - val_mae: 0.3917 - val_mse: 0.2512\n",
      "Epoch 402/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1820 - mae: 0.3422 - mse: 0.1820 - val_loss: 0.2579 - val_mae: 0.4040 - val_mse: 0.2579\n",
      "Epoch 403/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1823 - mae: 0.3425 - mse: 0.1823 - val_loss: 0.2505 - val_mae: 0.3930 - val_mse: 0.2505\n",
      "Epoch 404/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1820 - mae: 0.3425 - mse: 0.1820 - val_loss: 0.2585 - val_mae: 0.4049 - val_mse: 0.2585\n",
      "Epoch 405/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1816 - mae: 0.3423 - mse: 0.1816 - val_loss: 0.2497 - val_mae: 0.3917 - val_mse: 0.2497\n",
      "Epoch 406/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1815 - mae: 0.3426 - mse: 0.1815 - val_loss: 0.2548 - val_mae: 0.3997 - val_mse: 0.2548\n",
      "Epoch 407/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1813 - mae: 0.3417 - mse: 0.1813 - val_loss: 0.2511 - val_mae: 0.3939 - val_mse: 0.2511\n",
      "Epoch 408/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1812 - mae: 0.3419 - mse: 0.1812 - val_loss: 0.2517 - val_mae: 0.3949 - val_mse: 0.2517\n",
      "Epoch 409/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1812 - mae: 0.3417 - mse: 0.1812 - val_loss: 0.2498 - val_mae: 0.3921 - val_mse: 0.2498\n",
      "Epoch 410/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1819 - mae: 0.3428 - mse: 0.1819 - val_loss: 0.2519 - val_mae: 0.3953 - val_mse: 0.2519\n",
      "Epoch 411/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1808 - mae: 0.3415 - mse: 0.1808 - val_loss: 0.2500 - val_mae: 0.3925 - val_mse: 0.2500\n",
      "Epoch 412/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1811 - mae: 0.3417 - mse: 0.1811 - val_loss: 0.2508 - val_mae: 0.3936 - val_mse: 0.2508\n",
      "Epoch 413/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1807 - mae: 0.3413 - mse: 0.1807 - val_loss: 0.2511 - val_mae: 0.3941 - val_mse: 0.2511\n",
      "Epoch 414/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1808 - mae: 0.3412 - mse: 0.1808 - val_loss: 0.2491 - val_mae: 0.3910 - val_mse: 0.2491\n",
      "Epoch 415/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1806 - mae: 0.3411 - mse: 0.1806 - val_loss: 0.2547 - val_mae: 0.3998 - val_mse: 0.2547\n",
      "Epoch 416/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1809 - mae: 0.3414 - mse: 0.1809 - val_loss: 0.2519 - val_mae: 0.3955 - val_mse: 0.2519\n",
      "Epoch 417/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1806 - mae: 0.3408 - mse: 0.1806 - val_loss: 0.2490 - val_mae: 0.3911 - val_mse: 0.2490\n",
      "Epoch 418/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1803 - mae: 0.3410 - mse: 0.1803 - val_loss: 0.2528 - val_mae: 0.3969 - val_mse: 0.2528\n",
      "Epoch 419/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1800 - mae: 0.3398 - mse: 0.1800 - val_loss: 0.2488 - val_mae: 0.3907 - val_mse: 0.2488\n",
      "Epoch 420/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1812 - mae: 0.3421 - mse: 0.1812 - val_loss: 0.2550 - val_mae: 0.4004 - val_mse: 0.2550\n",
      "Epoch 421/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1802 - mae: 0.3408 - mse: 0.1802 - val_loss: 0.2526 - val_mae: 0.3968 - val_mse: 0.2526\n",
      "Epoch 422/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1797 - mae: 0.3400 - mse: 0.1797 - val_loss: 0.2494 - val_mae: 0.3918 - val_mse: 0.2494\n",
      "Epoch 423/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1797 - mae: 0.3401 - mse: 0.1797 - val_loss: 0.2517 - val_mae: 0.3954 - val_mse: 0.2517\n",
      "Epoch 424/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1796 - mae: 0.3404 - mse: 0.1796 - val_loss: 0.2486 - val_mae: 0.3906 - val_mse: 0.2486\n",
      "Epoch 425/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1799 - mae: 0.3403 - mse: 0.1799 - val_loss: 0.2491 - val_mae: 0.3915 - val_mse: 0.2491\n",
      "Epoch 426/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1795 - mae: 0.3402 - mse: 0.1795 - val_loss: 0.2493 - val_mae: 0.3918 - val_mse: 0.2493\n",
      "Epoch 427/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1795 - mae: 0.3403 - mse: 0.1795 - val_loss: 0.2502 - val_mae: 0.3932 - val_mse: 0.2502\n",
      "Epoch 428/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1794 - mae: 0.3398 - mse: 0.1794 - val_loss: 0.2521 - val_mae: 0.3962 - val_mse: 0.2521\n",
      "Epoch 429/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1798 - mae: 0.3406 - mse: 0.1798 - val_loss: 0.2495 - val_mae: 0.3921 - val_mse: 0.2495\n",
      "Epoch 430/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1795 - mae: 0.3404 - mse: 0.1795 - val_loss: 0.2527 - val_mae: 0.3972 - val_mse: 0.2527\n",
      "Epoch 431/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1792 - mae: 0.3394 - mse: 0.1792 - val_loss: 0.2479 - val_mae: 0.3892 - val_mse: 0.2479\n",
      "Epoch 432/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1791 - mae: 0.3399 - mse: 0.1791 - val_loss: 0.2529 - val_mae: 0.3974 - val_mse: 0.2529\n",
      "Epoch 433/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1787 - mae: 0.3393 - mse: 0.1787 - val_loss: 0.2495 - val_mae: 0.3923 - val_mse: 0.2495\n",
      "Epoch 434/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1787 - mae: 0.3393 - mse: 0.1787 - val_loss: 0.2483 - val_mae: 0.3904 - val_mse: 0.2483\n",
      "Epoch 435/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1786 - mae: 0.3393 - mse: 0.1786 - val_loss: 0.2512 - val_mae: 0.3950 - val_mse: 0.2512\n",
      "Epoch 436/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1787 - mae: 0.3395 - mse: 0.1787 - val_loss: 0.2484 - val_mae: 0.3906 - val_mse: 0.2484\n",
      "Epoch 437/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1789 - mae: 0.3396 - mse: 0.1789 - val_loss: 0.2574 - val_mae: 0.4037 - val_mse: 0.2574\n",
      "Epoch 438/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1783 - mae: 0.3386 - mse: 0.1783 - val_loss: 0.2476 - val_mae: 0.3893 - val_mse: 0.2476\n",
      "Epoch 439/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1781 - mae: 0.3390 - mse: 0.1781 - val_loss: 0.2494 - val_mae: 0.3923 - val_mse: 0.2494\n",
      "Epoch 440/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1780 - mae: 0.3388 - mse: 0.1780 - val_loss: 0.2499 - val_mae: 0.3931 - val_mse: 0.2499\n",
      "Epoch 441/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1779 - mae: 0.3385 - mse: 0.1779 - val_loss: 0.2487 - val_mae: 0.3912 - val_mse: 0.2487\n",
      "Epoch 442/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1782 - mae: 0.3388 - mse: 0.1782 - val_loss: 0.2494 - val_mae: 0.3924 - val_mse: 0.2494\n",
      "Epoch 443/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1778 - mae: 0.3384 - mse: 0.1778 - val_loss: 0.2472 - val_mae: 0.3886 - val_mse: 0.2472\n",
      "Epoch 444/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1784 - mae: 0.3393 - mse: 0.1784 - val_loss: 0.2483 - val_mae: 0.3906 - val_mse: 0.2483\n",
      "Epoch 445/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1779 - mae: 0.3386 - mse: 0.1779 - val_loss: 0.2478 - val_mae: 0.3898 - val_mse: 0.2478\n",
      "Epoch 446/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1775 - mae: 0.3384 - mse: 0.1775 - val_loss: 0.2505 - val_mae: 0.3942 - val_mse: 0.2505\n",
      "Epoch 447/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1773 - mae: 0.3380 - mse: 0.1773 - val_loss: 0.2482 - val_mae: 0.3905 - val_mse: 0.2482\n",
      "Epoch 448/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1774 - mae: 0.3381 - mse: 0.1774 - val_loss: 0.2471 - val_mae: 0.3888 - val_mse: 0.2471\n",
      "Epoch 449/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1773 - mae: 0.3382 - mse: 0.1773 - val_loss: 0.2474 - val_mae: 0.3892 - val_mse: 0.2474\n",
      "Epoch 450/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1776 - mae: 0.3389 - mse: 0.1776 - val_loss: 0.2525 - val_mae: 0.3971 - val_mse: 0.2525\n",
      "Epoch 451/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1782 - mae: 0.3386 - mse: 0.1782 - val_loss: 0.2468 - val_mae: 0.3884 - val_mse: 0.2468\n",
      "Epoch 452/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1776 - mae: 0.3384 - mse: 0.1776 - val_loss: 0.2468 - val_mae: 0.3876 - val_mse: 0.2468\n",
      "Epoch 453/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1775 - mae: 0.3386 - mse: 0.1775 - val_loss: 0.2504 - val_mae: 0.3941 - val_mse: 0.2504\n",
      "Epoch 454/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1768 - mae: 0.3375 - mse: 0.1768 - val_loss: 0.2497 - val_mae: 0.3932 - val_mse: 0.2497\n",
      "Epoch 455/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1768 - mae: 0.3376 - mse: 0.1768 - val_loss: 0.2470 - val_mae: 0.3889 - val_mse: 0.2470\n",
      "Epoch 456/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1771 - mae: 0.3377 - mse: 0.1771 - val_loss: 0.2473 - val_mae: 0.3893 - val_mse: 0.2473\n",
      "Epoch 457/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1767 - mae: 0.3380 - mse: 0.1767 - val_loss: 0.2505 - val_mae: 0.3943 - val_mse: 0.2505\n",
      "Epoch 458/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1764 - mae: 0.3374 - mse: 0.1764 - val_loss: 0.2475 - val_mae: 0.3897 - val_mse: 0.2475\n",
      "Epoch 459/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1765 - mae: 0.3374 - mse: 0.1765 - val_loss: 0.2479 - val_mae: 0.3903 - val_mse: 0.2479\n",
      "Epoch 460/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1765 - mae: 0.3378 - mse: 0.1765 - val_loss: 0.2493 - val_mae: 0.3928 - val_mse: 0.2493\n",
      "Epoch 461/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1764 - mae: 0.3373 - mse: 0.1764 - val_loss: 0.2488 - val_mae: 0.3920 - val_mse: 0.2488\n",
      "Epoch 462/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1760 - mae: 0.3370 - mse: 0.1760 - val_loss: 0.2467 - val_mae: 0.3886 - val_mse: 0.2467\n",
      "Epoch 463/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1762 - mae: 0.3371 - mse: 0.1762 - val_loss: 0.2462 - val_mae: 0.3877 - val_mse: 0.2462\n",
      "Epoch 464/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1760 - mae: 0.3371 - mse: 0.1760 - val_loss: 0.2499 - val_mae: 0.3936 - val_mse: 0.2499\n",
      "Epoch 465/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1760 - mae: 0.3370 - mse: 0.1760 - val_loss: 0.2469 - val_mae: 0.3889 - val_mse: 0.2469\n",
      "Epoch 466/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1759 - mae: 0.3368 - mse: 0.1759 - val_loss: 0.2482 - val_mae: 0.3912 - val_mse: 0.2482\n",
      "Epoch 467/500\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.1760 - mae: 0.3365 - mse: 0.1760 - val_loss: 0.2463 - val_mae: 0.3880 - val_mse: 0.2463\n",
      "Epoch 468/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1758 - mae: 0.3369 - mse: 0.1758 - val_loss: 0.2473 - val_mae: 0.3895 - val_mse: 0.2473\n",
      "Epoch 469/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1758 - mae: 0.3366 - mse: 0.1758 - val_loss: 0.2457 - val_mae: 0.3864 - val_mse: 0.2457\n",
      "Epoch 470/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1758 - mae: 0.3367 - mse: 0.1758 - val_loss: 0.2466 - val_mae: 0.3884 - val_mse: 0.2466\n",
      "Epoch 471/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1759 - mae: 0.3368 - mse: 0.1759 - val_loss: 0.2455 - val_mae: 0.3865 - val_mse: 0.2455\n",
      "Epoch 472/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1760 - mae: 0.3372 - mse: 0.1760 - val_loss: 0.2456 - val_mae: 0.3863 - val_mse: 0.2456\n",
      "Epoch 473/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1762 - mae: 0.3369 - mse: 0.1762 - val_loss: 0.2468 - val_mae: 0.3888 - val_mse: 0.2468\n",
      "Epoch 474/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1753 - mae: 0.3364 - mse: 0.1753 - val_loss: 0.2472 - val_mae: 0.3898 - val_mse: 0.2472\n",
      "Epoch 475/500\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.1750 - mae: 0.3360 - mse: 0.1750 - val_loss: 0.2476 - val_mae: 0.3904 - val_mse: 0.2476\n",
      "Epoch 476/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1747 - mae: 0.3356 - mse: 0.1747 - val_loss: 0.2469 - val_mae: 0.3891 - val_mse: 0.2469\n",
      "Epoch 477/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1755 - mae: 0.3361 - mse: 0.1755 - val_loss: 0.2452 - val_mae: 0.3861 - val_mse: 0.2452\n",
      "Epoch 478/500\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.1747 - mae: 0.3360 - mse: 0.1747 - val_loss: 0.2474 - val_mae: 0.3901 - val_mse: 0.2474\n",
      "Epoch 479/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1752 - mae: 0.3358 - mse: 0.1752 - val_loss: 0.2452 - val_mae: 0.3864 - val_mse: 0.2452\n",
      "Epoch 480/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1746 - mae: 0.3355 - mse: 0.1746 - val_loss: 0.2454 - val_mae: 0.3869 - val_mse: 0.2454\n",
      "Epoch 481/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1750 - mae: 0.3361 - mse: 0.1750 - val_loss: 0.2449 - val_mae: 0.3858 - val_mse: 0.2449\n",
      "Epoch 482/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1743 - mae: 0.3353 - mse: 0.1743 - val_loss: 0.2468 - val_mae: 0.3891 - val_mse: 0.2468\n",
      "Epoch 483/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1742 - mae: 0.3351 - mse: 0.1742 - val_loss: 0.2455 - val_mae: 0.3871 - val_mse: 0.2455\n",
      "Epoch 484/500\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.1742 - mae: 0.3353 - mse: 0.1742 - val_loss: 0.2458 - val_mae: 0.3875 - val_mse: 0.2458\n",
      "Epoch 485/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1741 - mae: 0.3353 - mse: 0.1741 - val_loss: 0.2452 - val_mae: 0.3866 - val_mse: 0.2452\n",
      "Epoch 486/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1746 - mae: 0.3351 - mse: 0.1746 - val_loss: 0.2517 - val_mae: 0.3963 - val_mse: 0.2517\n",
      "Epoch 487/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1737 - mae: 0.3342 - mse: 0.1737 - val_loss: 0.2446 - val_mae: 0.3854 - val_mse: 0.2446\n",
      "Epoch 488/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1737 - mae: 0.3349 - mse: 0.1737 - val_loss: 0.2463 - val_mae: 0.3886 - val_mse: 0.2463\n",
      "Epoch 489/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1737 - mae: 0.3348 - mse: 0.1737 - val_loss: 0.2452 - val_mae: 0.3867 - val_mse: 0.2452\n",
      "Epoch 490/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1737 - mae: 0.3347 - mse: 0.1737 - val_loss: 0.2453 - val_mae: 0.3868 - val_mse: 0.2453\n",
      "Epoch 491/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1736 - mae: 0.3347 - mse: 0.1736 - val_loss: 0.2457 - val_mae: 0.3876 - val_mse: 0.2457\n",
      "Epoch 492/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1740 - mae: 0.3350 - mse: 0.1740 - val_loss: 0.2444 - val_mae: 0.3850 - val_mse: 0.2444\n",
      "Epoch 493/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1730 - mae: 0.3342 - mse: 0.1730 - val_loss: 0.2470 - val_mae: 0.3900 - val_mse: 0.2470\n",
      "Epoch 494/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1735 - mae: 0.3350 - mse: 0.1735 - val_loss: 0.2457 - val_mae: 0.3876 - val_mse: 0.2457\n",
      "Epoch 495/500\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.1732 - mae: 0.3342 - mse: 0.1732 - val_loss: 0.2442 - val_mae: 0.3849 - val_mse: 0.2442\n",
      "Epoch 496/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1731 - mae: 0.3345 - mse: 0.1731 - val_loss: 0.2460 - val_mae: 0.3884 - val_mse: 0.2460\n",
      "Epoch 497/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1730 - mae: 0.3343 - mse: 0.1730 - val_loss: 0.2454 - val_mae: 0.3872 - val_mse: 0.2454\n",
      "Epoch 498/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1729 - mae: 0.3340 - mse: 0.1729 - val_loss: 0.2455 - val_mae: 0.3875 - val_mse: 0.2455\n",
      "Epoch 499/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1734 - mae: 0.3350 - mse: 0.1734 - val_loss: 0.2440 - val_mae: 0.3846 - val_mse: 0.2440\n",
      "Epoch 500/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1726 - mae: 0.3335 - mse: 0.1726 - val_loss: 0.2462 - val_mae: 0.3887 - val_mse: 0.2462\n"
     ]
    }
   ],
   "source": [
    "# Mostra o progresso do treinamento imprimindo um único ponto para cada epoch completada\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "\n",
    "EPOCHS = 500 \n",
    "\n",
    "early_stop = keras.callbacks.EarlyStopping(\n",
    "  monitor='val_mse', patience=25, mode='min' ,restore_best_weights=True)\n",
    "\n",
    "# earlystop como o val_mse \n",
    "# Add dados de validação \n",
    "#  validation_data=\n",
    "# train_dataset = x\n",
    "# train_labels = y\n",
    "\n",
    "history = model.fit(\n",
    "  train_dataset,train_labels,\n",
    "  # validation_data=valid_dataset,\n",
    "  validation_split=0.2,\n",
    "  epochs=EPOCHS, verbose=1,\n",
    "  callbacks=([early_stop,tensorboard_callback]))\n",
    "\n",
    "#   validation_data=valid_dataset,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>mae</th>\n",
       "      <th>mse</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_mae</th>\n",
       "      <th>val_mse</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>0.173079</td>\n",
       "      <td>0.334468</td>\n",
       "      <td>0.173079</td>\n",
       "      <td>0.246047</td>\n",
       "      <td>0.388409</td>\n",
       "      <td>0.246047</td>\n",
       "      <td>495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>0.172990</td>\n",
       "      <td>0.334314</td>\n",
       "      <td>0.172990</td>\n",
       "      <td>0.245394</td>\n",
       "      <td>0.387188</td>\n",
       "      <td>0.245394</td>\n",
       "      <td>496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>0.172937</td>\n",
       "      <td>0.334018</td>\n",
       "      <td>0.172937</td>\n",
       "      <td>0.245512</td>\n",
       "      <td>0.387473</td>\n",
       "      <td>0.245512</td>\n",
       "      <td>497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>0.173385</td>\n",
       "      <td>0.334962</td>\n",
       "      <td>0.173385</td>\n",
       "      <td>0.244003</td>\n",
       "      <td>0.384622</td>\n",
       "      <td>0.244003</td>\n",
       "      <td>498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>0.172588</td>\n",
       "      <td>0.333547</td>\n",
       "      <td>0.172588</td>\n",
       "      <td>0.246154</td>\n",
       "      <td>0.388743</td>\n",
       "      <td>0.246154</td>\n",
       "      <td>499</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         loss       mae       mse  val_loss   val_mae   val_mse  epoch\n",
       "495  0.173079  0.334468  0.173079  0.246047  0.388409  0.246047    495\n",
       "496  0.172990  0.334314  0.172990  0.245394  0.387188  0.245394    496\n",
       "497  0.172937  0.334018  0.172937  0.245512  0.387473  0.245512    497\n",
       "498  0.173385  0.334962  0.173385  0.244003  0.384622  0.244003    498\n",
       "499  0.172588  0.333547  0.172588  0.246154  0.388743  0.246154    499"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist = pd.DataFrame(history.history)\n",
    "hist['epoch'] = history.epoch\n",
    "hist.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min MSE: 0.17258796095848083\n",
      "Min Val_MSE: 0.24400289356708527\n"
     ]
    }
   ],
   "source": [
    "print(f'Min MSE: {hist.mse.min()}')\n",
    "print(f'Min Val_MSE: {hist.val_mse.min()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_history(history):\n",
    "  hist = pd.DataFrame(history.history)\n",
    "  hist['epoch'] = history.epoch\n",
    "\n",
    "  plt.figure()\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('Mean Abs Error [ibova_0]')\n",
    "  plt.plot(hist['epoch'], hist['mae'],label='Train Error')\n",
    "  plt.plot(hist['epoch'], hist['val_mae'],label = 'Val Error')\n",
    "  plt.ylim([0,5])\n",
    "  plt.legend()\n",
    "\n",
    "  plt.figure()\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('Mean Square Error [$ibova_0^2$]')\n",
    "  plt.plot(hist['epoch'], hist['mse'],label='Train Error')\n",
    "  plt.plot(hist['epoch'], hist['val_mse'],label = 'Val Error')\n",
    "  plt.ylim([0,20])\n",
    "  plt.legend()\n",
    "  plt.show()\n",
    "\n",
    "\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      " 2/36 [>.............................] - ETA: 10s - loss: 1521.0609 - mae: 33.7500 - mse: 1521.0609WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0020s vs `on_train_batch_end` time: 0.6140s). Check your callbacks.\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 1200.8032 - mae: 29.9309 - mse: 1200.8032 - val_loss: 3349.0251 - val_mae: 57.7443 - val_mse: 3349.0251\n",
      "Epoch 2/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 631.8521 - mae: 21.6848 - mse: 631.8521 - val_loss: 1663.2002 - val_mae: 40.6863 - val_mse: 1663.2002\n",
      "Epoch 3/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 302.7237 - mae: 14.9064 - mse: 302.7237 - val_loss: 747.6281 - val_mae: 27.2666 - val_mse: 747.6281\n",
      "Epoch 4/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 129.1006 - mae: 9.7317 - mse: 129.1006 - val_loss: 308.2642 - val_mae: 17.4882 - val_mse: 308.2642\n",
      "Epoch 5/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 49.0638 - mae: 5.9794 - mse: 49.0638 - val_loss: 112.0375 - val_mae: 10.5053 - val_mse: 112.0375\n",
      "Epoch 6/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 16.4373 - mae: 3.4074 - mse: 16.4373 - val_loss: 36.6574 - val_mae: 5.9381 - val_mse: 36.6574\n",
      "Epoch 7/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.0542 - mae: 1.8497 - mse: 5.0542 - val_loss: 11.9269 - val_mae: 3.2612 - val_mse: 11.9269\n",
      "Epoch 8/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 1.6692 - mae: 1.0312 - mse: 1.6692 - val_loss: 4.5593 - val_mae: 1.8895 - val_mse: 4.5593\n",
      "Epoch 9/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.7990 - mae: 0.6937 - mse: 0.7990 - val_loss: 2.4116 - val_mae: 1.2768 - val_mse: 2.4116\n",
      "Epoch 10/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5984 - mae: 0.6006 - mse: 0.5984 - val_loss: 1.7716 - val_mae: 1.0417 - val_mse: 1.7716\n",
      "Epoch 11/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5532 - mae: 0.5758 - mse: 0.5532 - val_loss: 1.5677 - val_mae: 0.9649 - val_mse: 1.5677\n",
      "Epoch 12/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5404 - mae: 0.5682 - mse: 0.5404 - val_loss: 1.4762 - val_mae: 0.9297 - val_mse: 1.4762\n",
      "Epoch 13/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5339 - mae: 0.5644 - mse: 0.5339 - val_loss: 1.4353 - val_mae: 0.9152 - val_mse: 1.4353\n",
      "Epoch 14/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5284 - mae: 0.5615 - mse: 0.5284 - val_loss: 1.4240 - val_mae: 0.9119 - val_mse: 1.4240\n",
      "Epoch 15/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5230 - mae: 0.5582 - mse: 0.5230 - val_loss: 1.3792 - val_mae: 0.8960 - val_mse: 1.3792\n",
      "Epoch 16/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5176 - mae: 0.5553 - mse: 0.5176 - val_loss: 1.3813 - val_mae: 0.8977 - val_mse: 1.3813\n",
      "Epoch 17/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5120 - mae: 0.5522 - mse: 0.5120 - val_loss: 1.3515 - val_mae: 0.8873 - val_mse: 1.3515\n",
      "Epoch 18/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5065 - mae: 0.5498 - mse: 0.5065 - val_loss: 1.3452 - val_mae: 0.8858 - val_mse: 1.3452\n",
      "Epoch 19/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5009 - mae: 0.5463 - mse: 0.5009 - val_loss: 1.3192 - val_mae: 0.8767 - val_mse: 1.3192\n",
      "Epoch 20/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4955 - mae: 0.5436 - mse: 0.4955 - val_loss: 1.3138 - val_mae: 0.8755 - val_mse: 1.3138\n",
      "Epoch 21/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4901 - mae: 0.5407 - mse: 0.4901 - val_loss: 1.2886 - val_mae: 0.8666 - val_mse: 1.2886\n",
      "Epoch 22/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4847 - mae: 0.5376 - mse: 0.4847 - val_loss: 1.2760 - val_mae: 0.8626 - val_mse: 1.2760\n",
      "Epoch 23/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4794 - mae: 0.5343 - mse: 0.4794 - val_loss: 1.2368 - val_mae: 0.8479 - val_mse: 1.2368\n",
      "Epoch 24/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4738 - mae: 0.5316 - mse: 0.4738 - val_loss: 1.2367 - val_mae: 0.8488 - val_mse: 1.2367\n",
      "Epoch 25/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4687 - mae: 0.5285 - mse: 0.4687 - val_loss: 1.2119 - val_mae: 0.8399 - val_mse: 1.2119\n",
      "Epoch 26/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4629 - mae: 0.5254 - mse: 0.4629 - val_loss: 1.2048 - val_mae: 0.8379 - val_mse: 1.2048\n",
      "Epoch 27/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4578 - mae: 0.5226 - mse: 0.4578 - val_loss: 1.1820 - val_mae: 0.8297 - val_mse: 1.1820\n",
      "Epoch 28/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4524 - mae: 0.5197 - mse: 0.4524 - val_loss: 1.1700 - val_mae: 0.8258 - val_mse: 1.1700\n",
      "Epoch 29/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4471 - mae: 0.5164 - mse: 0.4471 - val_loss: 1.1507 - val_mae: 0.8188 - val_mse: 1.1507\n",
      "Epoch 30/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4421 - mae: 0.5136 - mse: 0.4421 - val_loss: 1.1459 - val_mae: 0.8178 - val_mse: 1.1459\n",
      "Epoch 31/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4370 - mae: 0.5108 - mse: 0.4370 - val_loss: 1.1186 - val_mae: 0.8076 - val_mse: 1.1186\n",
      "Epoch 32/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4312 - mae: 0.5074 - mse: 0.4312 - val_loss: 1.0963 - val_mae: 0.7992 - val_mse: 1.0963\n",
      "Epoch 33/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4255 - mae: 0.5042 - mse: 0.4255 - val_loss: 1.0808 - val_mae: 0.7939 - val_mse: 1.0808\n",
      "Epoch 34/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4196 - mae: 0.5007 - mse: 0.4196 - val_loss: 1.0664 - val_mae: 0.7889 - val_mse: 1.0664\n",
      "Epoch 35/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4135 - mae: 0.4974 - mse: 0.4135 - val_loss: 1.0531 - val_mae: 0.7843 - val_mse: 1.0531\n",
      "Epoch 36/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4074 - mae: 0.4941 - mse: 0.4074 - val_loss: 1.0355 - val_mae: 0.7781 - val_mse: 1.0355\n",
      "Epoch 37/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.3986 - mae: 0.4888 - mse: 0.3986 - val_loss: 0.9989 - val_mae: 0.7643 - val_mse: 0.9989\n",
      "Epoch 38/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.3837 - mae: 0.4808 - mse: 0.3837 - val_loss: 0.9684 - val_mae: 0.7513 - val_mse: 0.9684\n",
      "Epoch 39/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.3641 - mae: 0.4689 - mse: 0.3641 - val_loss: 0.9214 - val_mae: 0.7314 - val_mse: 0.9214\n",
      "Epoch 40/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.3502 - mae: 0.4606 - mse: 0.3502 - val_loss: 0.8742 - val_mae: 0.7135 - val_mse: 0.8742\n",
      "Epoch 41/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.3423 - mae: 0.4552 - mse: 0.3423 - val_loss: 0.8425 - val_mae: 0.7009 - val_mse: 0.8425\n",
      "Epoch 42/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.3368 - mae: 0.4515 - mse: 0.3368 - val_loss: 0.8101 - val_mae: 0.6870 - val_mse: 0.8101\n",
      "Epoch 43/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.3322 - mae: 0.4485 - mse: 0.3322 - val_loss: 0.7972 - val_mae: 0.6823 - val_mse: 0.7972\n",
      "Epoch 44/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.3281 - mae: 0.4459 - mse: 0.3281 - val_loss: 0.7720 - val_mae: 0.6713 - val_mse: 0.7720\n",
      "Epoch 45/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.3249 - mae: 0.4434 - mse: 0.3249 - val_loss: 0.7595 - val_mae: 0.6662 - val_mse: 0.7595\n",
      "Epoch 46/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.3211 - mae: 0.4403 - mse: 0.3211 - val_loss: 0.7423 - val_mae: 0.6587 - val_mse: 0.7423\n",
      "Epoch 47/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.3179 - mae: 0.4384 - mse: 0.3179 - val_loss: 0.7366 - val_mae: 0.6566 - val_mse: 0.7366\n",
      "Epoch 48/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.3151 - mae: 0.4363 - mse: 0.3151 - val_loss: 0.7255 - val_mae: 0.6518 - val_mse: 0.7255\n",
      "Epoch 49/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.3128 - mae: 0.4358 - mse: 0.3128 - val_loss: 0.7093 - val_mae: 0.6443 - val_mse: 0.7093\n",
      "Epoch 50/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.3091 - mae: 0.4319 - mse: 0.3091 - val_loss: 0.6963 - val_mae: 0.6384 - val_mse: 0.6963\n",
      "Epoch 51/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.3059 - mae: 0.4302 - mse: 0.3059 - val_loss: 0.6999 - val_mae: 0.6406 - val_mse: 0.6999\n",
      "Epoch 52/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.3033 - mae: 0.4282 - mse: 0.3033 - val_loss: 0.6747 - val_mae: 0.6284 - val_mse: 0.6747\n",
      "Epoch 53/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.3010 - mae: 0.4268 - mse: 0.3010 - val_loss: 0.6684 - val_mae: 0.6256 - val_mse: 0.6684\n",
      "Epoch 54/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2978 - mae: 0.4237 - mse: 0.2978 - val_loss: 0.6556 - val_mae: 0.6193 - val_mse: 0.6556\n",
      "Epoch 55/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2952 - mae: 0.4224 - mse: 0.2952 - val_loss: 0.6529 - val_mae: 0.6182 - val_mse: 0.6529\n",
      "Epoch 56/500\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.2925 - mae: 0.4206 - mse: 0.2925 - val_loss: 0.6601 - val_mae: 0.6225 - val_mse: 0.6601\n",
      "Epoch 57/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2901 - mae: 0.4190 - mse: 0.2901 - val_loss: 0.6479 - val_mae: 0.6165 - val_mse: 0.6479\n",
      "Epoch 58/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2881 - mae: 0.4170 - mse: 0.2881 - val_loss: 0.6218 - val_mae: 0.6029 - val_mse: 0.6218\n",
      "Epoch 59/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2847 - mae: 0.4148 - mse: 0.2847 - val_loss: 0.6346 - val_mae: 0.6104 - val_mse: 0.6346\n",
      "Epoch 60/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.2826 - mae: 0.4135 - mse: 0.2826 - val_loss: 0.6229 - val_mae: 0.6044 - val_mse: 0.6229\n",
      "Epoch 61/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.2801 - mae: 0.4120 - mse: 0.2801 - val_loss: 0.6007 - val_mae: 0.5927 - val_mse: 0.6007\n",
      "Epoch 62/500\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.2775 - mae: 0.4093 - mse: 0.2775 - val_loss: 0.6036 - val_mae: 0.5947 - val_mse: 0.6036\n",
      "Epoch 63/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2747 - mae: 0.4068 - mse: 0.2747 - val_loss: 0.5978 - val_mae: 0.5920 - val_mse: 0.5978\n",
      "Epoch 64/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.2682 - mae: 0.4004 - mse: 0.2682 - val_loss: 0.4180 - val_mae: 0.5035 - val_mse: 0.4180\n",
      "Epoch 65/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.2517 - mae: 0.3905 - mse: 0.2517 - val_loss: 0.4703 - val_mae: 0.5402 - val_mse: 0.4703\n",
      "Epoch 66/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.2508 - mae: 0.3893 - mse: 0.2508 - val_loss: 0.3906 - val_mae: 0.4920 - val_mse: 0.3906\n",
      "Epoch 67/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.2483 - mae: 0.3874 - mse: 0.2483 - val_loss: 0.4354 - val_mae: 0.5232 - val_mse: 0.4354\n",
      "Epoch 68/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2485 - mae: 0.3875 - mse: 0.2485 - val_loss: 0.4441 - val_mae: 0.5289 - val_mse: 0.4441\n",
      "Epoch 69/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2462 - mae: 0.3863 - mse: 0.2462 - val_loss: 0.3553 - val_mae: 0.4676 - val_mse: 0.3553\n",
      "Epoch 70/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2478 - mae: 0.3866 - mse: 0.2478 - val_loss: 0.3762 - val_mae: 0.4835 - val_mse: 0.3762\n",
      "Epoch 71/500\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.2436 - mae: 0.3836 - mse: 0.2436 - val_loss: 0.3623 - val_mae: 0.4727 - val_mse: 0.3623\n",
      "Epoch 72/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2419 - mae: 0.3832 - mse: 0.2419 - val_loss: 0.3548 - val_mae: 0.4687 - val_mse: 0.3548\n",
      "Epoch 73/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2405 - mae: 0.3817 - mse: 0.2405 - val_loss: 0.3538 - val_mae: 0.4674 - val_mse: 0.3538\n",
      "Epoch 74/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2421 - mae: 0.3827 - mse: 0.2421 - val_loss: 0.3410 - val_mae: 0.4591 - val_mse: 0.3410\n",
      "Epoch 75/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2395 - mae: 0.3807 - mse: 0.2395 - val_loss: 0.3396 - val_mae: 0.4581 - val_mse: 0.3396\n",
      "Epoch 76/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2391 - mae: 0.3807 - mse: 0.2391 - val_loss: 0.3412 - val_mae: 0.4593 - val_mse: 0.3412\n",
      "Epoch 77/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.2366 - mae: 0.3790 - mse: 0.2366 - val_loss: 0.3613 - val_mae: 0.4740 - val_mse: 0.3613\n",
      "Epoch 78/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.2352 - mae: 0.3781 - mse: 0.2352 - val_loss: 0.3337 - val_mae: 0.4548 - val_mse: 0.3337\n",
      "Epoch 79/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2351 - mae: 0.3780 - mse: 0.2351 - val_loss: 0.3541 - val_mae: 0.4688 - val_mse: 0.3541\n",
      "Epoch 80/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2336 - mae: 0.3763 - mse: 0.2336 - val_loss: 0.3348 - val_mae: 0.4552 - val_mse: 0.3348\n",
      "Epoch 81/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2337 - mae: 0.3773 - mse: 0.2337 - val_loss: 0.3569 - val_mae: 0.4718 - val_mse: 0.3569\n",
      "Epoch 82/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2316 - mae: 0.3753 - mse: 0.2316 - val_loss: 0.3432 - val_mae: 0.4608 - val_mse: 0.3432\n",
      "Epoch 83/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2307 - mae: 0.3743 - mse: 0.2307 - val_loss: 0.3218 - val_mae: 0.4478 - val_mse: 0.3218\n",
      "Epoch 84/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2298 - mae: 0.3735 - mse: 0.2298 - val_loss: 0.3477 - val_mae: 0.4650 - val_mse: 0.3477\n",
      "Epoch 85/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2291 - mae: 0.3730 - mse: 0.2291 - val_loss: 0.3305 - val_mae: 0.4517 - val_mse: 0.3305\n",
      "Epoch 86/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2279 - mae: 0.3726 - mse: 0.2279 - val_loss: 0.3237 - val_mae: 0.4473 - val_mse: 0.3237\n",
      "Epoch 87/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2278 - mae: 0.3719 - mse: 0.2278 - val_loss: 0.3513 - val_mae: 0.4674 - val_mse: 0.3513\n",
      "Epoch 88/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2262 - mae: 0.3705 - mse: 0.2262 - val_loss: 0.3194 - val_mae: 0.4446 - val_mse: 0.3194\n",
      "Epoch 89/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2253 - mae: 0.3697 - mse: 0.2253 - val_loss: 0.3298 - val_mae: 0.4508 - val_mse: 0.3298\n",
      "Epoch 90/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2244 - mae: 0.3694 - mse: 0.2244 - val_loss: 0.3258 - val_mae: 0.4481 - val_mse: 0.3258\n",
      "Epoch 91/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2232 - mae: 0.3684 - mse: 0.2232 - val_loss: 0.3197 - val_mae: 0.4439 - val_mse: 0.3197\n",
      "Epoch 92/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2227 - mae: 0.3672 - mse: 0.2227 - val_loss: 0.3502 - val_mae: 0.4681 - val_mse: 0.3502\n",
      "Epoch 93/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2232 - mae: 0.3675 - mse: 0.2232 - val_loss: 0.3322 - val_mae: 0.4532 - val_mse: 0.3322\n",
      "Epoch 94/500\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.2201 - mae: 0.3675 - mse: 0.220 - 0s 3ms/step - loss: 0.2211 - mae: 0.3665 - mse: 0.2211 - val_loss: 0.3164 - val_mae: 0.4416 - val_mse: 0.3164\n",
      "Epoch 95/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2198 - mae: 0.3649 - mse: 0.2198 - val_loss: 0.3115 - val_mae: 0.4387 - val_mse: 0.3115\n",
      "Epoch 96/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2191 - mae: 0.3647 - mse: 0.2191 - val_loss: 0.3303 - val_mae: 0.4526 - val_mse: 0.3303\n",
      "Epoch 97/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2186 - mae: 0.3650 - mse: 0.2186 - val_loss: 0.3135 - val_mae: 0.4395 - val_mse: 0.3135\n",
      "Epoch 98/500\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.2171 - mae: 0.3626 - mse: 0.2171 - val_loss: 0.3229 - val_mae: 0.4469 - val_mse: 0.3229\n",
      "Epoch 99/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.2166 - mae: 0.3631 - mse: 0.2166 - val_loss: 0.3151 - val_mae: 0.4403 - val_mse: 0.3151\n",
      "Epoch 100/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2157 - mae: 0.3624 - mse: 0.2157 - val_loss: 0.3065 - val_mae: 0.4350 - val_mse: 0.3065\n",
      "Epoch 101/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2156 - mae: 0.3615 - mse: 0.2156 - val_loss: 0.3048 - val_mae: 0.4344 - val_mse: 0.3048\n",
      "Epoch 102/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2147 - mae: 0.3614 - mse: 0.2147 - val_loss: 0.3083 - val_mae: 0.4372 - val_mse: 0.3083\n",
      "Epoch 103/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.2137 - mae: 0.3603 - mse: 0.2137 - val_loss: 0.3023 - val_mae: 0.4321 - val_mse: 0.3023\n",
      "Epoch 104/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.2134 - mae: 0.3606 - mse: 0.2134 - val_loss: 0.3080 - val_mae: 0.4355 - val_mse: 0.3080\n",
      "Epoch 105/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2121 - mae: 0.3584 - mse: 0.2121 - val_loss: 0.3058 - val_mae: 0.4347 - val_mse: 0.3058\n",
      "Epoch 106/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2109 - mae: 0.3582 - mse: 0.2109 - val_loss: 0.2918 - val_mae: 0.4271 - val_mse: 0.2918\n",
      "Epoch 107/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.2100 - mae: 0.3573 - mse: 0.2100 - val_loss: 0.3061 - val_mae: 0.4363 - val_mse: 0.3061\n",
      "Epoch 108/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2091 - mae: 0.3565 - mse: 0.2091 - val_loss: 0.2931 - val_mae: 0.4267 - val_mse: 0.2931\n",
      "Epoch 109/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2081 - mae: 0.3563 - mse: 0.2081 - val_loss: 0.2873 - val_mae: 0.4231 - val_mse: 0.2873\n",
      "Epoch 110/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2074 - mae: 0.3555 - mse: 0.2074 - val_loss: 0.2820 - val_mae: 0.4208 - val_mse: 0.2820\n",
      "Epoch 111/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2078 - mae: 0.3543 - mse: 0.2078 - val_loss: 0.3098 - val_mae: 0.4415 - val_mse: 0.3098\n",
      "Epoch 112/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.2067 - mae: 0.3547 - mse: 0.2067 - val_loss: 0.2914 - val_mae: 0.4250 - val_mse: 0.2914\n",
      "Epoch 113/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2043 - mae: 0.3531 - mse: 0.2043 - val_loss: 0.2776 - val_mae: 0.4169 - val_mse: 0.2776\n",
      "Epoch 114/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2049 - mae: 0.3534 - mse: 0.2049 - val_loss: 0.2785 - val_mae: 0.4167 - val_mse: 0.2785\n",
      "Epoch 115/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.2029 - mae: 0.3516 - mse: 0.2029 - val_loss: 0.2817 - val_mae: 0.4179 - val_mse: 0.2817\n",
      "Epoch 116/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2017 - mae: 0.3509 - mse: 0.2017 - val_loss: 0.2740 - val_mae: 0.4154 - val_mse: 0.2740\n",
      "Epoch 117/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2013 - mae: 0.3504 - mse: 0.2013 - val_loss: 0.2798 - val_mae: 0.4163 - val_mse: 0.2798\n",
      "Epoch 118/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.2007 - mae: 0.3496 - mse: 0.2007 - val_loss: 0.2852 - val_mae: 0.4207 - val_mse: 0.2852\n",
      "Epoch 119/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1993 - mae: 0.3484 - mse: 0.1993 - val_loss: 0.2723 - val_mae: 0.4148 - val_mse: 0.2723\n",
      "Epoch 120/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1991 - mae: 0.3486 - mse: 0.1991 - val_loss: 0.2731 - val_mae: 0.4118 - val_mse: 0.2731\n",
      "Epoch 121/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1988 - mae: 0.3485 - mse: 0.1988 - val_loss: 0.2684 - val_mae: 0.4104 - val_mse: 0.2684\n",
      "Epoch 122/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1988 - mae: 0.3501 - mse: 0.1988 - val_loss: 0.2734 - val_mae: 0.4168 - val_mse: 0.2734\n",
      "Epoch 123/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1975 - mae: 0.3473 - mse: 0.1975 - val_loss: 0.2683 - val_mae: 0.4089 - val_mse: 0.2683\n",
      "Epoch 124/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1958 - mae: 0.3455 - mse: 0.1958 - val_loss: 0.2670 - val_mae: 0.4082 - val_mse: 0.2670\n",
      "Epoch 125/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1958 - mae: 0.3456 - mse: 0.1958 - val_loss: 0.2649 - val_mae: 0.4086 - val_mse: 0.2649\n",
      "Epoch 126/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1943 - mae: 0.3446 - mse: 0.1943 - val_loss: 0.2643 - val_mae: 0.4070 - val_mse: 0.2643\n",
      "Epoch 127/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1931 - mae: 0.3434 - mse: 0.1931 - val_loss: 0.2680 - val_mae: 0.4082 - val_mse: 0.2680\n",
      "Epoch 128/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1922 - mae: 0.3426 - mse: 0.1922 - val_loss: 0.2637 - val_mae: 0.4060 - val_mse: 0.2637\n",
      "Epoch 129/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1912 - mae: 0.3420 - mse: 0.1912 - val_loss: 0.2615 - val_mae: 0.4063 - val_mse: 0.2615\n",
      "Epoch 130/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1904 - mae: 0.3414 - mse: 0.1904 - val_loss: 0.2666 - val_mae: 0.4071 - val_mse: 0.2666\n",
      "Epoch 131/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1892 - mae: 0.3403 - mse: 0.1892 - val_loss: 0.2601 - val_mae: 0.4052 - val_mse: 0.2601\n",
      "Epoch 132/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1889 - mae: 0.3399 - mse: 0.1889 - val_loss: 0.2631 - val_mae: 0.4044 - val_mse: 0.2631\n",
      "Epoch 133/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1881 - mae: 0.3388 - mse: 0.1881 - val_loss: 0.2579 - val_mae: 0.4029 - val_mse: 0.2579\n",
      "Epoch 134/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1877 - mae: 0.3391 - mse: 0.1877 - val_loss: 0.2580 - val_mae: 0.4014 - val_mse: 0.2580\n",
      "Epoch 135/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1866 - mae: 0.3381 - mse: 0.1866 - val_loss: 0.2562 - val_mae: 0.4014 - val_mse: 0.2562\n",
      "Epoch 136/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1866 - mae: 0.3378 - mse: 0.1866 - val_loss: 0.2562 - val_mae: 0.4000 - val_mse: 0.2562\n",
      "Epoch 137/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1859 - mae: 0.3368 - mse: 0.1859 - val_loss: 0.2568 - val_mae: 0.3996 - val_mse: 0.2568\n",
      "Epoch 138/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1846 - mae: 0.3361 - mse: 0.1846 - val_loss: 0.2535 - val_mae: 0.3988 - val_mse: 0.2535\n",
      "Epoch 139/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1843 - mae: 0.3363 - mse: 0.1843 - val_loss: 0.2570 - val_mae: 0.3993 - val_mse: 0.2570\n",
      "Epoch 140/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1834 - mae: 0.3353 - mse: 0.1834 - val_loss: 0.2523 - val_mae: 0.3973 - val_mse: 0.2523\n",
      "Epoch 141/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1827 - mae: 0.3347 - mse: 0.1827 - val_loss: 0.2508 - val_mae: 0.3967 - val_mse: 0.2508\n",
      "Epoch 142/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1832 - mae: 0.3347 - mse: 0.1832 - val_loss: 0.2522 - val_mae: 0.3962 - val_mse: 0.2522\n",
      "Epoch 143/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1810 - mae: 0.3328 - mse: 0.1810 - val_loss: 0.2509 - val_mae: 0.3955 - val_mse: 0.2509\n",
      "Epoch 144/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1807 - mae: 0.3322 - mse: 0.1807 - val_loss: 0.2501 - val_mae: 0.3948 - val_mse: 0.2501\n",
      "Epoch 145/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1806 - mae: 0.3322 - mse: 0.1806 - val_loss: 0.2478 - val_mae: 0.3939 - val_mse: 0.2478\n",
      "Epoch 146/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1794 - mae: 0.3314 - mse: 0.1794 - val_loss: 0.2468 - val_mae: 0.3932 - val_mse: 0.2468\n",
      "Epoch 147/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1789 - mae: 0.3308 - mse: 0.1789 - val_loss: 0.2460 - val_mae: 0.3925 - val_mse: 0.2460\n",
      "Epoch 148/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1785 - mae: 0.3303 - mse: 0.1785 - val_loss: 0.2449 - val_mae: 0.3923 - val_mse: 0.2449\n",
      "Epoch 149/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1775 - mae: 0.3300 - mse: 0.1775 - val_loss: 0.2494 - val_mae: 0.3936 - val_mse: 0.2494\n",
      "Epoch 150/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1769 - mae: 0.3290 - mse: 0.1769 - val_loss: 0.2449 - val_mae: 0.3906 - val_mse: 0.2449\n",
      "Epoch 151/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1766 - mae: 0.3291 - mse: 0.1766 - val_loss: 0.2469 - val_mae: 0.3916 - val_mse: 0.2469\n",
      "Epoch 152/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1763 - mae: 0.3282 - mse: 0.1763 - val_loss: 0.2572 - val_mae: 0.4005 - val_mse: 0.2572\n",
      "Epoch 153/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1759 - mae: 0.3281 - mse: 0.1759 - val_loss: 0.2418 - val_mae: 0.3884 - val_mse: 0.2418\n",
      "Epoch 154/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1755 - mae: 0.3272 - mse: 0.1755 - val_loss: 0.2402 - val_mae: 0.3890 - val_mse: 0.2402\n",
      "Epoch 155/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1737 - mae: 0.3263 - mse: 0.1737 - val_loss: 0.2493 - val_mae: 0.3937 - val_mse: 0.2493\n",
      "Epoch 156/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1739 - mae: 0.3260 - mse: 0.1739 - val_loss: 0.2390 - val_mae: 0.3861 - val_mse: 0.2390\n",
      "Epoch 157/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1734 - mae: 0.3260 - mse: 0.1734 - val_loss: 0.2371 - val_mae: 0.3858 - val_mse: 0.2371\n",
      "Epoch 158/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1741 - mae: 0.3260 - mse: 0.1741 - val_loss: 0.2363 - val_mae: 0.3847 - val_mse: 0.2363\n",
      "Epoch 159/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1721 - mae: 0.3253 - mse: 0.1721 - val_loss: 0.2367 - val_mae: 0.3842 - val_mse: 0.2367\n",
      "Epoch 160/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1712 - mae: 0.3237 - mse: 0.1712 - val_loss: 0.2389 - val_mae: 0.3852 - val_mse: 0.2389\n",
      "Epoch 161/500\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.1710 - mae: 0.3235 - mse: 0.1710 - val_loss: 0.2344 - val_mae: 0.3826 - val_mse: 0.2344\n",
      "Epoch 162/500\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.1707 - mae: 0.3239 - mse: 0.1707 - val_loss: 0.2405 - val_mae: 0.3866 - val_mse: 0.2405\n",
      "Epoch 163/500\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.1699 - mae: 0.3227 - mse: 0.1699 - val_loss: 0.2338 - val_mae: 0.3816 - val_mse: 0.2338\n",
      "Epoch 164/500\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1696 - mae: 0.3224 - mse: 0.1696 - val_loss: 0.2317 - val_mae: 0.3805 - val_mse: 0.2317\n",
      "Epoch 165/500\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.1689 - mae: 0.3212 - mse: 0.1689 - val_loss: 0.2316 - val_mae: 0.3801 - val_mse: 0.2316\n",
      "Epoch 166/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1680 - mae: 0.3212 - mse: 0.1680 - val_loss: 0.2301 - val_mae: 0.3792 - val_mse: 0.2301\n",
      "Epoch 167/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1682 - mae: 0.3211 - mse: 0.1682 - val_loss: 0.2293 - val_mae: 0.3785 - val_mse: 0.2293\n",
      "Epoch 168/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1671 - mae: 0.3200 - mse: 0.1671 - val_loss: 0.2288 - val_mae: 0.3780 - val_mse: 0.2288\n",
      "Epoch 169/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1673 - mae: 0.3202 - mse: 0.1673 - val_loss: 0.2310 - val_mae: 0.3789 - val_mse: 0.2310\n",
      "Epoch 170/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1667 - mae: 0.3194 - mse: 0.1667 - val_loss: 0.2304 - val_mae: 0.3784 - val_mse: 0.2304\n",
      "Epoch 171/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1657 - mae: 0.3186 - mse: 0.1657 - val_loss: 0.2282 - val_mae: 0.3768 - val_mse: 0.2282\n",
      "Epoch 172/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1652 - mae: 0.3181 - mse: 0.1652 - val_loss: 0.2305 - val_mae: 0.3784 - val_mse: 0.2305\n",
      "Epoch 173/500\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.1534 - mae: 0.2896 - mse: 0.153 - 0s 3ms/step - loss: 0.1650 - mae: 0.3181 - mse: 0.1650 - val_loss: 0.2286 - val_mae: 0.3769 - val_mse: 0.2286\n",
      "Epoch 174/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1641 - mae: 0.3170 - mse: 0.1641 - val_loss: 0.2258 - val_mae: 0.3750 - val_mse: 0.2258\n",
      "Epoch 175/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1640 - mae: 0.3172 - mse: 0.1640 - val_loss: 0.2233 - val_mae: 0.3736 - val_mse: 0.2233\n",
      "Epoch 176/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1636 - mae: 0.3164 - mse: 0.1636 - val_loss: 0.2223 - val_mae: 0.3731 - val_mse: 0.2223\n",
      "Epoch 177/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1629 - mae: 0.3161 - mse: 0.1629 - val_loss: 0.2237 - val_mae: 0.3732 - val_mse: 0.2237\n",
      "Epoch 178/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1626 - mae: 0.3149 - mse: 0.1626 - val_loss: 0.2264 - val_mae: 0.3750 - val_mse: 0.2264\n",
      "Epoch 179/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1623 - mae: 0.3148 - mse: 0.1623 - val_loss: 0.2272 - val_mae: 0.3757 - val_mse: 0.2272\n",
      "Epoch 180/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1614 - mae: 0.3145 - mse: 0.1614 - val_loss: 0.2194 - val_mae: 0.3708 - val_mse: 0.2194\n",
      "Epoch 181/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1607 - mae: 0.3141 - mse: 0.1607 - val_loss: 0.2256 - val_mae: 0.3744 - val_mse: 0.2256\n",
      "Epoch 182/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1606 - mae: 0.3138 - mse: 0.1606 - val_loss: 0.2208 - val_mae: 0.3707 - val_mse: 0.2208\n",
      "Epoch 183/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1599 - mae: 0.3130 - mse: 0.1599 - val_loss: 0.2172 - val_mae: 0.3695 - val_mse: 0.2172\n",
      "Epoch 184/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1594 - mae: 0.3125 - mse: 0.1594 - val_loss: 0.2266 - val_mae: 0.3753 - val_mse: 0.2266\n",
      "Epoch 185/500\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.1593 - mae: 0.3123 - mse: 0.1593 - val_loss: 0.2165 - val_mae: 0.3679 - val_mse: 0.2165\n",
      "Epoch 186/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1586 - mae: 0.3120 - mse: 0.1586 - val_loss: 0.2157 - val_mae: 0.3673 - val_mse: 0.2157\n",
      "Epoch 187/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1579 - mae: 0.3112 - mse: 0.1579 - val_loss: 0.2188 - val_mae: 0.3689 - val_mse: 0.2188\n",
      "Epoch 188/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1579 - mae: 0.3114 - mse: 0.1579 - val_loss: 0.2159 - val_mae: 0.3669 - val_mse: 0.2159\n",
      "Epoch 189/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1574 - mae: 0.3102 - mse: 0.1574 - val_loss: 0.2153 - val_mae: 0.3663 - val_mse: 0.2153\n",
      "Epoch 190/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1576 - mae: 0.3105 - mse: 0.1576 - val_loss: 0.2128 - val_mae: 0.3650 - val_mse: 0.2128\n",
      "Epoch 191/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1560 - mae: 0.3091 - mse: 0.1560 - val_loss: 0.2146 - val_mae: 0.3657 - val_mse: 0.2146\n",
      "Epoch 192/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1560 - mae: 0.3094 - mse: 0.1560 - val_loss: 0.2118 - val_mae: 0.3640 - val_mse: 0.2118\n",
      "Epoch 193/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1554 - mae: 0.3086 - mse: 0.1554 - val_loss: 0.2118 - val_mae: 0.3637 - val_mse: 0.2118\n",
      "Epoch 194/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1549 - mae: 0.3082 - mse: 0.1549 - val_loss: 0.2128 - val_mae: 0.3641 - val_mse: 0.2128\n",
      "Epoch 195/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1557 - mae: 0.3083 - mse: 0.1557 - val_loss: 0.2221 - val_mae: 0.3718 - val_mse: 0.2221\n",
      "Epoch 196/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1546 - mae: 0.3076 - mse: 0.1546 - val_loss: 0.2095 - val_mae: 0.3620 - val_mse: 0.2095\n",
      "Epoch 197/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1536 - mae: 0.3069 - mse: 0.1536 - val_loss: 0.2089 - val_mae: 0.3614 - val_mse: 0.2089\n",
      "Epoch 198/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1534 - mae: 0.3067 - mse: 0.1534 - val_loss: 0.2077 - val_mae: 0.3607 - val_mse: 0.2077\n",
      "Epoch 199/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1528 - mae: 0.3059 - mse: 0.1528 - val_loss: 0.2079 - val_mae: 0.3605 - val_mse: 0.2079\n",
      "Epoch 200/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1525 - mae: 0.3058 - mse: 0.1525 - val_loss: 0.2058 - val_mae: 0.3599 - val_mse: 0.2058\n",
      "Epoch 201/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1521 - mae: 0.3056 - mse: 0.1521 - val_loss: 0.2158 - val_mae: 0.3666 - val_mse: 0.2158\n",
      "Epoch 202/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1519 - mae: 0.3048 - mse: 0.1519 - val_loss: 0.2060 - val_mae: 0.3589 - val_mse: 0.2060\n",
      "Epoch 203/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1513 - mae: 0.3047 - mse: 0.1513 - val_loss: 0.2045 - val_mae: 0.3580 - val_mse: 0.2045\n",
      "Epoch 204/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1507 - mae: 0.3037 - mse: 0.1507 - val_loss: 0.2045 - val_mae: 0.3577 - val_mse: 0.2045\n",
      "Epoch 205/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1510 - mae: 0.3043 - mse: 0.1510 - val_loss: 0.2037 - val_mae: 0.3571 - val_mse: 0.2037\n",
      "Epoch 206/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1500 - mae: 0.3030 - mse: 0.1500 - val_loss: 0.2052 - val_mae: 0.3577 - val_mse: 0.2052\n",
      "Epoch 207/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1498 - mae: 0.3027 - mse: 0.1498 - val_loss: 0.2033 - val_mae: 0.3564 - val_mse: 0.2033\n",
      "Epoch 208/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1491 - mae: 0.3021 - mse: 0.1491 - val_loss: 0.2022 - val_mae: 0.3580 - val_mse: 0.2022\n",
      "Epoch 209/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1489 - mae: 0.3020 - mse: 0.1489 - val_loss: 0.2072 - val_mae: 0.3593 - val_mse: 0.2072\n",
      "Epoch 210/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1486 - mae: 0.3019 - mse: 0.1486 - val_loss: 0.2000 - val_mae: 0.3544 - val_mse: 0.2000\n",
      "Epoch 211/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1478 - mae: 0.3007 - mse: 0.1478 - val_loss: 0.2028 - val_mae: 0.3554 - val_mse: 0.2028\n",
      "Epoch 212/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1487 - mae: 0.3019 - mse: 0.1487 - val_loss: 0.2095 - val_mae: 0.3612 - val_mse: 0.2095\n",
      "Epoch 213/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1471 - mae: 0.3004 - mse: 0.1471 - val_loss: 0.1982 - val_mae: 0.3539 - val_mse: 0.1982\n",
      "Epoch 214/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1466 - mae: 0.2996 - mse: 0.1466 - val_loss: 0.2027 - val_mae: 0.3554 - val_mse: 0.2027\n",
      "Epoch 215/500\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.1468 - mae: 0.3004 - mse: 0.1468 - val_loss: 0.1972 - val_mae: 0.3517 - val_mse: 0.1972\n",
      "Epoch 216/500\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.1460 - mae: 0.2990 - mse: 0.1460 - val_loss: 0.1978 - val_mae: 0.3515 - val_mse: 0.1978\n",
      "Epoch 217/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1461 - mae: 0.2995 - mse: 0.1461 - val_loss: 0.1961 - val_mae: 0.3507 - val_mse: 0.1961\n",
      "Epoch 218/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1463 - mae: 0.2989 - mse: 0.1463 - val_loss: 0.1952 - val_mae: 0.3505 - val_mse: 0.1952\n",
      "Epoch 219/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1448 - mae: 0.2980 - mse: 0.1448 - val_loss: 0.1950 - val_mae: 0.3496 - val_mse: 0.1950\n",
      "Epoch 220/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1446 - mae: 0.2972 - mse: 0.1446 - val_loss: 0.1976 - val_mae: 0.3508 - val_mse: 0.1976\n",
      "Epoch 221/500\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.1445 - mae: 0.2972 - mse: 0.1445 - val_loss: 0.1964 - val_mae: 0.3499 - val_mse: 0.1964\n",
      "Epoch 222/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1439 - mae: 0.2969 - mse: 0.1439 - val_loss: 0.1937 - val_mae: 0.3481 - val_mse: 0.1937\n",
      "Epoch 223/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1439 - mae: 0.2969 - mse: 0.1439 - val_loss: 0.1934 - val_mae: 0.3478 - val_mse: 0.1934\n",
      "Epoch 224/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1431 - mae: 0.2960 - mse: 0.1431 - val_loss: 0.1922 - val_mae: 0.3487 - val_mse: 0.1922\n",
      "Epoch 225/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1428 - mae: 0.2962 - mse: 0.1428 - val_loss: 0.1915 - val_mae: 0.3467 - val_mse: 0.1915\n",
      "Epoch 226/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1422 - mae: 0.2951 - mse: 0.1422 - val_loss: 0.1925 - val_mae: 0.3466 - val_mse: 0.1925\n",
      "Epoch 227/500\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.1418 - mae: 0.2949 - mse: 0.1418 - val_loss: 0.1921 - val_mae: 0.3462 - val_mse: 0.1921\n",
      "Epoch 228/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1417 - mae: 0.2946 - mse: 0.1417 - val_loss: 0.1917 - val_mae: 0.3487 - val_mse: 0.1917\n",
      "Epoch 229/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1417 - mae: 0.2947 - mse: 0.1417 - val_loss: 0.1891 - val_mae: 0.3452 - val_mse: 0.1891\n",
      "Epoch 230/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1410 - mae: 0.2939 - mse: 0.1410 - val_loss: 0.1887 - val_mae: 0.3444 - val_mse: 0.1887\n",
      "Epoch 231/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1409 - mae: 0.2939 - mse: 0.1409 - val_loss: 0.1882 - val_mae: 0.3440 - val_mse: 0.1882\n",
      "Epoch 232/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1410 - mae: 0.2935 - mse: 0.1410 - val_loss: 0.1878 - val_mae: 0.3447 - val_mse: 0.1878\n",
      "Epoch 233/500\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.1398 - mae: 0.2925 - mse: 0.1398 - val_loss: 0.1892 - val_mae: 0.3434 - val_mse: 0.1892\n",
      "Epoch 234/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1395 - mae: 0.2926 - mse: 0.1395 - val_loss: 0.1866 - val_mae: 0.3428 - val_mse: 0.1866\n",
      "Epoch 235/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1394 - mae: 0.2924 - mse: 0.1394 - val_loss: 0.1863 - val_mae: 0.3433 - val_mse: 0.1863\n",
      "Epoch 236/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1398 - mae: 0.2927 - mse: 0.1398 - val_loss: 0.1859 - val_mae: 0.3430 - val_mse: 0.1859\n",
      "Epoch 237/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1388 - mae: 0.2912 - mse: 0.1388 - val_loss: 0.1851 - val_mae: 0.3415 - val_mse: 0.1851\n",
      "Epoch 238/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1381 - mae: 0.2907 - mse: 0.1381 - val_loss: 0.1852 - val_mae: 0.3405 - val_mse: 0.1852\n",
      "Epoch 239/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1390 - mae: 0.2912 - mse: 0.1390 - val_loss: 0.1844 - val_mae: 0.3417 - val_mse: 0.1844\n",
      "Epoch 240/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1378 - mae: 0.2905 - mse: 0.1378 - val_loss: 0.1836 - val_mae: 0.3402 - val_mse: 0.1836\n",
      "Epoch 241/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1374 - mae: 0.2903 - mse: 0.1374 - val_loss: 0.1850 - val_mae: 0.3395 - val_mse: 0.1850\n",
      "Epoch 242/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1370 - mae: 0.2895 - mse: 0.1370 - val_loss: 0.1882 - val_mae: 0.3422 - val_mse: 0.1882\n",
      "Epoch 243/500\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.1365 - mae: 0.2892 - mse: 0.1365 - val_loss: 0.1833 - val_mae: 0.3382 - val_mse: 0.1833\n",
      "Epoch 244/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1363 - mae: 0.2892 - mse: 0.1363 - val_loss: 0.1817 - val_mae: 0.3382 - val_mse: 0.1817\n",
      "Epoch 245/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1360 - mae: 0.2885 - mse: 0.1360 - val_loss: 0.1843 - val_mae: 0.3387 - val_mse: 0.1843\n",
      "Epoch 246/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1356 - mae: 0.2880 - mse: 0.1356 - val_loss: 0.1812 - val_mae: 0.3370 - val_mse: 0.1812\n",
      "Epoch 247/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1352 - mae: 0.2879 - mse: 0.1352 - val_loss: 0.1803 - val_mae: 0.3373 - val_mse: 0.1803\n",
      "Epoch 248/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1349 - mae: 0.2873 - mse: 0.1349 - val_loss: 0.1803 - val_mae: 0.3360 - val_mse: 0.1803\n",
      "Epoch 249/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1343 - mae: 0.2868 - mse: 0.1343 - val_loss: 0.1810 - val_mae: 0.3358 - val_mse: 0.1810\n",
      "Epoch 250/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1341 - mae: 0.2866 - mse: 0.1341 - val_loss: 0.1800 - val_mae: 0.3352 - val_mse: 0.1800\n",
      "Epoch 251/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1346 - mae: 0.2866 - mse: 0.1346 - val_loss: 0.1785 - val_mae: 0.3358 - val_mse: 0.1785\n",
      "Epoch 252/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1337 - mae: 0.2863 - mse: 0.1337 - val_loss: 0.1788 - val_mae: 0.3343 - val_mse: 0.1788\n",
      "Epoch 253/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1337 - mae: 0.2862 - mse: 0.1337 - val_loss: 0.1798 - val_mae: 0.3345 - val_mse: 0.1798\n",
      "Epoch 254/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1329 - mae: 0.2855 - mse: 0.1329 - val_loss: 0.1771 - val_mae: 0.3341 - val_mse: 0.1771\n",
      "Epoch 255/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1329 - mae: 0.2856 - mse: 0.1329 - val_loss: 0.1795 - val_mae: 0.3341 - val_mse: 0.1795\n",
      "Epoch 256/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1325 - mae: 0.2846 - mse: 0.1325 - val_loss: 0.1796 - val_mae: 0.3341 - val_mse: 0.1796\n",
      "Epoch 257/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1318 - mae: 0.2843 - mse: 0.1318 - val_loss: 0.1762 - val_mae: 0.3338 - val_mse: 0.1762\n",
      "Epoch 258/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1321 - mae: 0.2841 - mse: 0.1321 - val_loss: 0.1754 - val_mae: 0.3328 - val_mse: 0.1754\n",
      "Epoch 259/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1318 - mae: 0.2841 - mse: 0.1318 - val_loss: 0.1754 - val_mae: 0.3314 - val_mse: 0.1754\n",
      "Epoch 260/500\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.1311 - mae: 0.2837 - mse: 0.1311 - val_loss: 0.1751 - val_mae: 0.3310 - val_mse: 0.1751\n",
      "Epoch 261/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1310 - mae: 0.2836 - mse: 0.1310 - val_loss: 0.1765 - val_mae: 0.3313 - val_mse: 0.1765\n",
      "Epoch 262/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1312 - mae: 0.2829 - mse: 0.1312 - val_loss: 0.1781 - val_mae: 0.3325 - val_mse: 0.1781\n",
      "Epoch 263/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1302 - mae: 0.2828 - mse: 0.1302 - val_loss: 0.1733 - val_mae: 0.3309 - val_mse: 0.1733\n",
      "Epoch 264/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1301 - mae: 0.2820 - mse: 0.1301 - val_loss: 0.1740 - val_mae: 0.3295 - val_mse: 0.1740\n",
      "Epoch 265/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1297 - mae: 0.2817 - mse: 0.1297 - val_loss: 0.1726 - val_mae: 0.3303 - val_mse: 0.1726\n",
      "Epoch 266/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1294 - mae: 0.2817 - mse: 0.1294 - val_loss: 0.1725 - val_mae: 0.3286 - val_mse: 0.1725\n",
      "Epoch 267/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1291 - mae: 0.2812 - mse: 0.1291 - val_loss: 0.1717 - val_mae: 0.3285 - val_mse: 0.1717\n",
      "Epoch 268/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1285 - mae: 0.2805 - mse: 0.1285 - val_loss: 0.1726 - val_mae: 0.3280 - val_mse: 0.1726\n",
      "Epoch 269/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1283 - mae: 0.2803 - mse: 0.1283 - val_loss: 0.1712 - val_mae: 0.3274 - val_mse: 0.1712\n",
      "Epoch 270/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1279 - mae: 0.2798 - mse: 0.1279 - val_loss: 0.1716 - val_mae: 0.3271 - val_mse: 0.1716\n",
      "Epoch 271/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1278 - mae: 0.2797 - mse: 0.1278 - val_loss: 0.1724 - val_mae: 0.3274 - val_mse: 0.1724\n",
      "Epoch 272/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1275 - mae: 0.2792 - mse: 0.1275 - val_loss: 0.1704 - val_mae: 0.3262 - val_mse: 0.1704\n",
      "Epoch 273/500\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.1275 - mae: 0.2796 - mse: 0.1275 - val_loss: 0.1730 - val_mae: 0.3275 - val_mse: 0.1730\n",
      "Epoch 274/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1270 - mae: 0.2792 - mse: 0.1270 - val_loss: 0.1689 - val_mae: 0.3267 - val_mse: 0.1689\n",
      "Epoch 275/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1268 - mae: 0.2783 - mse: 0.1268 - val_loss: 0.1696 - val_mae: 0.3252 - val_mse: 0.1696\n",
      "Epoch 276/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1264 - mae: 0.2785 - mse: 0.1264 - val_loss: 0.1693 - val_mae: 0.3248 - val_mse: 0.1693\n",
      "Epoch 277/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1260 - mae: 0.2779 - mse: 0.1260 - val_loss: 0.1676 - val_mae: 0.3248 - val_mse: 0.1676\n",
      "Epoch 278/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1256 - mae: 0.2772 - mse: 0.1256 - val_loss: 0.1683 - val_mae: 0.3240 - val_mse: 0.1683\n",
      "Epoch 279/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1258 - mae: 0.2778 - mse: 0.1258 - val_loss: 0.1670 - val_mae: 0.3238 - val_mse: 0.1670\n",
      "Epoch 280/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1254 - mae: 0.2769 - mse: 0.1254 - val_loss: 0.1665 - val_mae: 0.3239 - val_mse: 0.1665\n",
      "Epoch 281/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1251 - mae: 0.2765 - mse: 0.1251 - val_loss: 0.1679 - val_mae: 0.3232 - val_mse: 0.1679\n",
      "Epoch 282/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1247 - mae: 0.2762 - mse: 0.1247 - val_loss: 0.1663 - val_mae: 0.3224 - val_mse: 0.1663\n",
      "Epoch 283/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1246 - mae: 0.2763 - mse: 0.1246 - val_loss: 0.1653 - val_mae: 0.3226 - val_mse: 0.1653\n",
      "Epoch 284/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1241 - mae: 0.2756 - mse: 0.1241 - val_loss: 0.1672 - val_mae: 0.3223 - val_mse: 0.1672\n",
      "Epoch 285/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1243 - mae: 0.2759 - mse: 0.1243 - val_loss: 0.1685 - val_mae: 0.3232 - val_mse: 0.1685\n",
      "Epoch 286/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1241 - mae: 0.2756 - mse: 0.1241 - val_loss: 0.1645 - val_mae: 0.3223 - val_mse: 0.1645\n",
      "Epoch 287/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1232 - mae: 0.2745 - mse: 0.1232 - val_loss: 0.1647 - val_mae: 0.3206 - val_mse: 0.1647\n",
      "Epoch 288/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1232 - mae: 0.2746 - mse: 0.1232 - val_loss: 0.1636 - val_mae: 0.3211 - val_mse: 0.1636\n",
      "Epoch 289/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1229 - mae: 0.2740 - mse: 0.1229 - val_loss: 0.1637 - val_mae: 0.3198 - val_mse: 0.1637\n",
      "Epoch 290/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1227 - mae: 0.2740 - mse: 0.1227 - val_loss: 0.1632 - val_mae: 0.3194 - val_mse: 0.1632\n",
      "Epoch 291/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1223 - mae: 0.2736 - mse: 0.1223 - val_loss: 0.1661 - val_mae: 0.3209 - val_mse: 0.1661\n",
      "Epoch 292/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1227 - mae: 0.2737 - mse: 0.1227 - val_loss: 0.1641 - val_mae: 0.3193 - val_mse: 0.1641\n",
      "Epoch 293/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1218 - mae: 0.2728 - mse: 0.1218 - val_loss: 0.1632 - val_mae: 0.3186 - val_mse: 0.1632\n",
      "Epoch 294/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1215 - mae: 0.2728 - mse: 0.1215 - val_loss: 0.1617 - val_mae: 0.3180 - val_mse: 0.1617\n",
      "Epoch 295/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1214 - mae: 0.2728 - mse: 0.1214 - val_loss: 0.1634 - val_mae: 0.3185 - val_mse: 0.1634\n",
      "Epoch 296/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1212 - mae: 0.2722 - mse: 0.1212 - val_loss: 0.1615 - val_mae: 0.3173 - val_mse: 0.1615\n",
      "Epoch 297/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1207 - mae: 0.2718 - mse: 0.1207 - val_loss: 0.1604 - val_mae: 0.3170 - val_mse: 0.1604\n",
      "Epoch 298/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1205 - mae: 0.2714 - mse: 0.1205 - val_loss: 0.1609 - val_mae: 0.3165 - val_mse: 0.1609\n",
      "Epoch 299/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1204 - mae: 0.2715 - mse: 0.1204 - val_loss: 0.1621 - val_mae: 0.3206 - val_mse: 0.1621\n",
      "Epoch 300/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1204 - mae: 0.2714 - mse: 0.1204 - val_loss: 0.1606 - val_mae: 0.3160 - val_mse: 0.1606\n",
      "Epoch 301/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1199 - mae: 0.2707 - mse: 0.1199 - val_loss: 0.1596 - val_mae: 0.3176 - val_mse: 0.1596\n",
      "Epoch 302/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1193 - mae: 0.2701 - mse: 0.1193 - val_loss: 0.1606 - val_mae: 0.3158 - val_mse: 0.1606\n",
      "Epoch 303/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1195 - mae: 0.2708 - mse: 0.1195 - val_loss: 0.1584 - val_mae: 0.3150 - val_mse: 0.1584\n",
      "Epoch 304/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1189 - mae: 0.2698 - mse: 0.1189 - val_loss: 0.1580 - val_mae: 0.3148 - val_mse: 0.1580\n",
      "Epoch 305/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1189 - mae: 0.2694 - mse: 0.1189 - val_loss: 0.1577 - val_mae: 0.3143 - val_mse: 0.1577\n",
      "Epoch 306/500\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.1196 - mae: 0.2700 - mse: 0.1196 - val_loss: 0.1586 - val_mae: 0.3139 - val_mse: 0.1586\n",
      "Epoch 307/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1187 - mae: 0.2696 - mse: 0.1187 - val_loss: 0.1596 - val_mae: 0.3180 - val_mse: 0.1596\n",
      "Epoch 308/500\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.1182 - mae: 0.2686 - mse: 0.1182 - val_loss: 0.1584 - val_mae: 0.3137 - val_mse: 0.1584\n",
      "Epoch 309/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1179 - mae: 0.2687 - mse: 0.1179 - val_loss: 0.1573 - val_mae: 0.3153 - val_mse: 0.1573\n",
      "Epoch 310/500\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.1178 - mae: 0.2683 - mse: 0.1178 - val_loss: 0.1565 - val_mae: 0.3124 - val_mse: 0.1565\n",
      "Epoch 311/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1176 - mae: 0.2677 - mse: 0.1176 - val_loss: 0.1601 - val_mae: 0.3149 - val_mse: 0.1601\n",
      "Epoch 312/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1173 - mae: 0.2675 - mse: 0.1173 - val_loss: 0.1569 - val_mae: 0.3151 - val_mse: 0.1569\n",
      "Epoch 313/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1171 - mae: 0.2675 - mse: 0.1171 - val_loss: 0.1554 - val_mae: 0.3114 - val_mse: 0.1554\n",
      "Epoch 314/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1166 - mae: 0.2670 - mse: 0.1166 - val_loss: 0.1572 - val_mae: 0.3123 - val_mse: 0.1572\n",
      "Epoch 315/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1168 - mae: 0.2674 - mse: 0.1168 - val_loss: 0.1583 - val_mae: 0.3132 - val_mse: 0.1583\n",
      "Epoch 316/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1163 - mae: 0.2669 - mse: 0.1163 - val_loss: 0.1550 - val_mae: 0.3105 - val_mse: 0.1550\n",
      "Epoch 317/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1163 - mae: 0.2667 - mse: 0.1163 - val_loss: 0.1539 - val_mae: 0.3103 - val_mse: 0.1539\n",
      "Epoch 318/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1159 - mae: 0.2661 - mse: 0.1159 - val_loss: 0.1538 - val_mae: 0.3098 - val_mse: 0.1538\n",
      "Epoch 319/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1158 - mae: 0.2663 - mse: 0.1158 - val_loss: 0.1536 - val_mae: 0.3094 - val_mse: 0.1536\n",
      "Epoch 320/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1159 - mae: 0.2661 - mse: 0.1159 - val_loss: 0.1553 - val_mae: 0.3136 - val_mse: 0.1553\n",
      "Epoch 321/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1153 - mae: 0.2657 - mse: 0.1153 - val_loss: 0.1536 - val_mae: 0.3089 - val_mse: 0.1536\n",
      "Epoch 322/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1148 - mae: 0.2649 - mse: 0.1148 - val_loss: 0.1531 - val_mae: 0.3086 - val_mse: 0.1531\n",
      "Epoch 323/500\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.1148 - mae: 0.2648 - mse: 0.1148 - val_loss: 0.1523 - val_mae: 0.3095 - val_mse: 0.1523\n",
      "Epoch 324/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1148 - mae: 0.2652 - mse: 0.1148 - val_loss: 0.1518 - val_mae: 0.3087 - val_mse: 0.1518\n",
      "Epoch 325/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1142 - mae: 0.2644 - mse: 0.1142 - val_loss: 0.1555 - val_mae: 0.3102 - val_mse: 0.1555\n",
      "Epoch 326/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1139 - mae: 0.2651 - mse: 0.1139 - val_loss: 0.1513 - val_mae: 0.3081 - val_mse: 0.1513\n",
      "Epoch 327/500\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.1138 - mae: 0.2638 - mse: 0.1138 - val_loss: 0.1524 - val_mae: 0.3075 - val_mse: 0.1524\n",
      "Epoch 328/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1134 - mae: 0.2633 - mse: 0.1134 - val_loss: 0.1509 - val_mae: 0.3081 - val_mse: 0.1509\n",
      "Epoch 329/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1134 - mae: 0.2626 - mse: 0.1134 - val_loss: 0.1529 - val_mae: 0.3079 - val_mse: 0.1529\n",
      "Epoch 330/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1131 - mae: 0.2629 - mse: 0.1131 - val_loss: 0.1505 - val_mae: 0.3078 - val_mse: 0.1505\n",
      "Epoch 331/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1133 - mae: 0.2632 - mse: 0.1133 - val_loss: 0.1520 - val_mae: 0.3070 - val_mse: 0.1520\n",
      "Epoch 332/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1128 - mae: 0.2627 - mse: 0.1128 - val_loss: 0.1496 - val_mae: 0.3057 - val_mse: 0.1496\n",
      "Epoch 333/500\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.1127 - mae: 0.2624 - mse: 0.1127 - val_loss: 0.1493 - val_mae: 0.3062 - val_mse: 0.1493\n",
      "Epoch 334/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1122 - mae: 0.2618 - mse: 0.1122 - val_loss: 0.1503 - val_mae: 0.3054 - val_mse: 0.1503\n",
      "Epoch 335/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1123 - mae: 0.2618 - mse: 0.1123 - val_loss: 0.1501 - val_mae: 0.3052 - val_mse: 0.1501\n",
      "Epoch 336/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1121 - mae: 0.2615 - mse: 0.1121 - val_loss: 0.1502 - val_mae: 0.3052 - val_mse: 0.1502\n",
      "Epoch 337/500\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.1119 - mae: 0.2616 - mse: 0.1119 - val_loss: 0.1492 - val_mae: 0.3043 - val_mse: 0.1492\n",
      "Epoch 338/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1116 - mae: 0.2612 - mse: 0.1116 - val_loss: 0.1482 - val_mae: 0.3037 - val_mse: 0.1482\n",
      "Epoch 339/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1116 - mae: 0.2607 - mse: 0.1116 - val_loss: 0.1489 - val_mae: 0.3039 - val_mse: 0.1489\n",
      "Epoch 340/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1112 - mae: 0.2606 - mse: 0.1112 - val_loss: 0.1474 - val_mae: 0.3033 - val_mse: 0.1474\n",
      "Epoch 341/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1114 - mae: 0.2606 - mse: 0.1114 - val_loss: 0.1495 - val_mae: 0.3043 - val_mse: 0.1495\n",
      "Epoch 342/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1109 - mae: 0.2605 - mse: 0.1109 - val_loss: 0.1520 - val_mae: 0.3063 - val_mse: 0.1520\n",
      "Epoch 343/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1108 - mae: 0.2601 - mse: 0.1108 - val_loss: 0.1489 - val_mae: 0.3066 - val_mse: 0.1489\n",
      "Epoch 344/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1106 - mae: 0.2592 - mse: 0.1106 - val_loss: 0.1473 - val_mae: 0.3023 - val_mse: 0.1473\n",
      "Epoch 345/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1101 - mae: 0.2593 - mse: 0.1101 - val_loss: 0.1475 - val_mae: 0.3024 - val_mse: 0.1475\n",
      "Epoch 346/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1099 - mae: 0.2592 - mse: 0.1099 - val_loss: 0.1459 - val_mae: 0.3015 - val_mse: 0.1459\n",
      "Epoch 347/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1101 - mae: 0.2593 - mse: 0.1101 - val_loss: 0.1458 - val_mae: 0.3025 - val_mse: 0.1458\n",
      "Epoch 348/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1098 - mae: 0.2589 - mse: 0.1098 - val_loss: 0.1455 - val_mae: 0.3009 - val_mse: 0.1455\n",
      "Epoch 349/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1094 - mae: 0.2582 - mse: 0.1094 - val_loss: 0.1451 - val_mae: 0.3007 - val_mse: 0.1451\n",
      "Epoch 350/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1092 - mae: 0.2582 - mse: 0.1092 - val_loss: 0.1448 - val_mae: 0.3005 - val_mse: 0.1448\n",
      "Epoch 351/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1090 - mae: 0.2580 - mse: 0.1090 - val_loss: 0.1458 - val_mae: 0.3006 - val_mse: 0.1458\n",
      "Epoch 352/500\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.1088 - mae: 0.2577 - mse: 0.1088 - val_loss: 0.1443 - val_mae: 0.3000 - val_mse: 0.1443\n",
      "Epoch 353/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1087 - mae: 0.2574 - mse: 0.1087 - val_loss: 0.1446 - val_mae: 0.2996 - val_mse: 0.1446\n",
      "Epoch 354/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1087 - mae: 0.2573 - mse: 0.1087 - val_loss: 0.1438 - val_mae: 0.2994 - val_mse: 0.1438\n",
      "Epoch 355/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1084 - mae: 0.2569 - mse: 0.1084 - val_loss: 0.1445 - val_mae: 0.2993 - val_mse: 0.1445\n",
      "Epoch 356/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1082 - mae: 0.2571 - mse: 0.1082 - val_loss: 0.1435 - val_mae: 0.2999 - val_mse: 0.1435\n",
      "Epoch 357/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1081 - mae: 0.2566 - mse: 0.1081 - val_loss: 0.1432 - val_mae: 0.2985 - val_mse: 0.1432\n",
      "Epoch 358/500\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.1083 - mae: 0.2567 - mse: 0.1083 - val_loss: 0.1441 - val_mae: 0.2987 - val_mse: 0.1441\n",
      "Epoch 359/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1074 - mae: 0.2559 - mse: 0.1074 - val_loss: 0.1432 - val_mae: 0.2997 - val_mse: 0.1432\n",
      "Epoch 360/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1078 - mae: 0.2557 - mse: 0.1078 - val_loss: 0.1432 - val_mae: 0.2980 - val_mse: 0.1432\n",
      "Epoch 361/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1075 - mae: 0.2556 - mse: 0.1075 - val_loss: 0.1434 - val_mae: 0.2980 - val_mse: 0.1434\n",
      "Epoch 362/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1070 - mae: 0.2553 - mse: 0.1070 - val_loss: 0.1432 - val_mae: 0.2978 - val_mse: 0.1432\n",
      "Epoch 363/500\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.1068 - mae: 0.2548 - mse: 0.1068 - val_loss: 0.1417 - val_mae: 0.2976 - val_mse: 0.1417\n",
      "Epoch 364/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1068 - mae: 0.2554 - mse: 0.1068 - val_loss: 0.1491 - val_mae: 0.3032 - val_mse: 0.1491\n",
      "Epoch 365/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1069 - mae: 0.2549 - mse: 0.1069 - val_loss: 0.1425 - val_mae: 0.2970 - val_mse: 0.1425\n",
      "Epoch 366/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1063 - mae: 0.2543 - mse: 0.1063 - val_loss: 0.1413 - val_mae: 0.2961 - val_mse: 0.1413\n",
      "Epoch 367/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1061 - mae: 0.2541 - mse: 0.1061 - val_loss: 0.1411 - val_mae: 0.2959 - val_mse: 0.1411\n",
      "Epoch 368/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1060 - mae: 0.2541 - mse: 0.1060 - val_loss: 0.1411 - val_mae: 0.2957 - val_mse: 0.1411\n",
      "Epoch 369/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1059 - mae: 0.2539 - mse: 0.1059 - val_loss: 0.1409 - val_mae: 0.2954 - val_mse: 0.1409\n",
      "Epoch 370/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1056 - mae: 0.2535 - mse: 0.1056 - val_loss: 0.1406 - val_mae: 0.2952 - val_mse: 0.1406\n",
      "Epoch 371/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1054 - mae: 0.2533 - mse: 0.1054 - val_loss: 0.1413 - val_mae: 0.2957 - val_mse: 0.1413\n",
      "Epoch 372/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1054 - mae: 0.2533 - mse: 0.1054 - val_loss: 0.1398 - val_mae: 0.2946 - val_mse: 0.1398\n",
      "Epoch 373/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1051 - mae: 0.2533 - mse: 0.1051 - val_loss: 0.1394 - val_mae: 0.2949 - val_mse: 0.1394\n",
      "Epoch 374/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1052 - mae: 0.2530 - mse: 0.1052 - val_loss: 0.1391 - val_mae: 0.2944 - val_mse: 0.1391\n",
      "Epoch 375/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1049 - mae: 0.2530 - mse: 0.1049 - val_loss: 0.1393 - val_mae: 0.2951 - val_mse: 0.1393\n",
      "Epoch 376/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1049 - mae: 0.2520 - mse: 0.1049 - val_loss: 0.1438 - val_mae: 0.2979 - val_mse: 0.1438\n",
      "Epoch 377/500\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.1046 - mae: 0.2521 - mse: 0.1046 - val_loss: 0.1392 - val_mae: 0.2935 - val_mse: 0.1392\n",
      "Epoch 378/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1042 - mae: 0.2518 - mse: 0.1042 - val_loss: 0.1384 - val_mae: 0.2932 - val_mse: 0.1384\n",
      "Epoch 379/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1041 - mae: 0.2521 - mse: 0.1041 - val_loss: 0.1382 - val_mae: 0.2929 - val_mse: 0.1382\n",
      "Epoch 380/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1038 - mae: 0.2513 - mse: 0.1038 - val_loss: 0.1380 - val_mae: 0.2926 - val_mse: 0.1380\n",
      "Epoch 381/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1040 - mae: 0.2514 - mse: 0.1040 - val_loss: 0.1387 - val_mae: 0.2929 - val_mse: 0.1387\n",
      "Epoch 382/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1038 - mae: 0.2512 - mse: 0.1038 - val_loss: 0.1374 - val_mae: 0.2925 - val_mse: 0.1374\n",
      "Epoch 383/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1033 - mae: 0.2507 - mse: 0.1033 - val_loss: 0.1383 - val_mae: 0.2925 - val_mse: 0.1383\n",
      "Epoch 384/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1035 - mae: 0.2509 - mse: 0.1035 - val_loss: 0.1373 - val_mae: 0.2917 - val_mse: 0.1373\n",
      "Epoch 385/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1030 - mae: 0.2501 - mse: 0.1030 - val_loss: 0.1374 - val_mae: 0.2916 - val_mse: 0.1374\n",
      "Epoch 386/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1029 - mae: 0.2501 - mse: 0.1029 - val_loss: 0.1375 - val_mae: 0.2916 - val_mse: 0.1375\n",
      "Epoch 387/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1029 - mae: 0.2501 - mse: 0.1029 - val_loss: 0.1366 - val_mae: 0.2918 - val_mse: 0.1366\n",
      "Epoch 388/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1028 - mae: 0.2497 - mse: 0.1028 - val_loss: 0.1362 - val_mae: 0.2910 - val_mse: 0.1362\n",
      "Epoch 389/500\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.1024 - mae: 0.2494 - mse: 0.1024 - val_loss: 0.1366 - val_mae: 0.2908 - val_mse: 0.1366\n",
      "Epoch 390/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1024 - mae: 0.2494 - mse: 0.1024 - val_loss: 0.1363 - val_mae: 0.2905 - val_mse: 0.1363\n",
      "Epoch 391/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1022 - mae: 0.2491 - mse: 0.1022 - val_loss: 0.1357 - val_mae: 0.2907 - val_mse: 0.1357\n",
      "Epoch 392/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1022 - mae: 0.2494 - mse: 0.1022 - val_loss: 0.1354 - val_mae: 0.2904 - val_mse: 0.1354\n",
      "Epoch 393/500\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.1018 - mae: 0.2488 - mse: 0.1018 - val_loss: 0.1358 - val_mae: 0.2899 - val_mse: 0.1358\n",
      "Epoch 394/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1016 - mae: 0.2485 - mse: 0.1016 - val_loss: 0.1355 - val_mae: 0.2896 - val_mse: 0.1355\n",
      "Epoch 395/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1014 - mae: 0.2483 - mse: 0.1014 - val_loss: 0.1349 - val_mae: 0.2892 - val_mse: 0.1349\n",
      "Epoch 396/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1014 - mae: 0.2479 - mse: 0.1014 - val_loss: 0.1388 - val_mae: 0.2927 - val_mse: 0.1388\n",
      "Epoch 397/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1018 - mae: 0.2488 - mse: 0.1018 - val_loss: 0.1357 - val_mae: 0.2895 - val_mse: 0.1357\n",
      "Epoch 398/500\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.1010 - mae: 0.2478 - mse: 0.1010 - val_loss: 0.1352 - val_mae: 0.2891 - val_mse: 0.1352\n",
      "Epoch 399/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1008 - mae: 0.2474 - mse: 0.1008 - val_loss: 0.1340 - val_mae: 0.2884 - val_mse: 0.1340\n",
      "Epoch 400/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1006 - mae: 0.2468 - mse: 0.1006 - val_loss: 0.1376 - val_mae: 0.2914 - val_mse: 0.1376\n",
      "Epoch 401/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1008 - mae: 0.2476 - mse: 0.1008 - val_loss: 0.1337 - val_mae: 0.2880 - val_mse: 0.1337\n",
      "Epoch 402/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1006 - mae: 0.2471 - mse: 0.1006 - val_loss: 0.1336 - val_mae: 0.2883 - val_mse: 0.1336\n",
      "Epoch 403/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1006 - mae: 0.2468 - mse: 0.1006 - val_loss: 0.1333 - val_mae: 0.2878 - val_mse: 0.1333\n",
      "Epoch 404/500\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.1001 - mae: 0.2466 - mse: 0.1001 - val_loss: 0.1339 - val_mae: 0.2877 - val_mse: 0.1339\n",
      "Epoch 405/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1000 - mae: 0.2463 - mse: 0.1000 - val_loss: 0.1330 - val_mae: 0.2871 - val_mse: 0.1330\n",
      "Epoch 406/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1001 - mae: 0.2465 - mse: 0.1001 - val_loss: 0.1328 - val_mae: 0.2870 - val_mse: 0.1328\n",
      "Epoch 407/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0997 - mae: 0.2460 - mse: 0.0997 - val_loss: 0.1333 - val_mae: 0.2871 - val_mse: 0.1333\n",
      "Epoch 408/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0995 - mae: 0.2458 - mse: 0.0995 - val_loss: 0.1331 - val_mae: 0.2868 - val_mse: 0.1331\n",
      "Epoch 409/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0995 - mae: 0.2459 - mse: 0.0995 - val_loss: 0.1324 - val_mae: 0.2863 - val_mse: 0.1324\n",
      "Epoch 410/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0995 - mae: 0.2456 - mse: 0.0995 - val_loss: 0.1324 - val_mae: 0.2862 - val_mse: 0.1324\n",
      "Epoch 411/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0992 - mae: 0.2453 - mse: 0.0992 - val_loss: 0.1325 - val_mae: 0.2861 - val_mse: 0.1325\n",
      "Epoch 412/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0993 - mae: 0.2451 - mse: 0.0993 - val_loss: 0.1318 - val_mae: 0.2857 - val_mse: 0.1318\n",
      "Epoch 413/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0990 - mae: 0.2447 - mse: 0.0990 - val_loss: 0.1315 - val_mae: 0.2856 - val_mse: 0.1315\n",
      "Epoch 414/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0987 - mae: 0.2447 - mse: 0.0987 - val_loss: 0.1324 - val_mae: 0.2859 - val_mse: 0.1324\n",
      "Epoch 415/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0987 - mae: 0.2447 - mse: 0.0987 - val_loss: 0.1314 - val_mae: 0.2851 - val_mse: 0.1314\n",
      "Epoch 416/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0984 - mae: 0.2443 - mse: 0.0984 - val_loss: 0.1321 - val_mae: 0.2856 - val_mse: 0.1321\n",
      "Epoch 417/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0984 - mae: 0.2444 - mse: 0.0984 - val_loss: 0.1308 - val_mae: 0.2847 - val_mse: 0.1308\n",
      "Epoch 418/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0982 - mae: 0.2441 - mse: 0.0982 - val_loss: 0.1306 - val_mae: 0.2845 - val_mse: 0.1306\n",
      "Epoch 419/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0981 - mae: 0.2439 - mse: 0.0981 - val_loss: 0.1370 - val_mae: 0.2905 - val_mse: 0.1370\n",
      "Epoch 420/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0981 - mae: 0.2438 - mse: 0.0981 - val_loss: 0.1305 - val_mae: 0.2847 - val_mse: 0.1305\n",
      "Epoch 421/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0980 - mae: 0.2438 - mse: 0.0980 - val_loss: 0.1304 - val_mae: 0.2840 - val_mse: 0.1304\n",
      "Epoch 422/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0979 - mae: 0.2435 - mse: 0.0979 - val_loss: 0.1306 - val_mae: 0.2839 - val_mse: 0.1306\n",
      "Epoch 423/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0976 - mae: 0.2434 - mse: 0.0976 - val_loss: 0.1301 - val_mae: 0.2836 - val_mse: 0.1301\n",
      "Epoch 424/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0977 - mae: 0.2433 - mse: 0.0977 - val_loss: 0.1296 - val_mae: 0.2834 - val_mse: 0.1296\n",
      "Epoch 425/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0977 - mae: 0.2433 - mse: 0.0977 - val_loss: 0.1296 - val_mae: 0.2836 - val_mse: 0.1296\n",
      "Epoch 426/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0973 - mae: 0.2427 - mse: 0.0973 - val_loss: 0.1293 - val_mae: 0.2830 - val_mse: 0.1293\n",
      "Epoch 427/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0971 - mae: 0.2427 - mse: 0.0971 - val_loss: 0.1305 - val_mae: 0.2837 - val_mse: 0.1305\n",
      "Epoch 428/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0968 - mae: 0.2421 - mse: 0.0968 - val_loss: 0.1293 - val_mae: 0.2826 - val_mse: 0.1293\n",
      "Epoch 429/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0970 - mae: 0.2422 - mse: 0.0970 - val_loss: 0.1308 - val_mae: 0.2839 - val_mse: 0.1308\n",
      "Epoch 430/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0965 - mae: 0.2418 - mse: 0.0965 - val_loss: 0.1288 - val_mae: 0.2826 - val_mse: 0.1288\n",
      "Epoch 431/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0968 - mae: 0.2417 - mse: 0.0968 - val_loss: 0.1288 - val_mae: 0.2820 - val_mse: 0.1288\n",
      "Epoch 432/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0964 - mae: 0.2416 - mse: 0.0964 - val_loss: 0.1286 - val_mae: 0.2818 - val_mse: 0.1286\n",
      "Epoch 433/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0962 - mae: 0.2414 - mse: 0.0962 - val_loss: 0.1288 - val_mae: 0.2818 - val_mse: 0.1288\n",
      "Epoch 434/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0963 - mae: 0.2412 - mse: 0.0963 - val_loss: 0.1283 - val_mae: 0.2815 - val_mse: 0.1283\n",
      "Epoch 435/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0960 - mae: 0.2411 - mse: 0.0960 - val_loss: 0.1282 - val_mae: 0.2813 - val_mse: 0.1282\n",
      "Epoch 436/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0960 - mae: 0.2411 - mse: 0.0960 - val_loss: 0.1287 - val_mae: 0.2816 - val_mse: 0.1287\n",
      "Epoch 437/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0959 - mae: 0.2410 - mse: 0.0959 - val_loss: 0.1276 - val_mae: 0.2809 - val_mse: 0.1276\n",
      "Epoch 438/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0957 - mae: 0.2407 - mse: 0.0957 - val_loss: 0.1274 - val_mae: 0.2808 - val_mse: 0.1274\n",
      "Epoch 439/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0962 - mae: 0.2405 - mse: 0.0962 - val_loss: 0.1277 - val_mae: 0.2807 - val_mse: 0.1277\n",
      "Epoch 440/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0955 - mae: 0.2403 - mse: 0.0955 - val_loss: 0.1276 - val_mae: 0.2805 - val_mse: 0.1276\n",
      "Epoch 441/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0954 - mae: 0.2402 - mse: 0.0954 - val_loss: 0.1287 - val_mae: 0.2816 - val_mse: 0.1287\n",
      "Epoch 442/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0956 - mae: 0.2403 - mse: 0.0956 - val_loss: 0.1293 - val_mae: 0.2821 - val_mse: 0.1293\n",
      "Epoch 443/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0950 - mae: 0.2398 - mse: 0.0950 - val_loss: 0.1268 - val_mae: 0.2798 - val_mse: 0.1268\n",
      "Epoch 444/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0950 - mae: 0.2398 - mse: 0.0950 - val_loss: 0.1287 - val_mae: 0.2815 - val_mse: 0.1287\n",
      "Epoch 445/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0949 - mae: 0.2396 - mse: 0.0949 - val_loss: 0.1266 - val_mae: 0.2795 - val_mse: 0.1266\n",
      "Epoch 446/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0947 - mae: 0.2394 - mse: 0.0947 - val_loss: 0.1270 - val_mae: 0.2798 - val_mse: 0.1270\n",
      "Epoch 447/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0950 - mae: 0.2393 - mse: 0.0950 - val_loss: 0.1271 - val_mae: 0.2807 - val_mse: 0.1271\n",
      "Epoch 448/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0947 - mae: 0.2391 - mse: 0.0947 - val_loss: 0.1276 - val_mae: 0.2802 - val_mse: 0.1276\n",
      "Epoch 449/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0943 - mae: 0.2388 - mse: 0.0943 - val_loss: 0.1260 - val_mae: 0.2788 - val_mse: 0.1260\n",
      "Epoch 450/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0944 - mae: 0.2389 - mse: 0.0944 - val_loss: 0.1257 - val_mae: 0.2786 - val_mse: 0.1257\n",
      "Epoch 451/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0942 - mae: 0.2387 - mse: 0.0942 - val_loss: 0.1256 - val_mae: 0.2784 - val_mse: 0.1256\n",
      "Epoch 452/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0940 - mae: 0.2385 - mse: 0.0940 - val_loss: 0.1256 - val_mae: 0.2783 - val_mse: 0.1256\n",
      "Epoch 453/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0940 - mae: 0.2382 - mse: 0.0940 - val_loss: 0.1255 - val_mae: 0.2782 - val_mse: 0.1255\n",
      "Epoch 454/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0938 - mae: 0.2380 - mse: 0.0938 - val_loss: 0.1259 - val_mae: 0.2785 - val_mse: 0.1259\n",
      "Epoch 455/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0938 - mae: 0.2380 - mse: 0.0938 - val_loss: 0.1252 - val_mae: 0.2779 - val_mse: 0.1252\n",
      "Epoch 456/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0936 - mae: 0.2379 - mse: 0.0936 - val_loss: 0.1248 - val_mae: 0.2778 - val_mse: 0.1248\n",
      "Epoch 457/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0935 - mae: 0.2375 - mse: 0.0935 - val_loss: 0.1258 - val_mae: 0.2783 - val_mse: 0.1258\n",
      "Epoch 458/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0934 - mae: 0.2374 - mse: 0.0934 - val_loss: 0.1246 - val_mae: 0.2772 - val_mse: 0.1246\n",
      "Epoch 459/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0933 - mae: 0.2374 - mse: 0.0933 - val_loss: 0.1244 - val_mae: 0.2770 - val_mse: 0.1244\n",
      "Epoch 460/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0932 - mae: 0.2372 - mse: 0.0932 - val_loss: 0.1245 - val_mae: 0.2770 - val_mse: 0.1245\n",
      "Epoch 461/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0932 - mae: 0.2373 - mse: 0.0932 - val_loss: 0.1241 - val_mae: 0.2767 - val_mse: 0.1241\n",
      "Epoch 462/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0930 - mae: 0.2371 - mse: 0.0930 - val_loss: 0.1241 - val_mae: 0.2766 - val_mse: 0.1241\n",
      "Epoch 463/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0929 - mae: 0.2369 - mse: 0.0929 - val_loss: 0.1240 - val_mae: 0.2764 - val_mse: 0.1240\n",
      "Epoch 464/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0929 - mae: 0.2369 - mse: 0.0929 - val_loss: 0.1251 - val_mae: 0.2774 - val_mse: 0.1251\n",
      "Epoch 465/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0926 - mae: 0.2367 - mse: 0.0926 - val_loss: 0.1239 - val_mae: 0.2763 - val_mse: 0.1239\n",
      "Epoch 466/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0929 - mae: 0.2369 - mse: 0.0929 - val_loss: 0.1244 - val_mae: 0.2767 - val_mse: 0.1244\n",
      "Epoch 467/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0925 - mae: 0.2363 - mse: 0.0925 - val_loss: 0.1241 - val_mae: 0.2764 - val_mse: 0.1241\n",
      "Epoch 468/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0924 - mae: 0.2362 - mse: 0.0924 - val_loss: 0.1245 - val_mae: 0.2768 - val_mse: 0.1245\n",
      "Epoch 469/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0925 - mae: 0.2362 - mse: 0.0925 - val_loss: 0.1237 - val_mae: 0.2769 - val_mse: 0.1237\n",
      "Epoch 470/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0926 - mae: 0.2364 - mse: 0.0926 - val_loss: 0.1234 - val_mae: 0.2764 - val_mse: 0.1234\n",
      "Epoch 471/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0923 - mae: 0.2357 - mse: 0.0923 - val_loss: 0.1252 - val_mae: 0.2773 - val_mse: 0.1252\n",
      "Epoch 472/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0917 - mae: 0.2354 - mse: 0.0917 - val_loss: 0.1240 - val_mae: 0.2775 - val_mse: 0.1240\n",
      "Epoch 473/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0924 - mae: 0.2363 - mse: 0.0924 - val_loss: 0.1237 - val_mae: 0.2758 - val_mse: 0.1237\n",
      "Epoch 474/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0920 - mae: 0.2357 - mse: 0.0920 - val_loss: 0.1251 - val_mae: 0.2771 - val_mse: 0.1251\n",
      "Epoch 475/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0917 - mae: 0.2353 - mse: 0.0917 - val_loss: 0.1233 - val_mae: 0.2755 - val_mse: 0.1233\n",
      "Epoch 476/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0915 - mae: 0.2349 - mse: 0.0915 - val_loss: 0.1222 - val_mae: 0.2748 - val_mse: 0.1222\n",
      "Epoch 477/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0915 - mae: 0.2348 - mse: 0.0915 - val_loss: 0.1222 - val_mae: 0.2744 - val_mse: 0.1222\n",
      "Epoch 478/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0914 - mae: 0.2349 - mse: 0.0914 - val_loss: 0.1241 - val_mae: 0.2760 - val_mse: 0.1241\n",
      "Epoch 479/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0915 - mae: 0.2346 - mse: 0.0915 - val_loss: 0.1218 - val_mae: 0.2741 - val_mse: 0.1218\n",
      "Epoch 480/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0910 - mae: 0.2343 - mse: 0.0910 - val_loss: 0.1234 - val_mae: 0.2754 - val_mse: 0.1234\n",
      "Epoch 481/500\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0910 - mae: 0.2341 - mse: 0.0910 - val_loss: 0.1217 - val_mae: 0.2738 - val_mse: 0.1217\n",
      "Epoch 482/500\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0911 - mae: 0.2345 - mse: 0.0911 - val_loss: 0.1216 - val_mae: 0.2737 - val_mse: 0.1216\n",
      "Epoch 483/500\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0910 - mae: 0.2343 - mse: 0.0910 - val_loss: 0.1217 - val_mae: 0.2737 - val_mse: 0.1217\n",
      "Epoch 484/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0907 - mae: 0.2339 - mse: 0.0907 - val_loss: 0.1212 - val_mae: 0.2734 - val_mse: 0.1212\n",
      "Epoch 485/500\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0907 - mae: 0.2338 - mse: 0.0907 - val_loss: 0.1222 - val_mae: 0.2742 - val_mse: 0.1222\n",
      "Epoch 486/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0907 - mae: 0.2340 - mse: 0.0907 - val_loss: 0.1220 - val_mae: 0.2740 - val_mse: 0.1220\n",
      "Epoch 487/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0904 - mae: 0.2335 - mse: 0.0904 - val_loss: 0.1208 - val_mae: 0.2730 - val_mse: 0.1208\n",
      "Epoch 488/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0905 - mae: 0.2338 - mse: 0.0905 - val_loss: 0.1208 - val_mae: 0.2731 - val_mse: 0.1208\n",
      "Epoch 489/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0905 - mae: 0.2335 - mse: 0.0905 - val_loss: 0.1206 - val_mae: 0.2727 - val_mse: 0.1206\n",
      "Epoch 490/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0905 - mae: 0.2334 - mse: 0.0905 - val_loss: 0.1224 - val_mae: 0.2742 - val_mse: 0.1224\n",
      "Epoch 491/500\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0901 - mae: 0.2331 - mse: 0.0901 - val_loss: 0.1210 - val_mae: 0.2730 - val_mse: 0.1210\n",
      "Epoch 492/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0901 - mae: 0.2332 - mse: 0.0901 - val_loss: 0.1218 - val_mae: 0.2736 - val_mse: 0.1218\n",
      "Epoch 493/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0899 - mae: 0.2326 - mse: 0.0899 - val_loss: 0.1203 - val_mae: 0.2722 - val_mse: 0.1203\n",
      "Epoch 494/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0898 - mae: 0.2326 - mse: 0.0898 - val_loss: 0.1200 - val_mae: 0.2721 - val_mse: 0.1200\n",
      "Epoch 495/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0899 - mae: 0.2328 - mse: 0.0899 - val_loss: 0.1200 - val_mae: 0.2722 - val_mse: 0.1200\n",
      "Epoch 496/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0900 - mae: 0.2329 - mse: 0.0900 - val_loss: 0.1199 - val_mae: 0.2721 - val_mse: 0.1199\n",
      "Epoch 497/500\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0896 - mae: 0.2323 - mse: 0.0896 - val_loss: 0.1205 - val_mae: 0.2723 - val_mse: 0.1205\n",
      "Epoch 498/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0895 - mae: 0.2322 - mse: 0.0895 - val_loss: 0.1202 - val_mae: 0.2720 - val_mse: 0.1202\n",
      "Epoch 499/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0893 - mae: 0.2318 - mse: 0.0893 - val_loss: 0.1196 - val_mae: 0.2718 - val_mse: 0.1196\n",
      "Epoch 500/500\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0893 - mae: 0.2314 - mse: 0.0893 - val_loss: 0.1246 - val_mae: 0.2761 - val_mse: 0.1246\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = build_model()\n",
    "\n",
    "# O parâmetro patience é o quantidade de epochs para checar as melhoras\n",
    "early_stop = keras.callbacks.EarlyStopping(\n",
    "  monitor='val_mse', patience=25, mode='min' ,restore_best_weights=True)\n",
    "\n",
    "history = model.fit(train_dataset, train_labels, epochs=EPOCHS,\n",
    "                    validation_split = 0.2, verbose=1, callbacks=[early_stop, tensorboard_callback])\n",
    "\n",
    "# Mudar os dados de validação\n",
    "\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 - 0s - loss: 0.2634 - mae: 0.3143 - mse: 0.2634\n",
      "Testing set Mean Abs Error:  0.26 ibova_0\n"
     ]
    }
   ],
   "source": [
    "loss, mae, mse = model.evaluate(test_dataset, test_labels, verbose=2)\n",
    "\n",
    "print(f\"Testing set Mean Abs Error: {mse:5.2f} ibova_0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Realizando as previsões"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = model.predict(test_dataset).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avaliando as previsões:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_test_labels():\n",
    "\t# Imprimindo valores reais\n",
    "\tplt.plot(test_labels, color ='r', label='ibova_REAL')\n",
    "\tplt.xlabel(\"Dates\")\n",
    "\tplt.ylabel(\"Variation ROC\")\n",
    "\tplt.title(\"ibova_REAL\")\n",
    "\tplt.legend()\n",
    "\n",
    "def show_model_predictions():\n",
    "\t# Imprimindo previsoes\n",
    "\tplt.plot(test_predictions, color ='g', label='predictions_MODEL')\n",
    "\tplt.xlabel(\"Dates\")\n",
    "\tplt.ylabel(\"Variation ROC\")\n",
    "\tplt.title(\"predictions_MODEL\")\n",
    "\tplt.legend()\n",
    "\n",
    "def show_compare_graph():\n",
    "\t# Predictt X Real values\n",
    "\tplt.plot(test_labels, color ='r', label='ibova_REAL')\n",
    "\tplt.plot(test_predictions, color ='g', label='predictions_MODEL')\n",
    "\tplt.xlabel(\"Dates\")\n",
    "\tplt.ylabel(\"Variation ROC\")\n",
    "\tplt.title(\"Predict X Real values\")\n",
    "\tplt.legend()\n",
    "\tplt.show()\n",
    "\n",
    "def show_true_predict_values():\n",
    "\tplt.figure(figsize=(24,4))\n",
    "\tplt.scatter(test_labels, test_predictions)\n",
    "\tplt.xlabel('True Values [ibova_0]')\n",
    "\tplt.ylabel('Predictions [ibova_0]')\n",
    "\tplt.axis('equal')\n",
    "\tplt.axis('square')\n",
    "\tplt.xlim([0,plt.xlim()[1]])\n",
    "\tplt.ylim([0,plt.ylim()[1]])\n",
    "\t_ = plt.plot([-100, 100], [-100, 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Massa de predição: 0.020847512409090996\n",
      "Massa inicial: 0.014602090989644002\n",
      "Diferenças das médias: -0.006245421419446994\n"
     ]
    }
   ],
   "source": [
    "# Analisando Medias:\n",
    "\n",
    "print(f'Massa de predição: {test_predictions.mean()}')\n",
    "print(f'Massa inicial: {ibova_test.mean()}')\n",
    "print(f'Diferenças das médias: {ibova_test.mean() - test_predictions.mean()}')\n",
    "\n",
    "# Add o RM_MSE medio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_dataset"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8949756f31a89c949d21dc88cc29a9a975f9c9df810132ca4a98332ae1fc2efb"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('pystock': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
