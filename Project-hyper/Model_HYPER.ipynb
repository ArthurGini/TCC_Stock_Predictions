{
	"cells": [
		{
			"cell_type": "code",
			"execution_count": 2,
			"metadata": {},
			"outputs": [],
			"source": [
				"# cd 'C:/Users/arthu/Documents/GitHub/TCC_Stock_Predictions/'"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1,
			"metadata": {},
			"outputs": [
				{
					"data": {
						"application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 1;\n                var nbb_unformatted_code = \"%load_ext nb_black\";\n                var nbb_formatted_code = \"%load_ext nb_black\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
						"text/plain": [
							"<IPython.core.display.Javascript object>"
						]
					},
					"metadata": {},
					"output_type": "display_data"
				}
			],
			"source": [
				"%load_ext nb_black"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 2,
			"metadata": {},
			"outputs": [
				{
					"data": {
						"application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 2;\n                var nbb_unformatted_code = \"%load_ext lab_black\";\n                var nbb_formatted_code = \"%load_ext lab_black\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
						"text/plain": [
							"<IPython.core.display.Javascript object>"
						]
					},
					"metadata": {},
					"output_type": "display_data"
				}
			],
			"source": [
				"%load_ext lab_black"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"# Window Process "
			]
		},
		{
			"cell_type": "code",
			"execution_count": 3,
			"metadata": {},
			"outputs": [
				{
					"data": {
						"application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 3;\n                var nbb_unformatted_code = \"# Import packages\\nimport numpy as np\\nimport pandas as pd\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.model_selection import cross_val_score\\nfrom keras.models import Sequential\\nfrom keras.layers import Dense, BatchNormalization, Dropout\\nfrom keras.optimizers import Adam, SGD, RMSprop, Adadelta, Adagrad, Adamax, Nadam, Ftrl\\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\\nfrom keras.wrappers.scikit_learn import KerasClassifier\\nfrom math import floor\\nfrom sklearn.metrics import make_scorer, accuracy_score\\nfrom bayes_opt import BayesianOptimization\\nfrom sklearn.model_selection import StratifiedKFold\\nfrom keras.layers import LeakyReLU\\n\\nLeakyReLU = LeakyReLU(alpha=0.1)\\nimport warnings\\n\\nwarnings.filterwarnings(\\\"ignore\\\")\\npd.set_option(\\\"display.max_columns\\\", None)\";\n                var nbb_formatted_code = \"# Import packages\\nimport numpy as np\\nimport pandas as pd\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.model_selection import cross_val_score\\nfrom keras.models import Sequential\\nfrom keras.layers import Dense, BatchNormalization, Dropout\\nfrom keras.optimizers import Adam, SGD, RMSprop, Adadelta, Adagrad, Adamax, Nadam, Ftrl\\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\\nfrom keras.wrappers.scikit_learn import KerasClassifier\\nfrom math import floor\\nfrom sklearn.metrics import make_scorer, accuracy_score\\nfrom bayes_opt import BayesianOptimization\\nfrom sklearn.model_selection import StratifiedKFold\\nfrom keras.layers import LeakyReLU\\n\\nLeakyReLU = LeakyReLU(alpha=0.1)\\nimport warnings\\n\\nwarnings.filterwarnings(\\\"ignore\\\")\\npd.set_option(\\\"display.max_columns\\\", None)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
						"text/plain": [
							"<IPython.core.display.Javascript object>"
						]
					},
					"metadata": {},
					"output_type": "display_data"
				}
			],
			"source": [
				"# Import packages\n",
				"import numpy as np\n",
				"import pandas as pd\n",
				"import matplotlib.pyplot as plt\n",
				"import seaborn as sns\n",
				"from sklearn.model_selection import train_test_split\n",
				"from sklearn.model_selection import cross_val_score\n",
				"from keras.models import Sequential\n",
				"from keras.layers import Dense, BatchNormalization, Dropout\n",
				"from keras.optimizers import Adam, SGD, RMSprop, Adadelta, Adagrad, Adamax, Nadam, Ftrl\n",
				"from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
				"from keras.wrappers.scikit_learn import KerasClassifier\n",
				"from math import floor\n",
				"from sklearn.metrics import make_scorer, accuracy_score\n",
				"from bayes_opt import BayesianOptimization\n",
				"from sklearn.model_selection import StratifiedKFold\n",
				"from keras.layers import LeakyReLU\n",
				"\n",
				"LeakyReLU = LeakyReLU(alpha=0.1)\n",
				"import warnings\n",
				"\n",
				"warnings.filterwarnings(\"ignore\")\n",
				"pd.set_option(\"display.max_columns\", None)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 6,
			"metadata": {},
			"outputs": [
				{
					"data": {
						"application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 6;\n                var nbb_unformatted_code = \"# Make scorer accuracy\\nscore_acc = make_scorer(accuracy_score)\";\n                var nbb_formatted_code = \"# Make scorer accuracy\\nscore_acc = make_scorer(accuracy_score)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
						"text/plain": [
							"<IPython.core.display.Javascript object>"
						]
					},
					"metadata": {},
					"output_type": "display_data"
				}
			],
			"source": [
				"# Make scorer accuracy\n",
				"score_acc = make_scorer(accuracy_score)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 4,
			"metadata": {},
			"outputs": [
				{
					"data": {
						"application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 4;\n                var nbb_unformatted_code = \"# 60%\\nPATH_TREINO = \\\"../Data/3_Gold/Treino_all_stocks.csv\\\"\\nDF_TREINO = pd.read_csv(PATH_TREINO, sep=\\\",\\\")\\ntrain_dataset = DF_TREINO\\ntrain_dataset = train_dataset.drop(\\n    [\\n        \\\"oil_5\\\",\\n        \\\"usd_5\\\",\\n        \\\"abev_5\\\",\\n        \\\"jbs_5\\\",\\n        \\\"petr_5\\\",\\n        \\\"vale_5\\\",\\n    ],\\n    axis=1,\\n)\\ntrain_labels = train_dataset.pop(\\\"ibova_5\\\")\\n# train_dataset = train_dataset.iloc[:476]\\n\\n# 20%\\nPATH_VALIDACAO = \\\"../Data/3_Gold/Validacao_all_stocks.csv\\\"\\nDF_VALIDACAO = pd.read_csv(PATH_VALIDACAO, sep=\\\",\\\")\\nvalid_dataset = DF_VALIDACAO\\nvalid_dataset = valid_dataset.drop(\\n    [\\n        \\\"ibova_5\\\",\\n        \\\"oil_5\\\",\\n        \\\"usd_5\\\",\\n        \\\"abev_5\\\",\\n        \\\"jbs_5\\\",\\n        \\\"petr_5\\\",\\n        \\\"vale_5\\\",\\n    ],\\n    axis=1,\\n)\\n# valid_labels = valid_dataset.pop('ibova_5')\\n\\n# 20%\\nPATH_TESTE = \\\"../Data/3_Gold/Teste_all_stocks.csv\\\"\\nDF_TESTE = pd.read_csv(PATH_TESTE, sep=\\\",\\\")\\ntest_dataset = DF_TESTE\\ntest_dataset = test_dataset.drop(\\n    [\\n        \\\"oil_5\\\",\\n        \\\"usd_5\\\",\\n        \\\"abev_5\\\",\\n        \\\"jbs_5\\\",\\n        \\\"petr_5\\\",\\n        \\\"vale_5\\\",\\n    ],\\n    axis=1,\\n)\\ntest_labels = test_dataset.pop(\\\"ibova_5\\\")\";\n                var nbb_formatted_code = \"# 60%\\nPATH_TREINO = \\\"../Data/3_Gold/Treino_all_stocks.csv\\\"\\nDF_TREINO = pd.read_csv(PATH_TREINO, sep=\\\",\\\")\\ntrain_dataset = DF_TREINO\\ntrain_dataset = train_dataset.drop(\\n    [\\n        \\\"oil_5\\\",\\n        \\\"usd_5\\\",\\n        \\\"abev_5\\\",\\n        \\\"jbs_5\\\",\\n        \\\"petr_5\\\",\\n        \\\"vale_5\\\",\\n    ],\\n    axis=1,\\n)\\ntrain_labels = train_dataset.pop(\\\"ibova_5\\\")\\n# train_dataset = train_dataset.iloc[:476]\\n\\n# 20%\\nPATH_VALIDACAO = \\\"../Data/3_Gold/Validacao_all_stocks.csv\\\"\\nDF_VALIDACAO = pd.read_csv(PATH_VALIDACAO, sep=\\\",\\\")\\nvalid_dataset = DF_VALIDACAO\\nvalid_dataset = valid_dataset.drop(\\n    [\\n        \\\"ibova_5\\\",\\n        \\\"oil_5\\\",\\n        \\\"usd_5\\\",\\n        \\\"abev_5\\\",\\n        \\\"jbs_5\\\",\\n        \\\"petr_5\\\",\\n        \\\"vale_5\\\",\\n    ],\\n    axis=1,\\n)\\n# valid_labels = valid_dataset.pop('ibova_5')\\n\\n# 20%\\nPATH_TESTE = \\\"../Data/3_Gold/Teste_all_stocks.csv\\\"\\nDF_TESTE = pd.read_csv(PATH_TESTE, sep=\\\",\\\")\\ntest_dataset = DF_TESTE\\ntest_dataset = test_dataset.drop(\\n    [\\n        \\\"oil_5\\\",\\n        \\\"usd_5\\\",\\n        \\\"abev_5\\\",\\n        \\\"jbs_5\\\",\\n        \\\"petr_5\\\",\\n        \\\"vale_5\\\",\\n    ],\\n    axis=1,\\n)\\ntest_labels = test_dataset.pop(\\\"ibova_5\\\")\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
						"text/plain": [
							"<IPython.core.display.Javascript object>"
						]
					},
					"metadata": {},
					"output_type": "display_data"
				}
			],
			"source": [
				"# 60%\n",
				"PATH_TREINO = \"../Data/3_Gold/Treino_all_stocks.csv\"\n",
				"DF_TREINO = pd.read_csv(PATH_TREINO, sep=\",\")\n",
				"train_dataset = DF_TREINO\n",
				"train_dataset = train_dataset.drop(\n",
				"    [\n",
				"        \"oil_5\",\n",
				"        \"usd_5\",\n",
				"        \"abev_5\",\n",
				"        \"jbs_5\",\n",
				"        \"petr_5\",\n",
				"        \"vale_5\",\n",
				"    ],\n",
				"    axis=1,\n",
				")\n",
				"train_labels = train_dataset.pop(\"ibova_5\")\n",
				"# train_dataset = train_dataset.iloc[:476]\n",
				"\n",
				"# 20%\n",
				"PATH_VALIDACAO = \"../Data/3_Gold/Validacao_all_stocks.csv\"\n",
				"DF_VALIDACAO = pd.read_csv(PATH_VALIDACAO, sep=\",\")\n",
				"valid_dataset = DF_VALIDACAO\n",
				"valid_dataset = valid_dataset.drop(\n",
				"    [\n",
				"        \"ibova_5\",\n",
				"        \"oil_5\",\n",
				"        \"usd_5\",\n",
				"        \"abev_5\",\n",
				"        \"jbs_5\",\n",
				"        \"petr_5\",\n",
				"        \"vale_5\",\n",
				"    ],\n",
				"    axis=1,\n",
				")\n",
				"# valid_labels = valid_dataset.pop('ibova_5')\n",
				"\n",
				"# 20%\n",
				"PATH_TESTE = \"../Data/3_Gold/Teste_all_stocks.csv\"\n",
				"DF_TESTE = pd.read_csv(PATH_TESTE, sep=\",\")\n",
				"test_dataset = DF_TESTE\n",
				"test_dataset = test_dataset.drop(\n",
				"    [\n",
				"        \"oil_5\",\n",
				"        \"usd_5\",\n",
				"        \"abev_5\",\n",
				"        \"jbs_5\",\n",
				"        \"petr_5\",\n",
				"        \"vale_5\",\n",
				"    ],\n",
				"    axis=1,\n",
				")\n",
				"test_labels = test_dataset.pop(\"ibova_5\")"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 8,
			"metadata": {},
			"outputs": [
				{
					"data": {
						"application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 8;\n                var nbb_unformatted_code = \"# Load dataset\\ntrainSet = pd.read_csv(\\\"../Project-hyper/train.csv\\\")\\n# Feature generation: training data\\ntrain = trainSet.drop(columns=[\\\"Name\\\", \\\"Ticket\\\", \\\"Cabin\\\"])\\ntrain = train.dropna(axis=0)\\ntrain = pd.get_dummies(train)\\n# train validation split\\ntrain_dataset, train_labels, y_train, y_val = train_test_split(\\n    train.drop(columns=[\\\"PassengerId\\\", \\\"Survived\\\"], axis=0),\\n    train[\\\"Survived\\\"],\\n    test_size=0.2,\\n    random_state=111,\\n    stratify=train[\\\"Survived\\\"],\\n)\";\n                var nbb_formatted_code = \"# Load dataset\\ntrainSet = pd.read_csv(\\\"../Project-hyper/train.csv\\\")\\n# Feature generation: training data\\ntrain = trainSet.drop(columns=[\\\"Name\\\", \\\"Ticket\\\", \\\"Cabin\\\"])\\ntrain = train.dropna(axis=0)\\ntrain = pd.get_dummies(train)\\n# train validation split\\ntrain_dataset, train_labels, y_train, y_val = train_test_split(\\n    train.drop(columns=[\\\"PassengerId\\\", \\\"Survived\\\"], axis=0),\\n    train[\\\"Survived\\\"],\\n    test_size=0.2,\\n    random_state=111,\\n    stratify=train[\\\"Survived\\\"],\\n)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
						"text/plain": [
							"<IPython.core.display.Javascript object>"
						]
					},
					"metadata": {},
					"output_type": "display_data"
				}
			],
			"source": [
				"# Load dataset\n",
				"trainSet = pd.read_csv(\"../Project-hyper/train.csv\")\n",
				"# Feature generation: training data\n",
				"train = trainSet.drop(columns=[\"Name\", \"Ticket\", \"Cabin\"])\n",
				"train = train.dropna(axis=0)\n",
				"train = pd.get_dummies(train)\n",
				"# train validation split\n",
				"train_dataset, train_labels, y_train, y_val = train_test_split(\n",
				"    train.drop(columns=[\"PassengerId\", \"Survived\"], axis=0),\n",
				"    train[\"Survived\"],\n",
				"    test_size=0.2,\n",
				"    random_state=111,\n",
				"    stratify=train[\"Survived\"],\n",
				")"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": []
		},
		{
			"cell_type": "code",
			"execution_count": 9,
			"metadata": {},
			"outputs": [
				{
					"data": {
						"application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 9;\n                var nbb_unformatted_code = \"# Create function\\ndef nn_cl_bo(neurons, activation, optimizer, learning_rate, batch_size, epochs):\\n    optimizerL = [\\n        \\\"SGD\\\",\\n        \\\"Adam\\\",\\n        \\\"RMSprop\\\",\\n        \\\"Adadelta\\\",\\n        \\\"Adagrad\\\",\\n        \\\"Adamax\\\",\\n        \\\"Nadam\\\",\\n        \\\"Ftrl\\\",\\n        \\\"SGD\\\",\\n    ]\\n    optimizerD = {\\n        \\\"Adam\\\": Adam(lr=learning_rate),\\n        \\\"SGD\\\": SGD(lr=learning_rate),\\n        \\\"RMSprop\\\": RMSprop(lr=learning_rate),\\n        \\\"Adadelta\\\": Adadelta(lr=learning_rate),\\n        \\\"Adagrad\\\": Adagrad(lr=learning_rate),\\n        \\\"Adamax\\\": Adamax(lr=learning_rate),\\n        \\\"Nadam\\\": Nadam(lr=learning_rate),\\n        \\\"Ftrl\\\": Ftrl(lr=learning_rate),\\n    }\\n    activationL = [\\n        \\\"relu\\\",\\n        \\\"sigmoid\\\",\\n        \\\"softplus\\\",\\n        \\\"softsign\\\",\\n        \\\"tanh\\\",\\n        \\\"selu\\\",\\n        \\\"elu\\\",\\n        \\\"exponential\\\",\\n        LeakyReLU,\\n        \\\"relu\\\",\\n    ]\\n    neurons = round(neurons)\\n    activation = activationL[round(activation)]\\n    batch_size = round(batch_size)\\n    epochs = round(epochs)\\n\\n    def nn_cl_fun():\\n        opt = Adam(lr=learning_rate)\\n        nn = Sequential()\\n        nn.add(Dense(neurons, input_dim=10, activation=activation))\\n        nn.add(Dense(neurons, activation=activation))\\n        nn.add(Dense(1, activation=\\\"sigmoid\\\"))\\n        nn.compile(loss=\\\"binary_crossentropy\\\", optimizer=opt, metrics=[\\\"accuracy\\\"])\\n        return nn\\n\\n    es = EarlyStopping(monitor=\\\"accuracy\\\", mode=\\\"max\\\", verbose=0, patience=20)\\n    nn = KerasClassifier(\\n        build_fn=nn_cl_fun, epochs=epochs, batch_size=batch_size, verbose=0\\n    )\\n    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=123)\\n    score = cross_val_score(\\n        nn,\\n        train_dataset,\\n        y_train,\\n        scoring=score_acc,\\n        cv=kfold,\\n        fit_params={\\\"callbacks\\\": [es]},\\n    ).mean()\\n    return score\";\n                var nbb_formatted_code = \"# Create function\\ndef nn_cl_bo(neurons, activation, optimizer, learning_rate, batch_size, epochs):\\n    optimizerL = [\\n        \\\"SGD\\\",\\n        \\\"Adam\\\",\\n        \\\"RMSprop\\\",\\n        \\\"Adadelta\\\",\\n        \\\"Adagrad\\\",\\n        \\\"Adamax\\\",\\n        \\\"Nadam\\\",\\n        \\\"Ftrl\\\",\\n        \\\"SGD\\\",\\n    ]\\n    optimizerD = {\\n        \\\"Adam\\\": Adam(lr=learning_rate),\\n        \\\"SGD\\\": SGD(lr=learning_rate),\\n        \\\"RMSprop\\\": RMSprop(lr=learning_rate),\\n        \\\"Adadelta\\\": Adadelta(lr=learning_rate),\\n        \\\"Adagrad\\\": Adagrad(lr=learning_rate),\\n        \\\"Adamax\\\": Adamax(lr=learning_rate),\\n        \\\"Nadam\\\": Nadam(lr=learning_rate),\\n        \\\"Ftrl\\\": Ftrl(lr=learning_rate),\\n    }\\n    activationL = [\\n        \\\"relu\\\",\\n        \\\"sigmoid\\\",\\n        \\\"softplus\\\",\\n        \\\"softsign\\\",\\n        \\\"tanh\\\",\\n        \\\"selu\\\",\\n        \\\"elu\\\",\\n        \\\"exponential\\\",\\n        LeakyReLU,\\n        \\\"relu\\\",\\n    ]\\n    neurons = round(neurons)\\n    activation = activationL[round(activation)]\\n    batch_size = round(batch_size)\\n    epochs = round(epochs)\\n\\n    def nn_cl_fun():\\n        opt = Adam(lr=learning_rate)\\n        nn = Sequential()\\n        nn.add(Dense(neurons, input_dim=10, activation=activation))\\n        nn.add(Dense(neurons, activation=activation))\\n        nn.add(Dense(1, activation=\\\"sigmoid\\\"))\\n        nn.compile(loss=\\\"binary_crossentropy\\\", optimizer=opt, metrics=[\\\"accuracy\\\"])\\n        return nn\\n\\n    es = EarlyStopping(monitor=\\\"accuracy\\\", mode=\\\"max\\\", verbose=0, patience=20)\\n    nn = KerasClassifier(\\n        build_fn=nn_cl_fun, epochs=epochs, batch_size=batch_size, verbose=0\\n    )\\n    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=123)\\n    score = cross_val_score(\\n        nn,\\n        train_dataset,\\n        y_train,\\n        scoring=score_acc,\\n        cv=kfold,\\n        fit_params={\\\"callbacks\\\": [es]},\\n    ).mean()\\n    return score\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
						"text/plain": [
							"<IPython.core.display.Javascript object>"
						]
					},
					"metadata": {},
					"output_type": "display_data"
				}
			],
			"source": [
				"# Create function\n",
				"def nn_cl_bo(neurons, activation, optimizer, learning_rate, batch_size, epochs):\n",
				"    optimizerL = [\n",
				"        \"SGD\",\n",
				"        \"Adam\",\n",
				"        \"RMSprop\",\n",
				"        \"Adadelta\",\n",
				"        \"Adagrad\",\n",
				"        \"Adamax\",\n",
				"        \"Nadam\",\n",
				"        \"Ftrl\",\n",
				"        \"SGD\",\n",
				"    ]\n",
				"    optimizerD = {\n",
				"        \"Adam\": Adam(lr=learning_rate),\n",
				"        \"SGD\": SGD(lr=learning_rate),\n",
				"        \"RMSprop\": RMSprop(lr=learning_rate),\n",
				"        \"Adadelta\": Adadelta(lr=learning_rate),\n",
				"        \"Adagrad\": Adagrad(lr=learning_rate),\n",
				"        \"Adamax\": Adamax(lr=learning_rate),\n",
				"        \"Nadam\": Nadam(lr=learning_rate),\n",
				"        \"Ftrl\": Ftrl(lr=learning_rate),\n",
				"    }\n",
				"    activationL = [\n",
				"        \"relu\",\n",
				"        \"sigmoid\",\n",
				"        \"softplus\",\n",
				"        \"softsign\",\n",
				"        \"tanh\",\n",
				"        \"selu\",\n",
				"        \"elu\",\n",
				"        \"exponential\",\n",
				"        LeakyReLU,\n",
				"        \"relu\",\n",
				"    ]\n",
				"    neurons = round(neurons)\n",
				"    activation = activationL[round(activation)]\n",
				"    batch_size = round(batch_size)\n",
				"    epochs = round(epochs)\n",
				"\n",
				"    def nn_cl_fun():\n",
				"        opt = Adam(lr=learning_rate)\n",
				"        nn = Sequential()\n",
				"        nn.add(Dense(neurons, input_dim=10, activation=activation))\n",
				"        nn.add(Dense(neurons, activation=activation))\n",
				"        nn.add(Dense(1, activation=\"sigmoid\"))\n",
				"        nn.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
				"        return nn\n",
				"\n",
				"    es = EarlyStopping(monitor=\"accuracy\", mode=\"max\", verbose=0, patience=20)\n",
				"    nn = KerasClassifier(\n",
				"        build_fn=nn_cl_fun, epochs=epochs, batch_size=batch_size, verbose=0\n",
				"    )\n",
				"    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=123)\n",
				"    score = cross_val_score(\n",
				"        nn,\n",
				"        train_dataset,\n",
				"        y_train,\n",
				"        scoring=score_acc,\n",
				"        cv=kfold,\n",
				"        fit_params={\"callbacks\": [es]},\n",
				"    ).mean()\n",
				"    return score"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 10,
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"|   iter    |  target   | activa... | batch_... |  epochs   | learni... |  neurons  | optimizer |\n",
						"-------------------------------------------------------------------------------------------------\n",
						"482/482 [==============================] - 1s 3ms/step\n",
						"482/482 [==============================] - 1s 3ms/step\n",
						"482/482 [==============================] - 1s 2ms/step\n",
						"482/482 [==============================] - 1s 2ms/step\n",
						"482/482 [==============================] - 1s 2ms/step\n",
						"| \u001b[0m 1       \u001b[0m | \u001b[0m 0.5151  \u001b[0m | \u001b[0m 5.51    \u001b[0m | \u001b[0m 335.3   \u001b[0m | \u001b[0m 54.88   \u001b[0m | \u001b[0m 0.7716  \u001b[0m | \u001b[0m 36.58   \u001b[0m | \u001b[0m 1.044   \u001b[0m |\n",
						"482/482 [==============================] - 1s 2ms/step\n",
						"482/482 [==============================] - 1s 2ms/step\n",
						"482/482 [==============================] - 1s 2ms/step\n",
						"482/482 [==============================] - 1s 2ms/step\n",
						"482/482 [==============================] - 1s 3ms/step\n",
						"| \u001b[95m 2       \u001b[0m | \u001b[95m 0.5719  \u001b[0m | \u001b[95m 0.2023  \u001b[0m | \u001b[95m 536.2   \u001b[0m | \u001b[95m 39.09   \u001b[0m | \u001b[95m 0.3443  \u001b[0m | \u001b[95m 99.16   \u001b[0m | \u001b[95m 1.664   \u001b[0m |\n",
						"482/482 [==============================] - 1s 2ms/step\n",
						"482/482 [==============================] - 1s 2ms/step\n",
						"482/482 [==============================] - 1s 2ms/step\n",
						"482/482 [==============================] - 1s 2ms/step\n",
						"482/482 [==============================] - 1s 2ms/step\n",
						"| \u001b[0m 3       \u001b[0m | \u001b[0m 0.5719  \u001b[0m | \u001b[0m 0.7307  \u001b[0m | \u001b[0m 735.7   \u001b[0m | \u001b[0m 69.7    \u001b[0m | \u001b[0m 0.2815  \u001b[0m | \u001b[0m 51.96   \u001b[0m | \u001b[0m 0.8286  \u001b[0m |\n",
						"482/482 [==============================] - 1s 2ms/step\n",
						"482/482 [==============================] - 1s 2ms/step\n",
						"482/482 [==============================] - 1s 2ms/step\n",
						"482/482 [==============================] - 1s 2ms/step\n",
						"482/482 [==============================] - 2s 3ms/step\n",
						"| \u001b[0m 4       \u001b[0m | \u001b[0m 0.5431  \u001b[0m | \u001b[0m 0.6656  \u001b[0m | \u001b[0m 920.6   \u001b[0m | \u001b[0m 83.52   \u001b[0m | \u001b[0m 0.8422  \u001b[0m | \u001b[0m 83.37   \u001b[0m | \u001b[0m 6.937   \u001b[0m |\n",
						"482/482 [==============================] - 2s 3ms/step\n",
						"482/482 [==============================] - 2s 3ms/step\n",
						"482/482 [==============================] - 2s 3ms/step\n",
						"482/482 [==============================] - 2s 3ms/step\n",
						"482/482 [==============================] - 2s 3ms/step\n",
						"| \u001b[95m 5       \u001b[0m | \u001b[95m 0.7654  \u001b[0m | \u001b[95m 5.195   \u001b[0m | \u001b[95m 851.0   \u001b[0m | \u001b[95m 53.71   \u001b[0m | \u001b[95m 0.03717 \u001b[0m | \u001b[95m 50.87   \u001b[0m | \u001b[95m 0.7373  \u001b[0m |\n",
						"482/482 [==============================] - 2s 3ms/step\n",
						"482/482 [==============================] - 2s 3ms/step\n",
						"482/482 [==============================] - 2s 3ms/step\n",
						"482/482 [==============================] - 2s 3ms/step\n",
						"482/482 [==============================] - 2s 3ms/step\n",
						"| \u001b[0m 6       \u001b[0m | \u001b[0m 0.5719  \u001b[0m | \u001b[0m 7.355   \u001b[0m | \u001b[0m 758.2   \u001b[0m | \u001b[0m 65.22   \u001b[0m | \u001b[0m 0.2815  \u001b[0m | \u001b[0m 99.86   \u001b[0m | \u001b[0m 0.9663  \u001b[0m |\n",
						"482/482 [==============================] - 2s 3ms/step\n",
						"482/482 [==============================] - 2s 3ms/step\n",
						"482/482 [==============================] - 2s 3ms/step\n",
						"482/482 [==============================] - 2s 3ms/step\n",
						"482/482 [==============================] - 2s 3ms/step\n",
						"| \u001b[0m 7       \u001b[0m | \u001b[0m 0.5144  \u001b[0m | \u001b[0m 5.539   \u001b[0m | \u001b[0m 588.0   \u001b[0m | \u001b[0m 52.4    \u001b[0m | \u001b[0m 0.7306  \u001b[0m | \u001b[0m 39.05   \u001b[0m | \u001b[0m 2.804   \u001b[0m |\n",
						"482/482 [==============================] - 2s 3ms/step\n",
						"482/482 [==============================] - 2s 3ms/step\n",
						"482/482 [==============================] - 2s 3ms/step\n",
						"482/482 [==============================] - 2s 3ms/step\n",
						"482/482 [==============================] - 2s 4ms/step\n",
						"| \u001b[0m 8       \u001b[0m | \u001b[0m 0.5777  \u001b[0m | \u001b[0m 2.871   \u001b[0m | \u001b[0m 957.8   \u001b[0m | \u001b[0m 93.5    \u001b[0m | \u001b[0m 0.8157  \u001b[0m | \u001b[0m 13.07   \u001b[0m | \u001b[0m 6.604   \u001b[0m |\n",
						"482/482 [==============================] - 2s 3ms/step\n",
						"482/482 [==============================] - 2s 4ms/step\n",
						"482/482 [==============================] - 2s 3ms/step\n",
						"482/482 [==============================] - 2s 3ms/step\n",
						"482/482 [==============================] - 2s 3ms/step\n",
						"| \u001b[0m 9       \u001b[0m | \u001b[0m 0.5431  \u001b[0m | \u001b[0m 8.554   \u001b[0m | \u001b[0m 845.3   \u001b[0m | \u001b[0m 58.5    \u001b[0m | \u001b[0m 0.9671  \u001b[0m | \u001b[0m 47.53   \u001b[0m | \u001b[0m 2.232   \u001b[0m |\n",
						"482/482 [==============================] - 2s 3ms/step\n",
						"482/482 [==============================] - 2s 3ms/step\n",
						"482/482 [==============================] - 2s 3ms/step\n",
						"482/482 [==============================] - 2s 3ms/step\n",
						"482/482 [==============================] - 2s 3ms/step\n",
						"| \u001b[0m 10      \u001b[0m | \u001b[0m 0.6092  \u001b[0m | \u001b[0m 0.148   \u001b[0m | \u001b[0m 230.5   \u001b[0m | \u001b[0m 24.25   \u001b[0m | \u001b[0m 0.1367  \u001b[0m | \u001b[0m 13.0    \u001b[0m | \u001b[0m 1.585   \u001b[0m |\n",
						"482/482 [==============================] - 1s 2ms/step\n",
						"482/482 [==============================] - 1s 2ms/step\n",
						"482/482 [==============================] - 1s 2ms/step\n",
						"482/482 [==============================] - 1s 3ms/step\n",
						"482/482 [==============================] - 1s 2ms/step\n",
						"| \u001b[0m 11      \u001b[0m | \u001b[0m 0.6648  \u001b[0m | \u001b[0m 4.895   \u001b[0m | \u001b[0m 342.9   \u001b[0m | \u001b[0m 34.35   \u001b[0m | \u001b[0m 0.1581  \u001b[0m | \u001b[0m 71.47   \u001b[0m | \u001b[0m 3.283   \u001b[0m |\n",
						"482/482 [==============================] - 1s 2ms/step\n",
						"482/482 [==============================] - 1s 2ms/step\n",
						"482/482 [==============================] - 1s 2ms/step\n",
						"482/482 [==============================] - 1s 2ms/step\n",
						"482/482 [==============================] - 2s 3ms/step\n",
						"| \u001b[0m 12      \u001b[0m | \u001b[0m 0.5719  \u001b[0m | \u001b[0m 6.914   \u001b[0m | \u001b[0m 735.1   \u001b[0m | \u001b[0m 55.3    \u001b[0m | \u001b[0m 0.5993  \u001b[0m | \u001b[0m 51.55   \u001b[0m | \u001b[0m 6.743   \u001b[0m |\n",
						"482/482 [==============================] - 2s 3ms/step\n",
						"482/482 [==============================] - 2s 3ms/step\n",
						"482/482 [==============================] - 2s 3ms/step\n",
						"482/482 [==============================] - 2s 3ms/step\n",
						"482/482 [==============================] - 2s 3ms/step\n",
						"| \u001b[0m 13      \u001b[0m | \u001b[0m 0.5719  \u001b[0m | \u001b[0m 1.33    \u001b[0m | \u001b[0m 925.5   \u001b[0m | \u001b[0m 59.83   \u001b[0m | \u001b[0m 0.5966  \u001b[0m | \u001b[0m 71.62   \u001b[0m | \u001b[0m 1.242   \u001b[0m |\n",
						"482/482 [==============================] - 1s 3ms/step\n",
						"482/482 [==============================] - 2s 3ms/step\n",
						"482/482 [==============================] - 1s 3ms/step\n",
						"482/482 [==============================] - 1s 3ms/step\n",
						"482/482 [==============================] - 2s 3ms/step\n",
						"| \u001b[0m 14      \u001b[0m | \u001b[0m 0.6713  \u001b[0m | \u001b[0m 7.782   \u001b[0m | \u001b[0m 585.7   \u001b[0m | \u001b[0m 25.55   \u001b[0m | \u001b[0m 0.3711  \u001b[0m | \u001b[0m 42.54   \u001b[0m | \u001b[0m 3.304   \u001b[0m |\n",
						"482/482 [==============================] - 1s 3ms/step\n",
						"482/482 [==============================] - 2s 3ms/step\n",
						"482/482 [==============================] - 2s 3ms/step\n",
						"482/482 [==============================] - 2s 3ms/step\n",
						"482/482 [==============================] - 2s 3ms/step\n",
						"| \u001b[0m 15      \u001b[0m | \u001b[0m 0.5431  \u001b[0m | \u001b[0m 1.615   \u001b[0m | \u001b[0m 340.2   \u001b[0m | \u001b[0m 95.93   \u001b[0m | \u001b[0m 0.6591  \u001b[0m | \u001b[0m 22.15   \u001b[0m | \u001b[0m 6.495   \u001b[0m |\n",
						"482/482 [==============================] - 1s 3ms/step\n",
						"482/482 [==============================] - 2s 3ms/step\n",
						"482/482 [==============================] - 1s 3ms/step\n",
						"482/482 [==============================] - 1s 3ms/step\n",
						"482/482 [==============================] - 2s 3ms/step\n",
						"| \u001b[0m 16      \u001b[0m | \u001b[0m 0.5392  \u001b[0m | \u001b[0m 7.576   \u001b[0m | \u001b[0m 242.2   \u001b[0m | \u001b[0m 36.29   \u001b[0m | \u001b[0m 0.8738  \u001b[0m | \u001b[0m 70.65   \u001b[0m | \u001b[0m 2.081   \u001b[0m |\n",
						"482/482 [==============================] - 2s 3ms/step\n",
						"482/482 [==============================] - 1s 3ms/step\n",
						"482/482 [==============================] - 1s 3ms/step\n",
						"482/482 [==============================] - 1s 3ms/step\n",
						"482/482 [==============================] - 1s 2ms/step\n",
						"| \u001b[0m 17      \u001b[0m | \u001b[0m 0.5719  \u001b[0m | \u001b[0m 6.61    \u001b[0m | \u001b[0m 694.7   \u001b[0m | \u001b[0m 36.84   \u001b[0m | \u001b[0m 0.804   \u001b[0m | \u001b[0m 15.32   \u001b[0m | \u001b[0m 2.158   \u001b[0m |\n",
						"482/482 [==============================] - 1s 2ms/step\n",
						"482/482 [==============================] - 2s 3ms/step\n",
						"482/482 [==============================] - 1s 3ms/step\n",
						"482/482 [==============================] - 2s 3ms/step\n",
						"482/482 [==============================] - 2s 3ms/step\n",
						"| \u001b[0m 18      \u001b[0m | \u001b[0m 0.5719  \u001b[0m | \u001b[0m 1.866   \u001b[0m | \u001b[0m 977.8   \u001b[0m | \u001b[0m 92.75   \u001b[0m | \u001b[0m 0.6797  \u001b[0m | \u001b[0m 20.37   \u001b[0m | \u001b[0m 6.706   \u001b[0m |\n",
						"482/482 [==============================] - 2s 4ms/step\n",
						"482/482 [==============================] - 2s 3ms/step\n",
						"482/482 [==============================] - 2s 3ms/step\n",
						"482/482 [==============================] - 1s 3ms/step\n",
						"482/482 [==============================] - 2s 3ms/step\n",
						"| \u001b[0m 19      \u001b[0m | \u001b[0m 0.5719  \u001b[0m | \u001b[0m 0.8254  \u001b[0m | \u001b[0m 703.8   \u001b[0m | \u001b[0m 92.23   \u001b[0m | \u001b[0m 0.3464  \u001b[0m | \u001b[0m 68.75   \u001b[0m | \u001b[0m 6.476   \u001b[0m |\n",
						"482/482 [==============================] - 1s 3ms/step\n",
						"482/482 [==============================] - 1s 3ms/step\n",
						"482/482 [==============================] - 1s 3ms/step\n",
						"482/482 [==============================] - 1s 3ms/step\n",
						"482/482 [==============================] - 2s 3ms/step\n",
						"| \u001b[0m 20      \u001b[0m | \u001b[0m 0.5794  \u001b[0m | \u001b[0m 3.366   \u001b[0m | \u001b[0m 817.1   \u001b[0m | \u001b[0m 91.69   \u001b[0m | \u001b[0m 0.624   \u001b[0m | \u001b[0m 23.6    \u001b[0m | \u001b[0m 2.624   \u001b[0m |\n",
						"482/482 [==============================] - 2s 3ms/step\n",
						"482/482 [==============================] - 2s 3ms/step\n",
						"482/482 [==============================] - 2s 3ms/step\n",
						"482/482 [==============================] - 1s 3ms/step\n",
						"482/482 [==============================] - 2s 3ms/step\n",
						"| \u001b[0m 21      \u001b[0m | \u001b[0m 0.6466  \u001b[0m | \u001b[0m 5.723   \u001b[0m | \u001b[0m 567.3   \u001b[0m | \u001b[0m 62.58   \u001b[0m | \u001b[0m 0.3588  \u001b[0m | \u001b[0m 69.39   \u001b[0m | \u001b[0m 3.336   \u001b[0m |\n",
						"482/482 [==============================] - 1s 1ms/step\n",
						"482/482 [==============================] - 2s 4ms/step\n",
						"482/482 [==============================] - 2s 3ms/step\n",
						"482/482 [==============================] - 2s 4ms/step\n",
						"482/482 [==============================] - 2s 3ms/step\n",
						"| \u001b[0m 22      \u001b[0m | \u001b[0m 0.5719  \u001b[0m | \u001b[0m 4.091   \u001b[0m | \u001b[0m 299.8   \u001b[0m | \u001b[0m 53.0    \u001b[0m | \u001b[0m 0.2804  \u001b[0m | \u001b[0m 41.21   \u001b[0m | \u001b[0m 6.821   \u001b[0m |\n",
						"482/482 [==============================] - 2s 4ms/step\n",
						"482/482 [==============================] - 2s 4ms/step\n",
						"482/482 [==============================] - 2s 4ms/step\n",
						"482/482 [==============================] - 2s 4ms/step\n",
						"482/482 [==============================] - 2s 4ms/step\n",
						"| \u001b[0m 23      \u001b[0m | \u001b[0m 0.5719  \u001b[0m | \u001b[0m 1.94    \u001b[0m | \u001b[0m 746.3   \u001b[0m | \u001b[0m 22.54   \u001b[0m | \u001b[0m 0.837   \u001b[0m | \u001b[0m 73.15   \u001b[0m | \u001b[0m 6.762   \u001b[0m |\n",
						"482/482 [==============================] - 2s 4ms/step\n",
						"482/482 [==============================] - 2s 3ms/step\n",
						"482/482 [==============================] - 2s 3ms/step\n",
						"482/482 [==============================] - 2s 3ms/step\n",
						"482/482 [==============================] - 2s 4ms/step\n",
						"| \u001b[0m 24      \u001b[0m | \u001b[0m 0.7644  \u001b[0m | \u001b[0m 5.326   \u001b[0m | \u001b[0m 373.9   \u001b[0m | \u001b[0m 77.54   \u001b[0m | \u001b[0m 0.04056 \u001b[0m | \u001b[0m 47.68   \u001b[0m | \u001b[0m 1.969   \u001b[0m |\n",
						"482/482 [==============================] - 2s 4ms/step\n",
						"482/482 [==============================] - 2s 4ms/step\n",
						"482/482 [==============================] - 2s 4ms/step\n",
						"482/482 [==============================] - 2s 4ms/step\n",
						"482/482 [==============================] - 1s 3ms/step\n",
						"| \u001b[0m 25      \u001b[0m | \u001b[0m 0.6857  \u001b[0m | \u001b[0m 0.9562  \u001b[0m | \u001b[0m 541.1   \u001b[0m | \u001b[0m 87.25   \u001b[0m | \u001b[0m 0.1193  \u001b[0m | \u001b[0m 98.8    \u001b[0m | \u001b[0m 1.633   \u001b[0m |\n",
						"482/482 [==============================] - 2s 3ms/step\n",
						"482/482 [==============================] - 1s 2ms/step\n",
						"482/482 [==============================] - 1s 1ms/step\n",
						"482/482 [==============================] - 1s 1ms/step\n",
						"482/482 [==============================] - 1s 2ms/step\n",
						"| \u001b[0m 26      \u001b[0m | \u001b[0m 0.7539  \u001b[0m | \u001b[0m 7.588   \u001b[0m | \u001b[0m 234.1   \u001b[0m | \u001b[0m 72.25   \u001b[0m | \u001b[0m 0.4108  \u001b[0m | \u001b[0m 27.87   \u001b[0m | \u001b[0m 4.56    \u001b[0m |\n",
						"482/482 [==============================] - 1s 2ms/step\n",
						"482/482 [==============================] - 1s 1ms/step\n",
						"482/482 [==============================] - 1s 2ms/step\n",
						"482/482 [==============================] - 1s 3ms/step\n",
						"482/482 [==============================] - 2s 3ms/step\n",
						"| \u001b[0m 27      \u001b[0m | \u001b[0m 0.5431  \u001b[0m | \u001b[0m 3.724   \u001b[0m | \u001b[0m 412.4   \u001b[0m | \u001b[0m 62.06   \u001b[0m | \u001b[0m 0.9792  \u001b[0m | \u001b[0m 77.42   \u001b[0m | \u001b[0m 4.245   \u001b[0m |\n",
						"482/482 [==============================] - 2s 4ms/step\n",
						"482/482 [==============================] - 2s 3ms/step\n",
						"482/482 [==============================] - 2s 5ms/step\n",
						"482/482 [==============================] - 2s 4ms/step\n",
						"482/482 [==============================] - 2s 3ms/step\n",
						"| \u001b[0m 28      \u001b[0m | \u001b[0m 0.5719  \u001b[0m | \u001b[0m 1.738   \u001b[0m | \u001b[0m 997.2   \u001b[0m | \u001b[0m 48.97   \u001b[0m | \u001b[0m 0.7989  \u001b[0m | \u001b[0m 46.98   \u001b[0m | \u001b[0m 6.493   \u001b[0m |\n",
						"482/482 [==============================] - 2s 3ms/step\n",
						"482/482 [==============================] - 1s 3ms/step\n",
						"482/482 [==============================] - 2s 3ms/step\n",
						"482/482 [==============================] - 2s 5ms/step\n",
						"482/482 [==============================] - 2s 3ms/step\n",
						"| \u001b[0m 29      \u001b[0m | \u001b[0m 0.5719  \u001b[0m | \u001b[0m 8.671   \u001b[0m | \u001b[0m 828.0   \u001b[0m | \u001b[0m 51.03   \u001b[0m | \u001b[0m 0.8384  \u001b[0m | \u001b[0m 55.77   \u001b[0m | \u001b[0m 6.071   \u001b[0m |\n",
						"=================================================================================================\n"
					]
				},
				{
					"data": {
						"application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 10;\n                var nbb_unformatted_code = \"# Set paramaters\\nparams_nn = {\\n    \\\"neurons\\\": (10, 100),\\n    \\\"activation\\\": (0, 9),\\n    \\\"optimizer\\\": (0, 7),\\n    \\\"learning_rate\\\": (0.01, 1),\\n    \\\"batch_size\\\": (200, 1000),\\n    \\\"epochs\\\": (20, 100),\\n}\\n# Run Bayesian Optimization\\nnn_bo = BayesianOptimization(nn_cl_bo, params_nn, random_state=111)\\nnn_bo.maximize(init_points=25, n_iter=4)\";\n                var nbb_formatted_code = \"# Set paramaters\\nparams_nn = {\\n    \\\"neurons\\\": (10, 100),\\n    \\\"activation\\\": (0, 9),\\n    \\\"optimizer\\\": (0, 7),\\n    \\\"learning_rate\\\": (0.01, 1),\\n    \\\"batch_size\\\": (200, 1000),\\n    \\\"epochs\\\": (20, 100),\\n}\\n# Run Bayesian Optimization\\nnn_bo = BayesianOptimization(nn_cl_bo, params_nn, random_state=111)\\nnn_bo.maximize(init_points=25, n_iter=4)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
						"text/plain": [
							"<IPython.core.display.Javascript object>"
						]
					},
					"metadata": {},
					"output_type": "display_data"
				}
			],
			"source": [
				"# Set paramaters\n",
				"params_nn = {\n",
				"    \"neurons\": (10, 100),\n",
				"    \"activation\": (0, 9),\n",
				"    \"optimizer\": (0, 7),\n",
				"    \"learning_rate\": (0.01, 1),\n",
				"    \"batch_size\": (200, 1000),\n",
				"    \"epochs\": (20, 100),\n",
				"}\n",
				"# Run Bayesian Optimization\n",
				"nn_bo = BayesianOptimization(nn_cl_bo, params_nn, random_state=111)\n",
				"nn_bo.maximize(init_points=25, n_iter=4)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 11,
			"metadata": {},
			"outputs": [
				{
					"data": {
						"text/plain": [
							"{'activation': 'selu',\n",
							" 'batch_size': 851.0135336291902,\n",
							" 'epochs': 53.7054301919375,\n",
							" 'learning_rate': 0.037173480215022196,\n",
							" 'neurons': 50.872297884262295,\n",
							" 'optimizer': 0.7372825972056519}"
						]
					},
					"execution_count": 11,
					"metadata": {},
					"output_type": "execute_result"
				},
				{
					"data": {
						"application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 11;\n                var nbb_unformatted_code = \"params_nn_ = nn_bo.max['params']\\nactivationL = ['relu', 'sigmoid', 'softplus', 'softsign', 'tanh', 'selu',\\n               'elu', 'exponential', LeakyReLU,'relu']\\nparams_nn_['activation'] = activationL[round(params_nn_['activation'])]\\nparams_nn_\";\n                var nbb_formatted_code = \"params_nn_ = nn_bo.max[\\\"params\\\"]\\nactivationL = [\\n    \\\"relu\\\",\\n    \\\"sigmoid\\\",\\n    \\\"softplus\\\",\\n    \\\"softsign\\\",\\n    \\\"tanh\\\",\\n    \\\"selu\\\",\\n    \\\"elu\\\",\\n    \\\"exponential\\\",\\n    LeakyReLU,\\n    \\\"relu\\\",\\n]\\nparams_nn_[\\\"activation\\\"] = activationL[round(params_nn_[\\\"activation\\\"])]\\nparams_nn_\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
						"text/plain": [
							"<IPython.core.display.Javascript object>"
						]
					},
					"metadata": {},
					"output_type": "display_data"
				}
			],
			"source": [
				"params_nn_ = nn_bo.max[\"params\"]\n",
				"activationL = [\n",
				"    \"relu\",\n",
				"    \"sigmoid\",\n",
				"    \"softplus\",\n",
				"    \"softsign\",\n",
				"    \"tanh\",\n",
				"    \"selu\",\n",
				"    \"elu\",\n",
				"    \"exponential\",\n",
				"    LeakyReLU,\n",
				"    \"relu\",\n",
				"]\n",
				"params_nn_[\"activation\"] = activationL[round(params_nn_[\"activation\"])]\n",
				"params_nn_"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"## Tune Layers"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 19,
			"metadata": {},
			"outputs": [
				{
					"ename": "IndentationError",
					"evalue": "expected an indented block (3049273778.py, line 15)",
					"output_type": "error",
					"traceback": [
						"\u001b[1;36m  Input \u001b[1;32mIn [19]\u001b[1;36m\u001b[0m\n\u001b[1;33m    optimizerL = [\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
					]
				},
				{
					"name": "stderr",
					"output_type": "stream",
					"text": [
						"ERROR:root:Cannot parse: 15:0: optimizerL = [\n",
						"Traceback (most recent call last):\n",
						"  File \"c:\\Users\\arthu\\.conda\\envs\\pystock\\lib\\site-packages\\lab_black.py\", line 218, in format_cell\n",
						"    formatted_code = _format_code(cell)\n",
						"  File \"c:\\Users\\arthu\\.conda\\envs\\pystock\\lib\\site-packages\\lab_black.py\", line 29, in _format_code\n",
						"    return format_str(src_contents=code, mode=FileMode())\n",
						"  File \"c:\\Users\\arthu\\.conda\\envs\\pystock\\lib\\site-packages\\black\\__init__.py\", line 1163, in format_str\n",
						"    dst_contents = _format_str_once(src_contents, mode=mode)\n",
						"  File \"c:\\Users\\arthu\\.conda\\envs\\pystock\\lib\\site-packages\\black\\__init__.py\", line 1173, in _format_str_once\n",
						"    src_node = lib2to3_parse(src_contents.lstrip(), mode.target_versions)\n",
						"  File \"c:\\Users\\arthu\\.conda\\envs\\pystock\\lib\\site-packages\\black\\parsing.py\", line 128, in lib2to3_parse\n",
						"    raise exc from None\n",
						"black.parsing.InvalidInput: Cannot parse: 15:0: optimizerL = [\n",
						"ERROR:root:Cannot parse: 15:0: optimizerL = [\n",
						"Traceback (most recent call last):\n",
						"  File \"c:\\Users\\arthu\\.conda\\envs\\pystock\\lib\\site-packages\\lab_black.py\", line 218, in format_cell\n",
						"    formatted_code = _format_code(cell)\n",
						"  File \"c:\\Users\\arthu\\.conda\\envs\\pystock\\lib\\site-packages\\lab_black.py\", line 29, in _format_code\n",
						"    return format_str(src_contents=code, mode=FileMode())\n",
						"  File \"c:\\Users\\arthu\\.conda\\envs\\pystock\\lib\\site-packages\\black\\__init__.py\", line 1163, in format_str\n",
						"    dst_contents = _format_str_once(src_contents, mode=mode)\n",
						"  File \"c:\\Users\\arthu\\.conda\\envs\\pystock\\lib\\site-packages\\black\\__init__.py\", line 1173, in _format_str_once\n",
						"    src_node = lib2to3_parse(src_contents.lstrip(), mode.target_versions)\n",
						"  File \"c:\\Users\\arthu\\.conda\\envs\\pystock\\lib\\site-packages\\black\\parsing.py\", line 128, in lib2to3_parse\n",
						"    raise exc from None\n",
						"black.parsing.InvalidInput: Cannot parse: 15:0: optimizerL = [\n"
					]
				}
			],
			"source": [
				"# Create function\n",
				"def nn_cl_bo2(\n",
				"    neurons,\n",
				"    activation,\n",
				"    optimizer,\n",
				"    learning_rate,\n",
				"    batch_size,\n",
				"    epochs,\n",
				"    layers1,\n",
				"    layers2,\n",
				"    normalization,\n",
				"    dropout,\n",
				"    dropout_rate,\n",
				"):\n",
				"    optimizerL = [\n",
				"        \"SGD\",\n",
				"        \"Adam\",\n",
				"        \"RMSprop\",\n",
				"        \"Adadelta\",\n",
				"        \"Adagrad\",\n",
				"        \"Adamax\",\n",
				"        \"Nadam\",\n",
				"        \"Ftrl\",\n",
				"        \"SGD\",\n",
				"    ]\n",
				"    optimizerD = {\n",
				"        \"Adam\": Adam(lr=learning_rate),\n",
				"        \"SGD\": SGD(lr=learning_rate),\n",
				"        \"RMSprop\": RMSprop(lr=learning_rate),\n",
				"        \"Adadelta\": Adadelta(lr=learning_rate),\n",
				"        \"Adagrad\": Adagrad(lr=learning_rate),\n",
				"        \"Adamax\": Adamax(lr=learning_rate),\n",
				"        \"Nadam\": Nadam(lr=learning_rate),\n",
				"        \"Ftrl\": Ftrl(lr=learning_rate),\n",
				"    }\n",
				"    activationL = [\n",
				"        \"relu\",\n",
				"        \"sigmoid\",\n",
				"        \"softplus\",\n",
				"        \"softsign\",\n",
				"        \"tanh\",\n",
				"        \"selu\",\n",
				"        \"elu\",\n",
				"        \"exponential\",\n",
				"        LeakyReLU,\n",
				"        \"relu\",\n",
				"    ]\n",
				"    neurons = round(neurons)\n",
				"    activation = activationL[round(activation)]\n",
				"    optimizer = optimizerD[optimizerL[round(optimizer)]]\n",
				"    batch_size = round(batch_size)\n",
				"    epochs = round(epochs)\n",
				"    layers1 = round(layers1)\n",
				"    layers2 = round(layers2)\n",
				"\n",
				"    def nn_cl_fun():\n",
				"        nn = Sequential()\n",
				"        nn.add(Dense(neurons, input_dim=10, activation=activation))\n",
				"        if normalization > 0.5:\n",
				"            nn.add(BatchNormalization())\n",
				"        for i in range(layers1):\n",
				"            nn.add(Dense(neurons, activation=activation))\n",
				"        if dropout > 0.5:\n",
				"            nn.add(Dropout(dropout_rate, seed=123))\n",
				"        for i in range(layers2):\n",
				"            nn.add(Dense(neurons, activation=activation))\n",
				"        nn.add(Dense(1, activation=\"sigmoid\"))\n",
				"        nn.compile(\n",
				"            loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"]\n",
				"        )\n",
				"        return nn\n",
				"\n",
				"    es = EarlyStopping(monitor=\"accuracy\", mode=\"max\", verbose=0, patience=20)\n",
				"    nn = KerasClassifier(\n",
				"        build_fn=nn_cl_fun, epochs=epochs, batch_size=batch_size, verbose=0\n",
				"    )\n",
				"    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=123)\n",
				"    score = cross_val_score(\n",
				"        nn,\n",
				"        train_dataset,\n",
				"        y_train,\n",
				"        scoring=score_acc,\n",
				"        cv=kfold,\n",
				"        fit_params={\"callbacks\": [es]},\n",
				"    ).mean()\n",
				"    return score"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 13,
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"|   iter    |  target   | activa... | batch_... |  dropout  | dropou... |  epochs   |  layers1  |  layers2  | learni... |  neurons  | normal... | optimizer |\n",
						"-------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
						"482/482 [==============================] - 1s 3ms/step\n",
						"482/482 [==============================] - 1s 3ms/step\n"
					]
				},
				{
					"ename": "KeyboardInterrupt",
					"evalue": "",
					"output_type": "error",
					"traceback": [
						"\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
						"\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
						"File \u001b[1;32mc:\\Users\\arthu\\.conda\\envs\\pystock\\lib\\site-packages\\bayes_opt\\target_space.py:191\u001b[0m, in \u001b[0;36mTargetSpace.probe\u001b[1;34m(self, params)\u001b[0m\n\u001b[0;32m    190\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 191\u001b[0m     target \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cache[_hashable(x)]\n\u001b[0;32m    192\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n",
						"\u001b[1;31mKeyError\u001b[0m: (5.509531580558568, 335.25580347650913, 0.4360590193711702, 0.23077874175693686, 43.6260243522301, 1.2983259142789796, 1.0449566490883235, 0.42602224734191213, 31.481392712180146, 0.33765619188879237, 6.934987252416151)",
						"\nDuring handling of the above exception, another exception occurred:\n",
						"\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
						"\u001b[1;32mc:\\Users\\arthu\\Documents\\GitHub\\TCC_Stock_Predictions\\Project-hyper\\Model_HYPER.ipynb Cell 15\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/arthu/Documents/GitHub/TCC_Stock_Predictions/Project-hyper/Model_HYPER.ipynb#X20sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m# Run Bayesian Optimization\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/arthu/Documents/GitHub/TCC_Stock_Predictions/Project-hyper/Model_HYPER.ipynb#X20sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m nn_bo \u001b[39m=\u001b[39m BayesianOptimization(nn_cl_bo2, params_nn2, random_state\u001b[39m=\u001b[39m\u001b[39m111\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/arthu/Documents/GitHub/TCC_Stock_Predictions/Project-hyper/Model_HYPER.ipynb#X20sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m nn_bo\u001b[39m.\u001b[39;49mmaximize(init_points\u001b[39m=\u001b[39;49m\u001b[39m25\u001b[39;49m, n_iter\u001b[39m=\u001b[39;49m\u001b[39m4\u001b[39;49m)\n",
						"File \u001b[1;32mc:\\Users\\arthu\\.conda\\envs\\pystock\\lib\\site-packages\\bayes_opt\\bayesian_optimization.py:185\u001b[0m, in \u001b[0;36mBayesianOptimization.maximize\u001b[1;34m(self, init_points, n_iter, acq, kappa, kappa_decay, kappa_decay_delay, xi, **gp_params)\u001b[0m\n\u001b[0;32m    182\u001b[0m     x_probe \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msuggest(util)\n\u001b[0;32m    183\u001b[0m     iteration \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m--> 185\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprobe(x_probe, lazy\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    187\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bounds_transformer:\n\u001b[0;32m    188\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_bounds(\n\u001b[0;32m    189\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bounds_transformer\u001b[39m.\u001b[39mtransform(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_space))\n",
						"File \u001b[1;32mc:\\Users\\arthu\\.conda\\envs\\pystock\\lib\\site-packages\\bayes_opt\\bayesian_optimization.py:116\u001b[0m, in \u001b[0;36mBayesianOptimization.probe\u001b[1;34m(self, params, lazy)\u001b[0m\n\u001b[0;32m    114\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_queue\u001b[39m.\u001b[39madd(params)\n\u001b[0;32m    115\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 116\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_space\u001b[39m.\u001b[39;49mprobe(params)\n\u001b[0;32m    117\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch(Events\u001b[39m.\u001b[39mOPTIMIZATION_STEP)\n",
						"File \u001b[1;32mc:\\Users\\arthu\\.conda\\envs\\pystock\\lib\\site-packages\\bayes_opt\\target_space.py:194\u001b[0m, in \u001b[0;36mTargetSpace.probe\u001b[1;34m(self, params)\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n\u001b[0;32m    193\u001b[0m     params \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(\u001b[39mzip\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_keys, x))\n\u001b[1;32m--> 194\u001b[0m     target \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtarget_func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams)\n\u001b[0;32m    195\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mregister(x, target)\n\u001b[0;32m    196\u001b[0m \u001b[39mreturn\u001b[39;00m target\n",
						"\u001b[1;32mc:\\Users\\arthu\\Documents\\GitHub\\TCC_Stock_Predictions\\Project-hyper\\Model_HYPER.ipynb Cell 15\u001b[0m in \u001b[0;36mnn_cl_bo2\u001b[1;34m(neurons, activation, optimizer, learning_rate, batch_size, epochs, layers1, layers2, normalization, dropout, dropout_rate)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/arthu/Documents/GitHub/TCC_Stock_Predictions/Project-hyper/Model_HYPER.ipynb#X20sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m nn \u001b[39m=\u001b[39m KerasClassifier(build_fn\u001b[39m=\u001b[39mnn_cl_fun, epochs\u001b[39m=\u001b[39mepochs, batch_size\u001b[39m=\u001b[39mbatch_size, verbose\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/arthu/Documents/GitHub/TCC_Stock_Predictions/Project-hyper/Model_HYPER.ipynb#X20sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m kfold \u001b[39m=\u001b[39m StratifiedKFold(n_splits\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, random_state\u001b[39m=\u001b[39m\u001b[39m123\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/arthu/Documents/GitHub/TCC_Stock_Predictions/Project-hyper/Model_HYPER.ipynb#X20sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m score \u001b[39m=\u001b[39m cross_val_score(nn, train_dataset, y_train, scoring\u001b[39m=\u001b[39;49mscore_acc, cv\u001b[39m=\u001b[39;49mkfold, fit_params\u001b[39m=\u001b[39;49m{\u001b[39m'\u001b[39;49m\u001b[39mcallbacks\u001b[39;49m\u001b[39m'\u001b[39;49m:[es]})\u001b[39m.\u001b[39mmean()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/arthu/Documents/GitHub/TCC_Stock_Predictions/Project-hyper/Model_HYPER.ipynb#X20sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m \u001b[39mreturn\u001b[39;00m score\n",
						"File \u001b[1;32mc:\\Users\\arthu\\.conda\\envs\\pystock\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:515\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[39m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[0;32m    513\u001b[0m scorer \u001b[39m=\u001b[39m check_scoring(estimator, scoring\u001b[39m=\u001b[39mscoring)\n\u001b[1;32m--> 515\u001b[0m cv_results \u001b[39m=\u001b[39m cross_validate(\n\u001b[0;32m    516\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[0;32m    517\u001b[0m     X\u001b[39m=\u001b[39;49mX,\n\u001b[0;32m    518\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[0;32m    519\u001b[0m     groups\u001b[39m=\u001b[39;49mgroups,\n\u001b[0;32m    520\u001b[0m     scoring\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mscore\u001b[39;49m\u001b[39m\"\u001b[39;49m: scorer},\n\u001b[0;32m    521\u001b[0m     cv\u001b[39m=\u001b[39;49mcv,\n\u001b[0;32m    522\u001b[0m     n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[0;32m    523\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m    524\u001b[0m     fit_params\u001b[39m=\u001b[39;49mfit_params,\n\u001b[0;32m    525\u001b[0m     pre_dispatch\u001b[39m=\u001b[39;49mpre_dispatch,\n\u001b[0;32m    526\u001b[0m     error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[0;32m    527\u001b[0m )\n\u001b[0;32m    528\u001b[0m \u001b[39mreturn\u001b[39;00m cv_results[\u001b[39m\"\u001b[39m\u001b[39mtest_score\u001b[39m\u001b[39m\"\u001b[39m]\n",
						"File \u001b[1;32mc:\\Users\\arthu\\.conda\\envs\\pystock\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:266\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[39m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[39m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[0;32m    265\u001b[0m parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39mn_jobs, verbose\u001b[39m=\u001b[39mverbose, pre_dispatch\u001b[39m=\u001b[39mpre_dispatch)\n\u001b[1;32m--> 266\u001b[0m results \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    267\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    268\u001b[0m         clone(estimator),\n\u001b[0;32m    269\u001b[0m         X,\n\u001b[0;32m    270\u001b[0m         y,\n\u001b[0;32m    271\u001b[0m         scorers,\n\u001b[0;32m    272\u001b[0m         train,\n\u001b[0;32m    273\u001b[0m         test,\n\u001b[0;32m    274\u001b[0m         verbose,\n\u001b[0;32m    275\u001b[0m         \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    276\u001b[0m         fit_params,\n\u001b[0;32m    277\u001b[0m         return_train_score\u001b[39m=\u001b[39;49mreturn_train_score,\n\u001b[0;32m    278\u001b[0m         return_times\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    279\u001b[0m         return_estimator\u001b[39m=\u001b[39;49mreturn_estimator,\n\u001b[0;32m    280\u001b[0m         error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[0;32m    281\u001b[0m     )\n\u001b[0;32m    282\u001b[0m     \u001b[39mfor\u001b[39;49;00m train, test \u001b[39min\u001b[39;49;00m cv\u001b[39m.\u001b[39;49msplit(X, y, groups)\n\u001b[0;32m    283\u001b[0m )\n\u001b[0;32m    285\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[0;32m    287\u001b[0m \u001b[39m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[39m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    289\u001b[0m \u001b[39m# the correct key.\u001b[39;00m\n",
						"File \u001b[1;32mc:\\Users\\arthu\\.conda\\envs\\pystock\\lib\\site-packages\\joblib\\parallel.py:1046\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1043\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1044\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1046\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[0;32m   1047\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m   1049\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1050\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1051\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1052\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
						"File \u001b[1;32mc:\\Users\\arthu\\.conda\\envs\\pystock\\lib\\site-packages\\joblib\\parallel.py:861\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    859\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    860\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 861\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[0;32m    862\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
						"File \u001b[1;32mc:\\Users\\arthu\\.conda\\envs\\pystock\\lib\\site-packages\\joblib\\parallel.py:779\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    777\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    778\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[1;32m--> 779\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[0;32m    780\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    781\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    782\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    783\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    784\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
						"File \u001b[1;32mc:\\Users\\arthu\\.conda\\envs\\pystock\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m     \u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
						"File \u001b[1;32mc:\\Users\\arthu\\.conda\\envs\\pystock\\lib\\site-packages\\joblib\\_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    569\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[0;32m    570\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    571\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 572\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
						"File \u001b[1;32mc:\\Users\\arthu\\.conda\\envs\\pystock\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    259\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 262\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    263\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
						"File \u001b[1;32mc:\\Users\\arthu\\.conda\\envs\\pystock\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    259\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 262\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    263\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
						"File \u001b[1;32mc:\\Users\\arthu\\.conda\\envs\\pystock\\lib\\site-packages\\sklearn\\utils\\fixes.py:117\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    116\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig):\n\u001b[1;32m--> 117\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
						"File \u001b[1;32mc:\\Users\\arthu\\.conda\\envs\\pystock\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    684\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    685\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 686\u001b[0m         estimator\u001b[39m.\u001b[39;49mfit(X_train, y_train, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[0;32m    688\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m    689\u001b[0m     \u001b[39m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    690\u001b[0m     fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
						"File \u001b[1;32mc:\\Users\\arthu\\.conda\\envs\\pystock\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py:236\u001b[0m, in \u001b[0;36mKerasClassifier.fit\u001b[1;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[0;32m    234\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mInvalid shape for y: \u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(y\u001b[39m.\u001b[39mshape))\n\u001b[0;32m    235\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_ \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_)\n\u001b[1;32m--> 236\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(KerasClassifier, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mfit(x, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
						"File \u001b[1;32mc:\\Users\\arthu\\.conda\\envs\\pystock\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py:164\u001b[0m, in \u001b[0;36mBaseWrapper.fit\u001b[1;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[0;32m    161\u001b[0m fit_args \u001b[39m=\u001b[39m copy\u001b[39m.\u001b[39mdeepcopy(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfilter_sk_params(Sequential\u001b[39m.\u001b[39mfit))\n\u001b[0;32m    162\u001b[0m fit_args\u001b[39m.\u001b[39mupdate(kwargs)\n\u001b[1;32m--> 164\u001b[0m history \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mfit(x, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_args)\n\u001b[0;32m    166\u001b[0m \u001b[39mreturn\u001b[39;00m history\n",
						"File \u001b[1;32mc:\\Users\\arthu\\.conda\\envs\\pystock\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
						"File \u001b[1;32mc:\\Users\\arthu\\.conda\\envs\\pystock\\lib\\site-packages\\keras\\engine\\training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1402\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1403\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   1404\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   1405\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[0;32m   1406\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m   1407\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m   1408\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1409\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1410\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1411\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
						"File \u001b[1;32mc:\\Users\\arthu\\.conda\\envs\\pystock\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
						"File \u001b[1;32mc:\\Users\\arthu\\.conda\\envs\\pystock\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
						"File \u001b[1;32mc:\\Users\\arthu\\.conda\\envs\\pystock\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
						"File \u001b[1;32mc:\\Users\\arthu\\.conda\\envs\\pystock\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2450\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2451\u001b[0m   (graph_function,\n\u001b[0;32m   2452\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2453\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2454\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
						"File \u001b[1;32mc:\\Users\\arthu\\.conda\\envs\\pystock\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1856\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1857\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1858\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1859\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1860\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1861\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1862\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1863\u001b[0m     args,\n\u001b[0;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1865\u001b[0m     executing_eagerly)\n\u001b[0;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
						"File \u001b[1;32mc:\\Users\\arthu\\.conda\\envs\\pystock\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    496\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 497\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    498\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    499\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    500\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    501\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    502\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    503\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    504\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    505\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    506\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    509\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    510\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
						"File \u001b[1;32mc:\\Users\\arthu\\.conda\\envs\\pystock\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
						"\u001b[1;31mKeyboardInterrupt\u001b[0m: "
					]
				},
				{
					"data": {
						"application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 13;\n                var nbb_unformatted_code = \"params_nn2 ={\\n    'neurons': (10, 100),\\n    'activation':(0, 9),\\n    'optimizer':(0,7),\\n    'learning_rate':(0.01, 1),\\n    'batch_size':(200, 1000),\\n    'epochs':(20, 100),\\n    'layers1':(1,3),\\n    'layers2':(1,3),\\n    'normalization':(0,1),\\n    'dropout':(0,1),\\n    'dropout_rate':(0,0.3)\\n}\\n# Run Bayesian Optimization\\nnn_bo = BayesianOptimization(nn_cl_bo2, params_nn2, random_state=111)\\nnn_bo.maximize(init_points=25, n_iter=4)\";\n                var nbb_formatted_code = \"params_nn2 = {\\n    \\\"neurons\\\": (10, 100),\\n    \\\"activation\\\": (0, 9),\\n    \\\"optimizer\\\": (0, 7),\\n    \\\"learning_rate\\\": (0.01, 1),\\n    \\\"batch_size\\\": (200, 1000),\\n    \\\"epochs\\\": (20, 100),\\n    \\\"layers1\\\": (1, 3),\\n    \\\"layers2\\\": (1, 3),\\n    \\\"normalization\\\": (0, 1),\\n    \\\"dropout\\\": (0, 1),\\n    \\\"dropout_rate\\\": (0, 0.3),\\n}\\n# Run Bayesian Optimization\\nnn_bo = BayesianOptimization(nn_cl_bo2, params_nn2, random_state=111)\\nnn_bo.maximize(init_points=25, n_iter=4)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
						"text/plain": [
							"<IPython.core.display.Javascript object>"
						]
					},
					"metadata": {},
					"output_type": "display_data"
				}
			],
			"source": [
				"params_nn2 = {\n",
				"    \"neurons\": (10, 100),\n",
				"    \"activation\": (0, 9),\n",
				"    \"optimizer\": (0, 7),\n",
				"    \"learning_rate\": (0.01, 1),\n",
				"    \"batch_size\": (200, 1000),\n",
				"    \"epochs\": (20, 100),\n",
				"    \"layers1\": (1, 3),\n",
				"    \"layers2\": (1, 3),\n",
				"    \"normalization\": (0, 1),\n",
				"    \"dropout\": (0, 1),\n",
				"    \"dropout_rate\": (0, 0.3),\n",
				"}\n",
				"# Run Bayesian Optimization\n",
				"nn_bo = BayesianOptimization(nn_cl_bo2, params_nn2, random_state=111)\n",
				"nn_bo.maximize(init_points=25, n_iter=4)"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"#### Executing"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 14,
			"metadata": {},
			"outputs": [
				{
					"ename": "KeyError",
					"evalue": "'params'",
					"output_type": "error",
					"traceback": [
						"\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
						"\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
						"\u001b[1;32mc:\\Users\\arthu\\Documents\\GitHub\\TCC_Stock_Predictions\\Project-hyper\\Model_HYPER.ipynb Cell 17\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/arthu/Documents/GitHub/TCC_Stock_Predictions/Project-hyper/Model_HYPER.ipynb#X22sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m params_nn_ \u001b[39m=\u001b[39m nn_bo\u001b[39m.\u001b[39;49mmax[\u001b[39m'\u001b[39;49m\u001b[39mparams\u001b[39;49m\u001b[39m'\u001b[39;49m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/arthu/Documents/GitHub/TCC_Stock_Predictions/Project-hyper/Model_HYPER.ipynb#X22sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m learning_rate \u001b[39m=\u001b[39m params_nn_[\u001b[39m'\u001b[39m\u001b[39mlearning_rate\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/arthu/Documents/GitHub/TCC_Stock_Predictions/Project-hyper/Model_HYPER.ipynb#X22sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m activationL \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39msigmoid\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39msoftplus\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39msoftsign\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mtanh\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mselu\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/arthu/Documents/GitHub/TCC_Stock_Predictions/Project-hyper/Model_HYPER.ipynb#X22sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m                \u001b[39m'\u001b[39m\u001b[39melu\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mexponential\u001b[39m\u001b[39m'\u001b[39m, LeakyReLU,\u001b[39m'\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m'\u001b[39m]\n",
						"\u001b[1;31mKeyError\u001b[0m: 'params'"
					]
				},
				{
					"data": {
						"application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 14;\n                var nbb_unformatted_code = \"params_nn_ = nn_bo.max['params']\\nlearning_rate = params_nn_['learning_rate']\\nactivationL = ['relu', 'sigmoid', 'softplus', 'softsign', 'tanh', 'selu',\\n               'elu', 'exponential', LeakyReLU,'relu']\\nparams_nn_['activation'] = activationL[round(params_nn_['activation'])]\\nparams_nn_['batch_size'] = round(params_nn_['batch_size'])\\nparams_nn_['epochs'] = round(params_nn_['epochs'])\\nparams_nn_['layers1'] = round(params_nn_['layers1'])\\nparams_nn_['layers2'] = round(params_nn_['layers2'])\\nparams_nn_['neurons'] = round(params_nn_['neurons'])\\noptimizerL = ['Adam', 'SGD', 'RMSprop', 'Adadelta', 'Adagrad', 'Adamax', 'Nadam', 'Ftrl','Adam']\\noptimizerD= {'Adam':Adam(lr=learning_rate), 'SGD':SGD(lr=learning_rate),\\n             'RMSprop':RMSprop(lr=learning_rate), 'Adadelta':Adadelta(lr=learning_rate),\\n             'Adagrad':Adagrad(lr=learning_rate), 'Adamax':Adamax(lr=learning_rate),\\n             'Nadam':Nadam(lr=learning_rate), 'Ftrl':Ftrl(lr=learning_rate)}\\nparams_nn_['optimizer'] = optimizerD[optimizerL[round(params_nn_['optimizer'])]]\\nparams_nn_\";\n                var nbb_formatted_code = \"params_nn_ = nn_bo.max[\\\"params\\\"]\\nlearning_rate = params_nn_[\\\"learning_rate\\\"]\\nactivationL = [\\n    \\\"relu\\\",\\n    \\\"sigmoid\\\",\\n    \\\"softplus\\\",\\n    \\\"softsign\\\",\\n    \\\"tanh\\\",\\n    \\\"selu\\\",\\n    \\\"elu\\\",\\n    \\\"exponential\\\",\\n    LeakyReLU,\\n    \\\"relu\\\",\\n]\\nparams_nn_[\\\"activation\\\"] = activationL[round(params_nn_[\\\"activation\\\"])]\\nparams_nn_[\\\"batch_size\\\"] = round(params_nn_[\\\"batch_size\\\"])\\nparams_nn_[\\\"epochs\\\"] = round(params_nn_[\\\"epochs\\\"])\\nparams_nn_[\\\"layers1\\\"] = round(params_nn_[\\\"layers1\\\"])\\nparams_nn_[\\\"layers2\\\"] = round(params_nn_[\\\"layers2\\\"])\\nparams_nn_[\\\"neurons\\\"] = round(params_nn_[\\\"neurons\\\"])\\noptimizerL = [\\n    \\\"Adam\\\",\\n    \\\"SGD\\\",\\n    \\\"RMSprop\\\",\\n    \\\"Adadelta\\\",\\n    \\\"Adagrad\\\",\\n    \\\"Adamax\\\",\\n    \\\"Nadam\\\",\\n    \\\"Ftrl\\\",\\n    \\\"Adam\\\",\\n]\\noptimizerD = {\\n    \\\"Adam\\\": Adam(lr=learning_rate),\\n    \\\"SGD\\\": SGD(lr=learning_rate),\\n    \\\"RMSprop\\\": RMSprop(lr=learning_rate),\\n    \\\"Adadelta\\\": Adadelta(lr=learning_rate),\\n    \\\"Adagrad\\\": Adagrad(lr=learning_rate),\\n    \\\"Adamax\\\": Adamax(lr=learning_rate),\\n    \\\"Nadam\\\": Nadam(lr=learning_rate),\\n    \\\"Ftrl\\\": Ftrl(lr=learning_rate),\\n}\\nparams_nn_[\\\"optimizer\\\"] = optimizerD[optimizerL[round(params_nn_[\\\"optimizer\\\"])]]\\nparams_nn_\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
						"text/plain": [
							"<IPython.core.display.Javascript object>"
						]
					},
					"metadata": {},
					"output_type": "display_data"
				}
			],
			"source": [
				"params_nn_ = nn_bo.max[\"params\"]\n",
				"learning_rate = params_nn_[\"learning_rate\"]\n",
				"activationL = [\n",
				"    \"relu\",\n",
				"    \"sigmoid\",\n",
				"    \"softplus\",\n",
				"    \"softsign\",\n",
				"    \"tanh\",\n",
				"    \"selu\",\n",
				"    \"elu\",\n",
				"    \"exponential\",\n",
				"    LeakyReLU,\n",
				"    \"relu\",\n",
				"]\n",
				"params_nn_[\"activation\"] = activationL[round(params_nn_[\"activation\"])]\n",
				"params_nn_[\"batch_size\"] = round(params_nn_[\"batch_size\"])\n",
				"params_nn_[\"epochs\"] = round(params_nn_[\"epochs\"])\n",
				"params_nn_[\"layers1\"] = round(params_nn_[\"layers1\"])\n",
				"params_nn_[\"layers2\"] = round(params_nn_[\"layers2\"])\n",
				"params_nn_[\"neurons\"] = round(params_nn_[\"neurons\"])\n",
				"optimizerL = [\n",
				"    \"Adam\",\n",
				"    \"SGD\",\n",
				"    \"RMSprop\",\n",
				"    \"Adadelta\",\n",
				"    \"Adagrad\",\n",
				"    \"Adamax\",\n",
				"    \"Nadam\",\n",
				"    \"Ftrl\",\n",
				"    \"Adam\",\n",
				"]\n",
				"optimizerD = {\n",
				"    \"Adam\": Adam(lr=learning_rate),\n",
				"    \"SGD\": SGD(lr=learning_rate),\n",
				"    \"RMSprop\": RMSprop(lr=learning_rate),\n",
				"    \"Adadelta\": Adadelta(lr=learning_rate),\n",
				"    \"Adagrad\": Adagrad(lr=learning_rate),\n",
				"    \"Adamax\": Adamax(lr=learning_rate),\n",
				"    \"Nadam\": Nadam(lr=learning_rate),\n",
				"    \"Ftrl\": Ftrl(lr=learning_rate),\n",
				"}\n",
				"params_nn_[\"optimizer\"] = optimizerD[optimizerL[round(params_nn_[\"optimizer\"])]]\n",
				"params_nn_"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 18,
			"metadata": {},
			"outputs": [
				{
					"ename": "NameError",
					"evalue": "name 'X_train' is not defined",
					"output_type": "error",
					"traceback": [
						"\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
						"\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
						"\u001b[1;32mc:\\Users\\arthu\\Documents\\GitHub\\TCC_Stock_Predictions\\Project-hyper\\Model_HYPER.ipynb Cell 18\u001b[0m in \u001b[0;36m<cell line: 21>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/arthu/Documents/GitHub/TCC_Stock_Predictions/Project-hyper/Model_HYPER.ipynb#X23sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m es \u001b[39m=\u001b[39m EarlyStopping(monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m, mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmax\u001b[39m\u001b[39m'\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, patience\u001b[39m=\u001b[39m\u001b[39m20\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/arthu/Documents/GitHub/TCC_Stock_Predictions/Project-hyper/Model_HYPER.ipynb#X23sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m nn \u001b[39m=\u001b[39m KerasClassifier(build_fn\u001b[39m=\u001b[39mnn_cl_fun, epochs\u001b[39m=\u001b[39mparams_nn_[\u001b[39m'\u001b[39m\u001b[39mepochs\u001b[39m\u001b[39m'\u001b[39m], batch_size\u001b[39m=\u001b[39mparams_nn_[\u001b[39m'\u001b[39m\u001b[39mbatch_size\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/arthu/Documents/GitHub/TCC_Stock_Predictions/Project-hyper/Model_HYPER.ipynb#X23sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m verbose\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/arthu/Documents/GitHub/TCC_Stock_Predictions/Project-hyper/Model_HYPER.ipynb#X23sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m nn\u001b[39m.\u001b[39mfit(X_train, y_train, validation_data\u001b[39m=\u001b[39m(X_val, y_val), verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
						"\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
					]
				},
				{
					"data": {
						"application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 18;\n                var nbb_unformatted_code = \"# Fitting Neural Network\\ndef nn_cl_fun():\\n \\n\\tnn = Sequential()\\n\\tnn.add(Dense(params_nn_['neurons'], input_dim=10, activation=params_nn_['activation']))\\n\\tif params_nn_['normalization'] > 0.5:\\n\\t\\tnn.add(BatchNormalization())\\n\\tfor i in range(params_nn_['layers1']):\\n\\t\\tnn.add(Dense(params_nn_['neurons'], activation=params_nn_['activation']))\\n\\tif params_nn_['dropout'] > 0.5:\\n\\t\\tnn.add(Dropout(params_nn_['dropout_rate'], seed=123))\\n\\tfor i in range(params_nn_['layers2']):\\n\\t\\tnn.add(Dense(params_nn_['neurons'], activation=params_nn_['activation']))\\n\\t\\tnn.add(Dense(1, activation='sigmoid'))\\n\\t\\tnn.compile(loss='binary_crossentropy', optimizer=params_nn_['optimizer'], metrics=['accuracy'])\\n\\treturn nn\\n\\nes = EarlyStopping(monitor='accuracy', mode='max', verbose=0, patience=20)\\nnn = KerasClassifier(build_fn=nn_cl_fun, epochs=params_nn_['epochs'], batch_size=params_nn_['batch_size'],\\nverbose=0)\\nnn.fit(X_train, y_train, validation_data=(X_val, y_val), verbose=1)\";\n                var nbb_formatted_code = \"# Fitting Neural Network\\ndef nn_cl_fun():\\n\\n    nn = Sequential()\\n    nn.add(\\n        Dense(params_nn_[\\\"neurons\\\"], input_dim=10, activation=params_nn_[\\\"activation\\\"])\\n    )\\n    if params_nn_[\\\"normalization\\\"] > 0.5:\\n        nn.add(BatchNormalization())\\n    for i in range(params_nn_[\\\"layers1\\\"]):\\n        nn.add(Dense(params_nn_[\\\"neurons\\\"], activation=params_nn_[\\\"activation\\\"]))\\n    if params_nn_[\\\"dropout\\\"] > 0.5:\\n        nn.add(Dropout(params_nn_[\\\"dropout_rate\\\"], seed=123))\\n    for i in range(params_nn_[\\\"layers2\\\"]):\\n        nn.add(Dense(params_nn_[\\\"neurons\\\"], activation=params_nn_[\\\"activation\\\"]))\\n        nn.add(Dense(1, activation=\\\"sigmoid\\\"))\\n        nn.compile(\\n            loss=\\\"binary_crossentropy\\\",\\n            optimizer=params_nn_[\\\"optimizer\\\"],\\n            metrics=[\\\"accuracy\\\"],\\n        )\\n    return nn\\n\\n\\nes = EarlyStopping(monitor=\\\"accuracy\\\", mode=\\\"max\\\", verbose=0, patience=20)\\nnn = KerasClassifier(\\n    build_fn=nn_cl_fun,\\n    epochs=params_nn_[\\\"epochs\\\"],\\n    batch_size=params_nn_[\\\"batch_size\\\"],\\n    verbose=0,\\n)\\nnn.fit(X_train, y_train, validation_data=(X_val, y_val), verbose=1)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
						"text/plain": [
							"<IPython.core.display.Javascript object>"
						]
					},
					"metadata": {},
					"output_type": "display_data"
				}
			],
			"source": [
				"# Fitting Neural Network\n",
				"def nn_cl_fun():\n",
				"\n",
				"    nn = Sequential()\n",
				"    nn.add(\n",
				"        Dense(params_nn_[\"neurons\"], input_dim=10, activation=params_nn_[\"activation\"])\n",
				"    )\n",
				"    if params_nn_[\"normalization\"] > 0.5:\n",
				"        nn.add(BatchNormalization())\n",
				"    for i in range(params_nn_[\"layers1\"]):\n",
				"        nn.add(Dense(params_nn_[\"neurons\"], activation=params_nn_[\"activation\"]))\n",
				"    if params_nn_[\"dropout\"] > 0.5:\n",
				"        nn.add(Dropout(params_nn_[\"dropout_rate\"], seed=123))\n",
				"    for i in range(params_nn_[\"layers2\"]):\n",
				"        nn.add(Dense(params_nn_[\"neurons\"], activation=params_nn_[\"activation\"]))\n",
				"        nn.add(Dense(1, activation=\"sigmoid\"))\n",
				"        nn.compile(\n",
				"            loss=\"binary_crossentropy\",\n",
				"            optimizer=params_nn_[\"optimizer\"],\n",
				"            metrics=[\"accuracy\"],\n",
				"        )\n",
				"    return nn\n",
				"\n",
				"\n",
				"es = EarlyStopping(monitor=\"accuracy\", mode=\"max\", verbose=0, patience=20)\n",
				"nn = KerasClassifier(\n",
				"    build_fn=nn_cl_fun,\n",
				"    epochs=params_nn_[\"epochs\"],\n",
				"    batch_size=params_nn_[\"batch_size\"],\n",
				"    verbose=0,\n",
				")\n",
				"nn.fit(X_train, y_train, validation_data=(X_val, y_val), verbose=1)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": []
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": []
		}
	],
	"metadata": {
		"kernelspec": {
			"display_name": "Python 3.8.12 ('pystock')",
			"language": "python",
			"name": "python3"
		},
		"language_info": {
			"codemirror_mode": {
				"name": "ipython",
				"version": 3
			},
			"file_extension": ".py",
			"mimetype": "text/x-python",
			"name": "python",
			"nbconvert_exporter": "python",
			"pygments_lexer": "ipython3",
			"version": "3.8.13"
		},
		"orig_nbformat": 4,
		"vscode": {
			"interpreter": {
				"hash": "bc0c8eb905859abd75b389576d87e2ac71c748b72952270660ecc130aeb3e651"
			}
		}
	},
	"nbformat": 4,
	"nbformat_minor": 2
}
